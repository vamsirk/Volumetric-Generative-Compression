{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies not loaded, some functionality may not work\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dataIO as d\n",
    "\n",
    "from tqdm import *\n",
    "from utils import *\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voxel(voxel, voxel2=None, saveas=None):\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax.voxels(voxel.squeeze()>.5, facecolors='red', edgecolors='k')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    if voxel2 is not None:\n",
    "        ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "        ax.voxels(voxel2.squeeze()>.5, facecolors='red', edgecolors='k')\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "    if saveas is not None:\n",
    "        plt.savefig(saveas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'vase-ae_3_test'\n",
    "\n",
    "voxnet_save_path = '/home/vamsi/Downloads/tf-3dgan-master/src/models/cls_vox/biasfree_19999.cptk'\n",
    "gan_save_directory = '/home/vamsi/Downloads/tf-3dgan-master/src/models/vase/biasfree_5600.cptk'\n",
    "\n",
    "train_sample_directory = './train_sample/' + experiment_name + '/'\n",
    "model_directory = './models/' + experiment_name + '/'\n",
    "\n",
    "img_base_directory = './img/'\n",
    "img_directory = img_base_directory + experiment_name + '/'\n",
    "\n",
    "pickle_base_directory = './pickle/'\n",
    "pickle_directory = pickle_base_directory + experiment_name + '/'\n",
    "\n",
    "if not os.path.exists(pickle_directory):\n",
    "    os.makedirs(pickle_directory)\n",
    "    \n",
    "if not os.path.exists(train_sample_directory):\n",
    "    os.makedirs(train_sample_directory)\n",
    "    \n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "    \n",
    "if not os.path.exists(img_directory):\n",
    "    os.makedirs(img_directory)\n",
    "    \n",
    "    \n",
    "batch_size = 100\n",
    "z_size = 200\n",
    "cube_len = 32\n",
    "leak_value = 0.2\n",
    "weights = {}\n",
    "l = 0.95\n",
    "lr = 0.001\n",
    "\n",
    "obj = 'vase'\n",
    "obj_ratio = 1.0\n",
    "num_epoch = 101\n",
    "save_interval = 5\n",
    "beta       = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(z, batch_size=batch_size, phase_train=True, reuse=False):\n",
    "\n",
    "    strides    = [2,2,2]\n",
    "\n",
    "    with tf.variable_scope(\"gen\", reuse=reuse):\n",
    "#         z = tf.reshape(z, (batch_size, 1, 1, 1, z_size))\n",
    "        g_1 = tf.layers.dense(z, 256*2*2*2, kernel_initializer=tf.random_normal_initializer(stddev=0.02), name='g1',trainable=phase_train)\n",
    "        g_1 = tf.reshape(g_1, (-1, 2,2,2,256))\n",
    "#         g_1 = tf.nn.conv3d_transpose(z, weights['wg1'], (batch_size,4,4,4,512), strides=[1,1,1,1,1], padding=\"VALID\")\n",
    "        g_1 = tf.layers.batch_normalization(g_1, training=phase_train, name='g_bn1')\n",
    "        g_1 = tf.nn.relu(g_1)\n",
    "\n",
    "        g_2 = tf.layers.conv3d_transpose(g_1, 256, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g2',trainable=phase_train)\n",
    "        g_2 = tf.layers.batch_normalization(g_2, training=phase_train, name='g_bn2')\n",
    "        g_2 = tf.nn.relu(g_2)\n",
    "\n",
    "        g_3 = tf.layers.conv3d_transpose(g_2, 128, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g3',trainable=phase_train)\n",
    "        g_3 = tf.layers.batch_normalization(g_3, training=phase_train, name='g_bn3')\n",
    "        g_3 = tf.nn.relu(g_3)\n",
    "\n",
    "        g_4 = tf.layers.conv3d_transpose(g_3, 64, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g4',trainable=phase_train)\n",
    "        g_4 = tf.layers.batch_normalization(g_4, training=phase_train, name='g_bn4')\n",
    "        g_4 = tf.nn.relu(g_4)\n",
    "        \n",
    "        g_5 = tf.layers.conv3d_transpose(g_4, 1, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g5',trainable=phase_train)\n",
    "        g_5 = tf.nn.sigmoid(g_5)\n",
    "#         g_5 = tf.nn.tanh(g_5)\n",
    "\n",
    "    print (g_1, 'g1')\n",
    "    print (g_2, 'g2')\n",
    "    print (g_3, 'g3')\n",
    "    print (g_4, 'g4')\n",
    "    print (g_5, 'g5')\n",
    "    \n",
    "    return g_5\n",
    "\n",
    "def encoder(inputs, encoding_size, phase_train=True, reuse=False):\n",
    "\n",
    "    strides    = [2,2,2]\n",
    "    with tf.variable_scope(\"enc\", reuse=reuse):\n",
    "             \n",
    "        d_1 = tf.layers.conv3d(inputs, 32, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='e1',trainable=phase_train)\n",
    "        d_1 = tf.layers.batch_normalization(d_1, training=phase_train, name='bn_e1')                               \n",
    "        d_1 = lrelu(d_1, leak_value)\n",
    "\n",
    "        d_2 = tf.layers.conv3d(d_1, 64, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='e2',trainable=phase_train) \n",
    "        d_2 = tf.layers.batch_normalization(d_2, training=phase_train, name='bn_e2')\n",
    "        d_2 = lrelu(d_2, leak_value)\n",
    "        \n",
    "        d_3 = tf.layers.conv3d(d_2, 128, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='e3',trainable=phase_train)\n",
    "        d_3 = tf.layers.batch_normalization(d_3, training=phase_train, name='bn_e3')\n",
    "        d_3 = lrelu(d_3, leak_value) \n",
    "\n",
    "        d_4 = tf.layers.conv3d(d_3, 256, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='e4',trainable=phase_train)    \n",
    "        d_4 = tf.layers.batch_normalization(d_4, training=phase_train, name='bn_e4')\n",
    "        d_4 = lrelu(d_4)\n",
    "\n",
    "        d_5 = tf.contrib.layers.flatten(d_4)\n",
    "        d_5 = tf.layers.dense(d_5, encoding_size, kernel_initializer=tf.random_normal_initializer(stddev=0.02), name='f1',trainable=phase_train)\n",
    "        d_5_no_sigmoid = d_5\n",
    "        d_5 = tf.nn.sigmoid(d_5)\n",
    "        \n",
    "        \n",
    "    print (d_1, 'd1')\n",
    "    print (d_2, 'd2')\n",
    "    print (d_3, 'd3')\n",
    "    print (d_4, 'd4')\n",
    "    print (d_5, 'd5')\n",
    "\n",
    "    return d_5, d_5_no_sigmoid\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"enc/Maximum:0\", shape=(100, 16, 16, 16, 32), dtype=float32) d1\n",
      "Tensor(\"enc/Maximum_1:0\", shape=(100, 8, 8, 8, 64), dtype=float32) d2\n",
      "Tensor(\"enc/Maximum_2:0\", shape=(100, 4, 4, 4, 128), dtype=float32) d3\n",
      "Tensor(\"enc/Maximum_3:0\", shape=(100, 2, 2, 2, 256), dtype=float32) d4\n",
      "Tensor(\"enc/Sigmoid:0\", shape=(100, 200), dtype=float32) d5\n",
      "Tensor(\"gen/Relu:0\", shape=(100, 2, 2, 2, 256), dtype=float32) g1\n",
      "Tensor(\"gen/Relu_1:0\", shape=(100, 4, 4, 4, 256), dtype=float32) g2\n",
      "Tensor(\"gen/Relu_2:0\", shape=(100, 8, 8, 8, 128), dtype=float32) g3\n",
      "Tensor(\"gen/Relu_3:0\", shape=(100, 16, 16, 16, 64), dtype=float32) g4\n",
      "Tensor(\"gen/Sigmoid:0\", shape=(100, 32, 32, 32, 1), dtype=float32) g5\n"
     ]
    }
   ],
   "source": [
    "x_vector = tf.placeholder(shape=[batch_size,cube_len,cube_len,cube_len,1],dtype=tf.float32) \n",
    "\n",
    "#encoding from 32*32*32 down to 200 ::: 163x\n",
    "enc,_ = encoder(x_vector, z_size, phase_train=True, reuse=False)\n",
    "dec = decoder(enc, phase_train=True, reuse=False) \n",
    "\n",
    "loss_pixel = tf.nn.l2_loss(x_vector - dec) / (batch_size*cube_len*cube_len*cube_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='enc')\n",
    "#build a list of variable to load\n",
    "generator_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='gen')\n",
    "#generator_vars.extend(list(weights.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=lr, beta1 = beta ).minimize(loss_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vase Data\n",
      "epoch 0, batch 0: total loss    0.11925\n",
      "epoch 0, batch 1: total loss    0.10010\n",
      "epoch 0, batch 2: total loss    0.07760\n",
      "epoch 0, batch 3: total loss    0.06251\n",
      "epoch 0, batch 4: total loss    0.05054\n",
      "epoch 0, batch 5: total loss    0.04257\n",
      "epoch 0, batch 6: total loss    0.03709\n",
      "epoch 0, batch 7: total loss    0.03353\n",
      "epoch 0, batch 8: total loss    0.03044\n",
      "epoch 0, batch 9: total loss    0.02928\n",
      "epoch 0, batch 10: total loss    0.02684\n",
      "epoch 0, batch 11: total loss    0.02700\n",
      "epoch 0, batch 12: total loss    0.02773\n",
      "epoch 0, batch 13: total loss    0.02345\n",
      "epoch 0, batch 14: total loss    0.02418\n",
      "epoch 0, batch 15: total loss    0.02259\n",
      "epoch 0, batch 16: total loss    0.02152\n",
      "epoch 0, batch 17: total loss    0.02208\n",
      "epoch 0, batch 18: total loss    0.02049\n",
      "epoch 0, batch 19: total loss    0.02049\n",
      "epoch 0, batch 20: total loss    0.02039\n",
      "epoch 0, batch 21: total loss    0.01973\n",
      "epoch 0, batch 22: total loss    0.02023\n",
      "epoch 0, batch 23: total loss    0.01873\n",
      "epoch 0, batch 24: total loss    0.01931\n",
      "epoch 0, batch 25: total loss    0.01857\n",
      "epoch 0, batch 26: total loss    0.01913\n",
      "epoch 0, batch 27: total loss    0.01869\n",
      "epoch 0, batch 28: total loss    0.01756\n",
      "epoch 0, batch 29: total loss    0.01739\n",
      "epoch 0, batch 30: total loss    0.01838\n",
      "epoch 0, batch 31: total loss    0.01719\n",
      "epoch 0, batch 32: total loss    0.01991\n",
      "epoch 0, batch 33: total loss    0.01827\n",
      "epoch 0, batch 34: total loss    0.01818\n",
      "epoch 0, batch 35: total loss    0.01819\n",
      "epoch 0, batch 36: total loss    0.01808\n",
      "epoch 0, batch 37: total loss    0.01743\n",
      "epoch 0, batch 38: total loss    0.01815\n",
      "epoch 0, batch 39: total loss    0.01747\n",
      "epoch 0, batch 40: total loss    0.01547\n",
      "epoch 0, batch 41: total loss    0.01821\n",
      "epoch 0, batch 42: total loss    0.01771\n",
      "epoch 0, batch 43: total loss    0.01813\n",
      "epoch 0, batch 44: total loss    0.01809\n",
      "epoch 0, batch 45: total loss    0.01643\n",
      "epoch 0, batch 46: total loss    0.01784\n",
      "epoch 0, batch 47: total loss    0.01657\n",
      "epoch 0, batch 48: total loss    0.01473\n",
      "epoch 0, batch 49: total loss    0.01754\n",
      "epoch 0, batch 50: total loss    0.01603\n",
      "epoch 0, batch 51: total loss    0.01514\n",
      "epoch 0, batch 52: total loss    0.01635\n",
      "epoch 0, batch 53: total loss    0.01647\n",
      "epoch 0, batch 54: total loss    0.01546\n",
      "epoch 0, batch 55: total loss    0.01579\n",
      "epoch 0, batch 56: total loss    0.01708\n",
      "epoch 1, batch 0: total loss    0.01600\n",
      "epoch 1, batch 1: total loss    0.01412\n",
      "epoch 1, batch 2: total loss    0.01575\n",
      "epoch 1, batch 3: total loss    0.01643\n",
      "epoch 1, batch 4: total loss    0.01510\n",
      "epoch 1, batch 5: total loss    0.01535\n",
      "epoch 1, batch 6: total loss    0.01515\n",
      "epoch 1, batch 7: total loss    0.01401\n",
      "epoch 1, batch 8: total loss    0.01565\n",
      "epoch 1, batch 9: total loss    0.01458\n",
      "epoch 1, batch 10: total loss    0.01355\n",
      "epoch 1, batch 11: total loss    0.01634\n",
      "epoch 1, batch 12: total loss    0.01523\n",
      "epoch 1, batch 13: total loss    0.01370\n",
      "epoch 1, batch 14: total loss    0.01469\n",
      "epoch 1, batch 15: total loss    0.01464\n",
      "epoch 1, batch 16: total loss    0.01465\n",
      "epoch 1, batch 17: total loss    0.01307\n",
      "epoch 1, batch 18: total loss    0.01582\n",
      "epoch 1, batch 19: total loss    0.01478\n",
      "epoch 1, batch 20: total loss    0.01525\n",
      "epoch 1, batch 21: total loss    0.01407\n",
      "epoch 1, batch 22: total loss    0.01355\n",
      "epoch 1, batch 23: total loss    0.01462\n",
      "epoch 1, batch 24: total loss    0.01415\n",
      "epoch 1, batch 25: total loss    0.01308\n",
      "epoch 1, batch 26: total loss    0.01429\n",
      "epoch 1, batch 27: total loss    0.01325\n",
      "epoch 1, batch 28: total loss    0.01311\n",
      "epoch 1, batch 29: total loss    0.01353\n",
      "epoch 1, batch 30: total loss    0.01345\n",
      "epoch 1, batch 31: total loss    0.01303\n",
      "epoch 1, batch 32: total loss    0.01428\n",
      "epoch 1, batch 33: total loss    0.01245\n",
      "epoch 1, batch 34: total loss    0.01546\n",
      "epoch 1, batch 35: total loss    0.01535\n",
      "epoch 1, batch 36: total loss    0.01353\n",
      "epoch 1, batch 37: total loss    0.01334\n",
      "epoch 1, batch 38: total loss    0.01403\n",
      "epoch 1, batch 39: total loss    0.01307\n",
      "epoch 1, batch 40: total loss    0.01326\n",
      "epoch 1, batch 41: total loss    0.01271\n",
      "epoch 1, batch 42: total loss    0.01163\n",
      "epoch 1, batch 43: total loss    0.01357\n",
      "epoch 1, batch 44: total loss    0.01258\n",
      "epoch 1, batch 45: total loss    0.01209\n",
      "epoch 1, batch 46: total loss    0.01284\n",
      "epoch 1, batch 47: total loss    0.01334\n",
      "epoch 1, batch 48: total loss    0.01292\n",
      "epoch 1, batch 49: total loss    0.01344\n",
      "epoch 1, batch 50: total loss    0.01286\n",
      "epoch 1, batch 51: total loss    0.01209\n",
      "epoch 1, batch 52: total loss    0.01271\n",
      "epoch 1, batch 53: total loss    0.01282\n",
      "epoch 1, batch 54: total loss    0.01165\n",
      "epoch 1, batch 55: total loss    0.01365\n",
      "epoch 1, batch 56: total loss    0.01381\n",
      "epoch 2, batch 0: total loss    0.01411\n",
      "epoch 2, batch 1: total loss    0.01228\n",
      "epoch 2, batch 2: total loss    0.01131\n",
      "epoch 2, batch 3: total loss    0.01400\n",
      "epoch 2, batch 4: total loss    0.01320\n",
      "epoch 2, batch 5: total loss    0.01268\n",
      "epoch 2, batch 6: total loss    0.01326\n",
      "epoch 2, batch 7: total loss    0.01214\n",
      "epoch 2, batch 8: total loss    0.01239\n",
      "epoch 2, batch 9: total loss    0.01384\n",
      "epoch 2, batch 10: total loss    0.01275\n",
      "epoch 2, batch 11: total loss    0.01299\n",
      "epoch 2, batch 12: total loss    0.01356\n",
      "epoch 2, batch 13: total loss    0.01290\n",
      "epoch 2, batch 14: total loss    0.01190\n",
      "epoch 2, batch 15: total loss    0.01288\n",
      "epoch 2, batch 16: total loss    0.01239\n",
      "epoch 2, batch 17: total loss    0.01201\n",
      "epoch 2, batch 18: total loss    0.01136\n",
      "epoch 2, batch 19: total loss    0.01109\n",
      "epoch 2, batch 20: total loss    0.01212\n",
      "epoch 2, batch 21: total loss    0.01298\n",
      "epoch 2, batch 22: total loss    0.01215\n",
      "epoch 2, batch 23: total loss    0.01221\n",
      "epoch 2, batch 24: total loss    0.01226\n",
      "epoch 2, batch 25: total loss    0.01114\n",
      "epoch 2, batch 26: total loss    0.01151\n",
      "epoch 2, batch 27: total loss    0.01265\n",
      "epoch 2, batch 28: total loss    0.01141\n",
      "epoch 2, batch 29: total loss    0.01245\n",
      "epoch 2, batch 30: total loss    0.01373\n",
      "epoch 2, batch 31: total loss    0.01293\n",
      "epoch 2, batch 32: total loss    0.01122\n",
      "epoch 2, batch 33: total loss    0.01252\n",
      "epoch 2, batch 34: total loss    0.01101\n",
      "epoch 2, batch 35: total loss    0.01175\n",
      "epoch 2, batch 36: total loss    0.01160\n",
      "epoch 2, batch 37: total loss    0.01109\n",
      "epoch 2, batch 38: total loss    0.01058\n",
      "epoch 2, batch 39: total loss    0.01168\n",
      "epoch 2, batch 40: total loss    0.01173\n",
      "epoch 2, batch 41: total loss    0.01303\n",
      "epoch 2, batch 42: total loss    0.01176\n",
      "epoch 2, batch 43: total loss    0.01285\n",
      "epoch 2, batch 44: total loss    0.01229\n",
      "epoch 2, batch 45: total loss    0.01209\n",
      "epoch 2, batch 46: total loss    0.01262\n",
      "epoch 2, batch 47: total loss    0.01091\n",
      "epoch 2, batch 48: total loss    0.01177\n",
      "epoch 2, batch 49: total loss    0.01108\n",
      "epoch 2, batch 50: total loss    0.01158\n",
      "epoch 2, batch 51: total loss    0.01182\n",
      "epoch 2, batch 52: total loss    0.01079\n",
      "epoch 2, batch 53: total loss    0.01196\n",
      "epoch 2, batch 54: total loss    0.01086\n",
      "epoch 2, batch 55: total loss    0.01183\n",
      "epoch 2, batch 56: total loss    0.01160\n",
      "epoch 3, batch 0: total loss    0.01165\n",
      "epoch 3, batch 1: total loss    0.01099\n",
      "epoch 3, batch 2: total loss    0.01028\n",
      "epoch 3, batch 3: total loss    0.01072\n",
      "epoch 3, batch 4: total loss    0.01132\n",
      "epoch 3, batch 5: total loss    0.01085\n",
      "epoch 3, batch 6: total loss    0.01081\n",
      "epoch 3, batch 7: total loss    0.01001\n",
      "epoch 3, batch 8: total loss    0.00958\n",
      "epoch 3, batch 9: total loss    0.00974\n",
      "epoch 3, batch 10: total loss    0.01056\n",
      "epoch 3, batch 11: total loss    0.01137\n",
      "epoch 3, batch 12: total loss    0.01047\n",
      "epoch 3, batch 13: total loss    0.01074\n",
      "epoch 3, batch 14: total loss    0.01034\n",
      "epoch 3, batch 15: total loss    0.01059\n",
      "epoch 3, batch 16: total loss    0.01079\n",
      "epoch 3, batch 17: total loss    0.01048\n",
      "epoch 3, batch 18: total loss    0.00984\n",
      "epoch 3, batch 19: total loss    0.01009\n",
      "epoch 3, batch 20: total loss    0.01101\n",
      "epoch 3, batch 21: total loss    0.01045\n",
      "epoch 3, batch 22: total loss    0.00989\n",
      "epoch 3, batch 23: total loss    0.00992\n",
      "epoch 3, batch 24: total loss    0.00980\n",
      "epoch 3, batch 25: total loss    0.00970\n",
      "epoch 3, batch 26: total loss    0.00946\n",
      "epoch 3, batch 27: total loss    0.00915\n",
      "epoch 3, batch 28: total loss    0.00880\n",
      "epoch 3, batch 29: total loss    0.00879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, batch 30: total loss    0.00987\n",
      "epoch 3, batch 31: total loss    0.00906\n",
      "epoch 3, batch 32: total loss    0.00901\n",
      "epoch 3, batch 33: total loss    0.00938\n",
      "epoch 3, batch 34: total loss    0.00872\n",
      "epoch 3, batch 35: total loss    0.00912\n",
      "epoch 3, batch 36: total loss    0.00808\n",
      "epoch 3, batch 37: total loss    0.00977\n",
      "epoch 3, batch 38: total loss    0.00880\n",
      "epoch 3, batch 39: total loss    0.00755\n",
      "epoch 3, batch 40: total loss    0.00863\n",
      "epoch 3, batch 41: total loss    0.00734\n",
      "epoch 3, batch 42: total loss    0.00985\n",
      "epoch 3, batch 43: total loss    0.00848\n",
      "epoch 3, batch 44: total loss    0.00799\n",
      "epoch 3, batch 45: total loss    0.00824\n",
      "epoch 3, batch 46: total loss    0.00876\n",
      "epoch 3, batch 47: total loss    0.00853\n",
      "epoch 3, batch 48: total loss    0.00752\n",
      "epoch 3, batch 49: total loss    0.00847\n",
      "epoch 3, batch 50: total loss    0.00877\n",
      "epoch 3, batch 51: total loss    0.00867\n",
      "epoch 3, batch 52: total loss    0.00735\n",
      "epoch 3, batch 53: total loss    0.00755\n",
      "epoch 3, batch 54: total loss    0.00782\n",
      "epoch 3, batch 55: total loss    0.00813\n",
      "epoch 3, batch 56: total loss    0.00737\n",
      "epoch 4, batch 0: total loss    0.00731\n",
      "epoch 4, batch 1: total loss    0.00766\n",
      "epoch 4, batch 2: total loss    0.00861\n",
      "epoch 4, batch 3: total loss    0.00858\n",
      "epoch 4, batch 4: total loss    0.00860\n",
      "epoch 4, batch 5: total loss    0.00715\n",
      "epoch 4, batch 6: total loss    0.00785\n",
      "epoch 4, batch 7: total loss    0.00815\n",
      "epoch 4, batch 8: total loss    0.00883\n",
      "epoch 4, batch 9: total loss    0.00768\n",
      "epoch 4, batch 10: total loss    0.00835\n",
      "epoch 4, batch 11: total loss    0.00937\n",
      "epoch 4, batch 12: total loss    0.00789\n",
      "epoch 4, batch 13: total loss    0.00811\n",
      "epoch 4, batch 14: total loss    0.00652\n",
      "epoch 4, batch 15: total loss    0.00762\n",
      "epoch 4, batch 16: total loss    0.00755\n",
      "epoch 4, batch 17: total loss    0.00725\n",
      "epoch 4, batch 18: total loss    0.00748\n",
      "epoch 4, batch 19: total loss    0.00657\n",
      "epoch 4, batch 20: total loss    0.00772\n",
      "epoch 4, batch 21: total loss    0.00678\n",
      "epoch 4, batch 22: total loss    0.00725\n",
      "epoch 4, batch 23: total loss    0.00615\n",
      "epoch 4, batch 24: total loss    0.00757\n",
      "epoch 4, batch 25: total loss    0.00658\n",
      "epoch 4, batch 26: total loss    0.00762\n",
      "epoch 4, batch 27: total loss    0.00635\n",
      "epoch 4, batch 28: total loss    0.00705\n",
      "epoch 4, batch 29: total loss    0.00715\n",
      "epoch 4, batch 30: total loss    0.00684\n",
      "epoch 4, batch 31: total loss    0.00620\n",
      "epoch 4, batch 32: total loss    0.00758\n",
      "epoch 4, batch 33: total loss    0.00661\n",
      "epoch 4, batch 34: total loss    0.00584\n",
      "epoch 4, batch 35: total loss    0.00607\n",
      "epoch 4, batch 36: total loss    0.00628\n",
      "epoch 4, batch 37: total loss    0.00621\n",
      "epoch 4, batch 38: total loss    0.00658\n",
      "epoch 4, batch 39: total loss    0.00613\n",
      "epoch 4, batch 40: total loss    0.00680\n",
      "epoch 4, batch 41: total loss    0.00622\n",
      "epoch 4, batch 42: total loss    0.00611\n",
      "epoch 4, batch 43: total loss    0.00636\n",
      "epoch 4, batch 44: total loss    0.00585\n",
      "epoch 4, batch 45: total loss    0.00631\n",
      "epoch 4, batch 46: total loss    0.00715\n",
      "epoch 4, batch 47: total loss    0.00624\n",
      "epoch 4, batch 48: total loss    0.00603\n",
      "epoch 4, batch 49: total loss    0.00611\n",
      "epoch 4, batch 50: total loss    0.00700\n",
      "epoch 4, batch 51: total loss    0.00606\n",
      "epoch 4, batch 52: total loss    0.00708\n",
      "epoch 4, batch 53: total loss    0.00586\n",
      "epoch 4, batch 54: total loss    0.00665\n",
      "epoch 4, batch 55: total loss    0.00614\n",
      "epoch 4, batch 56: total loss    0.00640\n",
      "epoch 5, batch 0: total loss    0.00571\n",
      "epoch 5, batch 1: total loss    0.00573\n",
      "epoch 5, batch 2: total loss    0.00648\n",
      "epoch 5, batch 3: total loss    0.00617\n",
      "epoch 5, batch 4: total loss    0.00602\n",
      "epoch 5, batch 5: total loss    0.00566\n",
      "epoch 5, batch 6: total loss    0.00737\n",
      "epoch 5, batch 7: total loss    0.00637\n",
      "epoch 5, batch 8: total loss    0.00642\n",
      "epoch 5, batch 9: total loss    0.00682\n",
      "epoch 5, batch 10: total loss    0.00560\n",
      "epoch 5, batch 11: total loss    0.00603\n",
      "epoch 5, batch 12: total loss    0.00570\n",
      "epoch 5, batch 13: total loss    0.00642\n",
      "epoch 5, batch 14: total loss    0.00549\n",
      "epoch 5, batch 15: total loss    0.00594\n",
      "epoch 5, batch 16: total loss    0.00751\n",
      "epoch 5, batch 17: total loss    0.00633\n",
      "epoch 5, batch 18: total loss    0.00559\n",
      "epoch 5, batch 19: total loss    0.00545\n",
      "epoch 5, batch 20: total loss    0.00634\n",
      "epoch 5, batch 21: total loss    0.00608\n",
      "epoch 5, batch 22: total loss    0.00519\n",
      "epoch 5, batch 23: total loss    0.00628\n",
      "epoch 5, batch 24: total loss    0.00614\n",
      "epoch 5, batch 25: total loss    0.00512\n",
      "epoch 5, batch 26: total loss    0.00570\n",
      "epoch 5, batch 27: total loss    0.00542\n",
      "epoch 5, batch 28: total loss    0.00597\n",
      "epoch 5, batch 29: total loss    0.00594\n",
      "epoch 5, batch 30: total loss    0.00639\n",
      "epoch 5, batch 31: total loss    0.00646\n",
      "epoch 5, batch 32: total loss    0.00577\n",
      "epoch 5, batch 33: total loss    0.00528\n",
      "epoch 5, batch 34: total loss    0.00577\n",
      "epoch 5, batch 35: total loss    0.00544\n",
      "epoch 5, batch 36: total loss    0.00531\n",
      "epoch 5, batch 37: total loss    0.00508\n",
      "epoch 5, batch 38: total loss    0.00574\n",
      "epoch 5, batch 39: total loss    0.00534\n",
      "epoch 5, batch 40: total loss    0.00529\n",
      "epoch 5, batch 41: total loss    0.00592\n",
      "epoch 5, batch 42: total loss    0.00627\n",
      "epoch 5, batch 43: total loss    0.00492\n",
      "epoch 5, batch 44: total loss    0.00442\n",
      "epoch 5, batch 45: total loss    0.00566\n",
      "epoch 5, batch 46: total loss    0.00545\n",
      "epoch 5, batch 47: total loss    0.00657\n",
      "epoch 5, batch 48: total loss    0.00528\n",
      "epoch 5, batch 49: total loss    0.00552\n",
      "epoch 5, batch 50: total loss    0.00595\n",
      "epoch 5, batch 51: total loss    0.00555\n",
      "epoch 5, batch 52: total loss    0.00465\n",
      "epoch 5, batch 53: total loss    0.00540\n",
      "epoch 5, batch 54: total loss    0.00534\n",
      "epoch 5, batch 55: total loss    0.00516\n",
      "epoch 5, batch 56: total loss    0.00539\n",
      "epoch 6, batch 0: total loss    0.00470\n",
      "epoch 6, batch 1: total loss    0.00568\n",
      "epoch 6, batch 2: total loss    0.00570\n",
      "epoch 6, batch 3: total loss    0.00468\n",
      "epoch 6, batch 4: total loss    0.00520\n",
      "epoch 6, batch 5: total loss    0.00545\n",
      "epoch 6, batch 6: total loss    0.00582\n",
      "epoch 6, batch 7: total loss    0.00508\n",
      "epoch 6, batch 8: total loss    0.00526\n",
      "epoch 6, batch 9: total loss    0.00467\n",
      "epoch 6, batch 10: total loss    0.00490\n",
      "epoch 6, batch 11: total loss    0.00522\n",
      "epoch 6, batch 12: total loss    0.00401\n",
      "epoch 6, batch 13: total loss    0.00527\n",
      "epoch 6, batch 14: total loss    0.00490\n",
      "epoch 6, batch 15: total loss    0.00439\n",
      "epoch 6, batch 16: total loss    0.00516\n",
      "epoch 6, batch 17: total loss    0.00540\n",
      "epoch 6, batch 18: total loss    0.00594\n",
      "epoch 6, batch 19: total loss    0.00617\n",
      "epoch 6, batch 20: total loss    0.00517\n",
      "epoch 6, batch 21: total loss    0.00441\n",
      "epoch 6, batch 22: total loss    0.00475\n",
      "epoch 6, batch 23: total loss    0.00460\n",
      "epoch 6, batch 24: total loss    0.00563\n",
      "epoch 6, batch 25: total loss    0.00532\n",
      "epoch 6, batch 26: total loss    0.00473\n",
      "epoch 6, batch 27: total loss    0.00512\n",
      "epoch 6, batch 28: total loss    0.00524\n",
      "epoch 6, batch 29: total loss    0.00475\n",
      "epoch 6, batch 30: total loss    0.00511\n",
      "epoch 6, batch 31: total loss    0.00553\n",
      "epoch 6, batch 32: total loss    0.00502\n",
      "epoch 6, batch 33: total loss    0.00550\n",
      "epoch 6, batch 34: total loss    0.00508\n",
      "epoch 6, batch 35: total loss    0.00500\n",
      "epoch 6, batch 36: total loss    0.00488\n",
      "epoch 6, batch 37: total loss    0.00492\n",
      "epoch 6, batch 38: total loss    0.00505\n",
      "epoch 6, batch 39: total loss    0.00510\n",
      "epoch 6, batch 40: total loss    0.00521\n",
      "epoch 6, batch 41: total loss    0.00533\n",
      "epoch 6, batch 42: total loss    0.00449\n",
      "epoch 6, batch 43: total loss    0.00464\n",
      "epoch 6, batch 44: total loss    0.00474\n",
      "epoch 6, batch 45: total loss    0.00474\n",
      "epoch 6, batch 46: total loss    0.00460\n",
      "epoch 6, batch 47: total loss    0.00462\n",
      "epoch 6, batch 48: total loss    0.00529\n",
      "epoch 6, batch 49: total loss    0.00490\n",
      "epoch 6, batch 50: total loss    0.00428\n",
      "epoch 6, batch 51: total loss    0.00425\n",
      "epoch 6, batch 52: total loss    0.00516\n",
      "epoch 6, batch 53: total loss    0.00438\n",
      "epoch 6, batch 54: total loss    0.00458\n",
      "epoch 6, batch 55: total loss    0.00480\n",
      "epoch 6, batch 56: total loss    0.00485\n",
      "epoch 7, batch 0: total loss    0.00485\n",
      "epoch 7, batch 1: total loss    0.00419\n",
      "epoch 7, batch 2: total loss    0.00452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, batch 3: total loss    0.00449\n",
      "epoch 7, batch 4: total loss    0.00520\n",
      "epoch 7, batch 5: total loss    0.00434\n",
      "epoch 7, batch 6: total loss    0.00427\n",
      "epoch 7, batch 7: total loss    0.00422\n",
      "epoch 7, batch 8: total loss    0.00387\n",
      "epoch 7, batch 9: total loss    0.00506\n",
      "epoch 7, batch 10: total loss    0.00510\n",
      "epoch 7, batch 11: total loss    0.00353\n",
      "epoch 7, batch 12: total loss    0.00526\n",
      "epoch 7, batch 13: total loss    0.00453\n",
      "epoch 7, batch 14: total loss    0.00510\n",
      "epoch 7, batch 15: total loss    0.00420\n",
      "epoch 7, batch 16: total loss    0.00540\n",
      "epoch 7, batch 17: total loss    0.00523\n",
      "epoch 7, batch 18: total loss    0.00422\n",
      "epoch 7, batch 19: total loss    0.00501\n",
      "epoch 7, batch 20: total loss    0.00442\n",
      "epoch 7, batch 21: total loss    0.00436\n",
      "epoch 7, batch 22: total loss    0.00490\n",
      "epoch 7, batch 23: total loss    0.00488\n",
      "epoch 7, batch 24: total loss    0.00430\n",
      "epoch 7, batch 25: total loss    0.00469\n",
      "epoch 7, batch 26: total loss    0.00415\n",
      "epoch 7, batch 27: total loss    0.00447\n",
      "epoch 7, batch 28: total loss    0.00386\n",
      "epoch 7, batch 29: total loss    0.00452\n",
      "epoch 7, batch 30: total loss    0.00435\n",
      "epoch 7, batch 31: total loss    0.00408\n",
      "epoch 7, batch 32: total loss    0.00420\n",
      "epoch 7, batch 33: total loss    0.00466\n",
      "epoch 7, batch 34: total loss    0.00552\n",
      "epoch 7, batch 35: total loss    0.00490\n",
      "epoch 7, batch 36: total loss    0.00429\n",
      "epoch 7, batch 37: total loss    0.00467\n",
      "epoch 7, batch 38: total loss    0.00512\n",
      "epoch 7, batch 39: total loss    0.00426\n",
      "epoch 7, batch 40: total loss    0.00426\n",
      "epoch 7, batch 41: total loss    0.00423\n",
      "epoch 7, batch 42: total loss    0.00439\n",
      "epoch 7, batch 43: total loss    0.00459\n",
      "epoch 7, batch 44: total loss    0.00480\n",
      "epoch 7, batch 45: total loss    0.00446\n",
      "epoch 7, batch 46: total loss    0.00417\n",
      "epoch 7, batch 47: total loss    0.00416\n",
      "epoch 7, batch 48: total loss    0.00439\n",
      "epoch 7, batch 49: total loss    0.00461\n",
      "epoch 7, batch 50: total loss    0.00407\n",
      "epoch 7, batch 51: total loss    0.00417\n",
      "epoch 7, batch 52: total loss    0.00394\n",
      "epoch 7, batch 53: total loss    0.00434\n",
      "epoch 7, batch 54: total loss    0.00471\n",
      "epoch 7, batch 55: total loss    0.00475\n",
      "epoch 7, batch 56: total loss    0.00359\n",
      "epoch 8, batch 0: total loss    0.00369\n",
      "epoch 8, batch 1: total loss    0.00360\n",
      "epoch 8, batch 2: total loss    0.00495\n",
      "epoch 8, batch 3: total loss    0.00413\n",
      "epoch 8, batch 4: total loss    0.00425\n",
      "epoch 8, batch 5: total loss    0.00463\n",
      "epoch 8, batch 6: total loss    0.00407\n",
      "epoch 8, batch 7: total loss    0.00386\n",
      "epoch 8, batch 8: total loss    0.00428\n",
      "epoch 8, batch 9: total loss    0.00333\n",
      "epoch 8, batch 10: total loss    0.00366\n",
      "epoch 8, batch 11: total loss    0.00479\n",
      "epoch 8, batch 12: total loss    0.00405\n",
      "epoch 8, batch 13: total loss    0.00353\n",
      "epoch 8, batch 14: total loss    0.00378\n",
      "epoch 8, batch 15: total loss    0.00458\n",
      "epoch 8, batch 16: total loss    0.00448\n",
      "epoch 8, batch 17: total loss    0.00380\n",
      "epoch 8, batch 18: total loss    0.00377\n",
      "epoch 8, batch 19: total loss    0.00372\n",
      "epoch 8, batch 20: total loss    0.00385\n",
      "epoch 8, batch 21: total loss    0.00415\n",
      "epoch 8, batch 22: total loss    0.00343\n",
      "epoch 8, batch 23: total loss    0.00402\n",
      "epoch 8, batch 24: total loss    0.00359\n",
      "epoch 8, batch 25: total loss    0.00423\n",
      "epoch 8, batch 26: total loss    0.00346\n",
      "epoch 8, batch 27: total loss    0.00406\n",
      "epoch 8, batch 28: total loss    0.00394\n",
      "epoch 8, batch 29: total loss    0.00397\n",
      "epoch 8, batch 30: total loss    0.00436\n",
      "epoch 8, batch 31: total loss    0.00448\n",
      "epoch 8, batch 32: total loss    0.00321\n",
      "epoch 8, batch 33: total loss    0.00406\n",
      "epoch 8, batch 34: total loss    0.00398\n",
      "epoch 8, batch 35: total loss    0.00323\n",
      "epoch 8, batch 36: total loss    0.00357\n",
      "epoch 8, batch 37: total loss    0.00397\n",
      "epoch 8, batch 38: total loss    0.00377\n",
      "epoch 8, batch 39: total loss    0.00367\n",
      "epoch 8, batch 40: total loss    0.00485\n",
      "epoch 8, batch 41: total loss    0.00406\n",
      "epoch 8, batch 42: total loss    0.00404\n",
      "epoch 8, batch 43: total loss    0.00326\n",
      "epoch 8, batch 44: total loss    0.00367\n",
      "epoch 8, batch 45: total loss    0.00400\n",
      "epoch 8, batch 46: total loss    0.00378\n",
      "epoch 8, batch 47: total loss    0.00380\n",
      "epoch 8, batch 48: total loss    0.00398\n",
      "epoch 8, batch 49: total loss    0.00426\n",
      "epoch 8, batch 50: total loss    0.00464\n",
      "epoch 8, batch 51: total loss    0.00396\n",
      "epoch 8, batch 52: total loss    0.00368\n",
      "epoch 8, batch 53: total loss    0.00397\n",
      "epoch 8, batch 54: total loss    0.00387\n",
      "epoch 8, batch 55: total loss    0.00383\n",
      "epoch 8, batch 56: total loss    0.00359\n",
      "epoch 9, batch 0: total loss    0.00380\n",
      "epoch 9, batch 1: total loss    0.00423\n",
      "epoch 9, batch 2: total loss    0.00395\n",
      "epoch 9, batch 3: total loss    0.00402\n",
      "epoch 9, batch 4: total loss    0.00377\n",
      "epoch 9, batch 5: total loss    0.00351\n",
      "epoch 9, batch 6: total loss    0.00405\n",
      "epoch 9, batch 7: total loss    0.00412\n",
      "epoch 9, batch 8: total loss    0.00338\n",
      "epoch 9, batch 9: total loss    0.00353\n",
      "epoch 9, batch 10: total loss    0.00343\n",
      "epoch 9, batch 11: total loss    0.00478\n",
      "epoch 9, batch 12: total loss    0.00359\n",
      "epoch 9, batch 13: total loss    0.00348\n",
      "epoch 9, batch 14: total loss    0.00362\n",
      "epoch 9, batch 15: total loss    0.00363\n",
      "epoch 9, batch 16: total loss    0.00429\n",
      "epoch 9, batch 17: total loss    0.00326\n",
      "epoch 9, batch 18: total loss    0.00306\n",
      "epoch 9, batch 19: total loss    0.00368\n",
      "epoch 9, batch 20: total loss    0.00356\n",
      "epoch 9, batch 21: total loss    0.00384\n",
      "epoch 9, batch 22: total loss    0.00376\n",
      "epoch 9, batch 23: total loss    0.00404\n",
      "epoch 9, batch 24: total loss    0.00397\n",
      "epoch 9, batch 25: total loss    0.00364\n",
      "epoch 9, batch 26: total loss    0.00316\n",
      "epoch 9, batch 27: total loss    0.00360\n",
      "epoch 9, batch 28: total loss    0.00392\n",
      "epoch 9, batch 29: total loss    0.00345\n",
      "epoch 9, batch 30: total loss    0.00318\n",
      "epoch 9, batch 31: total loss    0.00324\n",
      "epoch 9, batch 32: total loss    0.00349\n",
      "epoch 9, batch 33: total loss    0.00317\n",
      "epoch 9, batch 34: total loss    0.00353\n",
      "epoch 9, batch 35: total loss    0.00335\n",
      "epoch 9, batch 36: total loss    0.00409\n",
      "epoch 9, batch 37: total loss    0.00401\n",
      "epoch 9, batch 38: total loss    0.00364\n",
      "epoch 9, batch 39: total loss    0.00334\n",
      "epoch 9, batch 40: total loss    0.00420\n",
      "epoch 9, batch 41: total loss    0.00349\n",
      "epoch 9, batch 42: total loss    0.00437\n",
      "epoch 9, batch 43: total loss    0.00362\n",
      "epoch 9, batch 44: total loss    0.00341\n",
      "epoch 9, batch 45: total loss    0.00294\n",
      "epoch 9, batch 46: total loss    0.00311\n",
      "epoch 9, batch 47: total loss    0.00294\n",
      "epoch 9, batch 48: total loss    0.00323\n",
      "epoch 9, batch 49: total loss    0.00343\n",
      "epoch 9, batch 50: total loss    0.00294\n",
      "epoch 9, batch 51: total loss    0.00325\n",
      "epoch 9, batch 52: total loss    0.00393\n",
      "epoch 9, batch 53: total loss    0.00307\n",
      "epoch 9, batch 54: total loss    0.00305\n",
      "epoch 9, batch 55: total loss    0.00355\n",
      "epoch 9, batch 56: total loss    0.00348\n",
      "epoch 10, batch 0: total loss    0.00389\n",
      "epoch 10, batch 1: total loss    0.00420\n",
      "epoch 10, batch 2: total loss    0.00324\n",
      "epoch 10, batch 3: total loss    0.00389\n",
      "epoch 10, batch 4: total loss    0.00312\n",
      "epoch 10, batch 5: total loss    0.00295\n",
      "epoch 10, batch 6: total loss    0.00282\n",
      "epoch 10, batch 7: total loss    0.00227\n",
      "epoch 10, batch 8: total loss    0.00296\n",
      "epoch 10, batch 9: total loss    0.00281\n",
      "epoch 10, batch 10: total loss    0.00285\n",
      "epoch 10, batch 11: total loss    0.00339\n",
      "epoch 10, batch 12: total loss    0.00307\n",
      "epoch 10, batch 13: total loss    0.00335\n",
      "epoch 10, batch 14: total loss    0.00307\n",
      "epoch 10, batch 15: total loss    0.00338\n",
      "epoch 10, batch 16: total loss    0.00308\n",
      "epoch 10, batch 17: total loss    0.00337\n",
      "epoch 10, batch 18: total loss    0.00304\n",
      "epoch 10, batch 19: total loss    0.00272\n",
      "epoch 10, batch 20: total loss    0.00316\n",
      "epoch 10, batch 21: total loss    0.00350\n",
      "epoch 10, batch 22: total loss    0.00339\n",
      "epoch 10, batch 23: total loss    0.00336\n",
      "epoch 10, batch 24: total loss    0.00261\n",
      "epoch 10, batch 25: total loss    0.00267\n",
      "epoch 10, batch 26: total loss    0.00338\n",
      "epoch 10, batch 27: total loss    0.00367\n",
      "epoch 10, batch 28: total loss    0.00306\n",
      "epoch 10, batch 29: total loss    0.00385\n",
      "epoch 10, batch 30: total loss    0.00339\n",
      "epoch 10, batch 31: total loss    0.00373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, batch 32: total loss    0.00326\n",
      "epoch 10, batch 33: total loss    0.00367\n",
      "epoch 10, batch 34: total loss    0.00372\n",
      "epoch 10, batch 35: total loss    0.00373\n",
      "epoch 10, batch 36: total loss    0.00291\n",
      "epoch 10, batch 37: total loss    0.00389\n",
      "epoch 10, batch 38: total loss    0.00344\n",
      "epoch 10, batch 39: total loss    0.00324\n",
      "epoch 10, batch 40: total loss    0.00369\n",
      "epoch 10, batch 41: total loss    0.00316\n",
      "epoch 10, batch 42: total loss    0.00278\n",
      "epoch 10, batch 43: total loss    0.00290\n",
      "epoch 10, batch 44: total loss    0.00314\n",
      "epoch 10, batch 45: total loss    0.00334\n",
      "epoch 10, batch 46: total loss    0.00318\n",
      "epoch 10, batch 47: total loss    0.00295\n",
      "epoch 10, batch 48: total loss    0.00310\n",
      "epoch 10, batch 49: total loss    0.00353\n",
      "epoch 10, batch 50: total loss    0.00322\n",
      "epoch 10, batch 51: total loss    0.00259\n",
      "epoch 10, batch 52: total loss    0.00251\n",
      "epoch 10, batch 53: total loss    0.00286\n",
      "epoch 10, batch 54: total loss    0.00378\n",
      "epoch 10, batch 55: total loss    0.00307\n",
      "epoch 10, batch 56: total loss    0.00333\n",
      "epoch 11, batch 0: total loss    0.00280\n",
      "epoch 11, batch 1: total loss    0.00380\n",
      "epoch 11, batch 2: total loss    0.00326\n",
      "epoch 11, batch 3: total loss    0.00298\n",
      "epoch 11, batch 4: total loss    0.00265\n",
      "epoch 11, batch 5: total loss    0.00234\n",
      "epoch 11, batch 6: total loss    0.00273\n",
      "epoch 11, batch 7: total loss    0.00399\n",
      "epoch 11, batch 8: total loss    0.00337\n",
      "epoch 11, batch 9: total loss    0.00321\n",
      "epoch 11, batch 10: total loss    0.00279\n",
      "epoch 11, batch 11: total loss    0.00357\n",
      "epoch 11, batch 12: total loss    0.00323\n",
      "epoch 11, batch 13: total loss    0.00296\n",
      "epoch 11, batch 14: total loss    0.00357\n",
      "epoch 11, batch 15: total loss    0.00304\n",
      "epoch 11, batch 16: total loss    0.00242\n",
      "epoch 11, batch 17: total loss    0.00355\n",
      "epoch 11, batch 18: total loss    0.00298\n",
      "epoch 11, batch 19: total loss    0.00291\n",
      "epoch 11, batch 20: total loss    0.00291\n",
      "epoch 11, batch 21: total loss    0.00299\n",
      "epoch 11, batch 22: total loss    0.00347\n",
      "epoch 11, batch 23: total loss    0.00288\n",
      "epoch 11, batch 24: total loss    0.00297\n",
      "epoch 11, batch 25: total loss    0.00268\n",
      "epoch 11, batch 26: total loss    0.00266\n",
      "epoch 11, batch 27: total loss    0.00262\n",
      "epoch 11, batch 28: total loss    0.00268\n",
      "epoch 11, batch 29: total loss    0.00321\n",
      "epoch 11, batch 30: total loss    0.00285\n",
      "epoch 11, batch 31: total loss    0.00257\n",
      "epoch 11, batch 32: total loss    0.00286\n",
      "epoch 11, batch 33: total loss    0.00308\n",
      "epoch 11, batch 34: total loss    0.00321\n",
      "epoch 11, batch 35: total loss    0.00271\n",
      "epoch 11, batch 36: total loss    0.00309\n",
      "epoch 11, batch 37: total loss    0.00276\n",
      "epoch 11, batch 38: total loss    0.00242\n",
      "epoch 11, batch 39: total loss    0.00314\n",
      "epoch 11, batch 40: total loss    0.00351\n",
      "epoch 11, batch 41: total loss    0.00360\n",
      "epoch 11, batch 42: total loss    0.00338\n",
      "epoch 11, batch 43: total loss    0.00361\n",
      "epoch 11, batch 44: total loss    0.00317\n",
      "epoch 11, batch 45: total loss    0.00309\n",
      "epoch 11, batch 46: total loss    0.00293\n",
      "epoch 11, batch 47: total loss    0.00291\n",
      "epoch 11, batch 48: total loss    0.00282\n",
      "epoch 11, batch 49: total loss    0.00301\n",
      "epoch 11, batch 50: total loss    0.00215\n",
      "epoch 11, batch 51: total loss    0.00325\n",
      "epoch 11, batch 52: total loss    0.00345\n",
      "epoch 11, batch 53: total loss    0.00298\n",
      "epoch 11, batch 54: total loss    0.00278\n",
      "epoch 11, batch 55: total loss    0.00336\n",
      "epoch 11, batch 56: total loss    0.00316\n",
      "epoch 12, batch 0: total loss    0.00249\n",
      "epoch 12, batch 1: total loss    0.00306\n",
      "epoch 12, batch 2: total loss    0.00290\n",
      "epoch 12, batch 3: total loss    0.00327\n",
      "epoch 12, batch 4: total loss    0.00292\n",
      "epoch 12, batch 5: total loss    0.00344\n",
      "epoch 12, batch 6: total loss    0.00279\n",
      "epoch 12, batch 7: total loss    0.00306\n",
      "epoch 12, batch 8: total loss    0.00370\n",
      "epoch 12, batch 9: total loss    0.00280\n",
      "epoch 12, batch 10: total loss    0.00272\n",
      "epoch 12, batch 11: total loss    0.00302\n",
      "epoch 12, batch 12: total loss    0.00310\n",
      "epoch 12, batch 13: total loss    0.00337\n",
      "epoch 12, batch 14: total loss    0.00297\n",
      "epoch 12, batch 15: total loss    0.00341\n",
      "epoch 12, batch 16: total loss    0.00259\n",
      "epoch 12, batch 17: total loss    0.00256\n",
      "epoch 12, batch 18: total loss    0.00232\n",
      "epoch 12, batch 19: total loss    0.00231\n",
      "epoch 12, batch 20: total loss    0.00267\n",
      "epoch 12, batch 21: total loss    0.00308\n",
      "epoch 12, batch 22: total loss    0.00241\n",
      "epoch 12, batch 23: total loss    0.00271\n",
      "epoch 12, batch 24: total loss    0.00278\n",
      "epoch 12, batch 25: total loss    0.00278\n",
      "epoch 12, batch 26: total loss    0.00224\n",
      "epoch 12, batch 27: total loss    0.00284\n",
      "epoch 12, batch 28: total loss    0.00253\n",
      "epoch 12, batch 29: total loss    0.00266\n",
      "epoch 12, batch 30: total loss    0.00238\n",
      "epoch 12, batch 31: total loss    0.00283\n",
      "epoch 12, batch 32: total loss    0.00245\n",
      "epoch 12, batch 33: total loss    0.00212\n",
      "epoch 12, batch 34: total loss    0.00239\n",
      "epoch 12, batch 35: total loss    0.00306\n",
      "epoch 12, batch 36: total loss    0.00332\n",
      "epoch 12, batch 37: total loss    0.00264\n",
      "epoch 12, batch 38: total loss    0.00264\n",
      "epoch 12, batch 39: total loss    0.00250\n",
      "epoch 12, batch 40: total loss    0.00262\n",
      "epoch 12, batch 41: total loss    0.00227\n",
      "epoch 12, batch 42: total loss    0.00278\n",
      "epoch 12, batch 43: total loss    0.00263\n",
      "epoch 12, batch 44: total loss    0.00280\n",
      "epoch 12, batch 45: total loss    0.00290\n",
      "epoch 12, batch 46: total loss    0.00273\n",
      "epoch 12, batch 47: total loss    0.00238\n",
      "epoch 12, batch 48: total loss    0.00249\n",
      "epoch 12, batch 49: total loss    0.00264\n",
      "epoch 12, batch 50: total loss    0.00333\n",
      "epoch 12, batch 51: total loss    0.00256\n",
      "epoch 12, batch 52: total loss    0.00268\n",
      "epoch 12, batch 53: total loss    0.00203\n",
      "epoch 12, batch 54: total loss    0.00271\n",
      "epoch 12, batch 55: total loss    0.00231\n",
      "epoch 12, batch 56: total loss    0.00236\n",
      "epoch 13, batch 0: total loss    0.00257\n",
      "epoch 13, batch 1: total loss    0.00284\n",
      "epoch 13, batch 2: total loss    0.00354\n",
      "epoch 13, batch 3: total loss    0.00273\n",
      "epoch 13, batch 4: total loss    0.00278\n",
      "epoch 13, batch 5: total loss    0.00240\n",
      "epoch 13, batch 6: total loss    0.00290\n",
      "epoch 13, batch 7: total loss    0.00273\n",
      "epoch 13, batch 8: total loss    0.00212\n",
      "epoch 13, batch 9: total loss    0.00272\n",
      "epoch 13, batch 10: total loss    0.00225\n",
      "epoch 13, batch 11: total loss    0.00274\n",
      "epoch 13, batch 12: total loss    0.00310\n",
      "epoch 13, batch 13: total loss    0.00256\n",
      "epoch 13, batch 14: total loss    0.00277\n",
      "epoch 13, batch 15: total loss    0.00266\n",
      "epoch 13, batch 16: total loss    0.00274\n",
      "epoch 13, batch 17: total loss    0.00285\n",
      "epoch 13, batch 18: total loss    0.00248\n",
      "epoch 13, batch 19: total loss    0.00251\n",
      "epoch 13, batch 20: total loss    0.00252\n",
      "epoch 13, batch 21: total loss    0.00313\n",
      "epoch 13, batch 22: total loss    0.00227\n",
      "epoch 13, batch 23: total loss    0.00260\n",
      "epoch 13, batch 24: total loss    0.00336\n",
      "epoch 13, batch 25: total loss    0.00250\n",
      "epoch 13, batch 26: total loss    0.00276\n",
      "epoch 13, batch 27: total loss    0.00258\n",
      "epoch 13, batch 28: total loss    0.00279\n",
      "epoch 13, batch 29: total loss    0.00225\n",
      "epoch 13, batch 30: total loss    0.00242\n",
      "epoch 13, batch 31: total loss    0.00256\n",
      "epoch 13, batch 32: total loss    0.00205\n",
      "epoch 13, batch 33: total loss    0.00188\n",
      "epoch 13, batch 34: total loss    0.00262\n",
      "epoch 13, batch 35: total loss    0.00266\n",
      "epoch 13, batch 36: total loss    0.00237\n",
      "epoch 13, batch 37: total loss    0.00259\n",
      "epoch 13, batch 38: total loss    0.00279\n",
      "epoch 13, batch 39: total loss    0.00277\n",
      "epoch 13, batch 40: total loss    0.00272\n",
      "epoch 13, batch 41: total loss    0.00267\n",
      "epoch 13, batch 42: total loss    0.00270\n",
      "epoch 13, batch 43: total loss    0.00236\n",
      "epoch 13, batch 44: total loss    0.00237\n",
      "epoch 13, batch 45: total loss    0.00225\n",
      "epoch 13, batch 46: total loss    0.00350\n",
      "epoch 13, batch 47: total loss    0.00354\n",
      "epoch 13, batch 48: total loss    0.00276\n",
      "epoch 13, batch 49: total loss    0.00316\n",
      "epoch 13, batch 50: total loss    0.00300\n",
      "epoch 13, batch 51: total loss    0.00232\n",
      "epoch 13, batch 52: total loss    0.00280\n",
      "epoch 13, batch 53: total loss    0.00302\n",
      "epoch 13, batch 54: total loss    0.00230\n",
      "epoch 13, batch 55: total loss    0.00250\n",
      "epoch 13, batch 56: total loss    0.00265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, batch 0: total loss    0.00244\n",
      "epoch 14, batch 1: total loss    0.00226\n",
      "epoch 14, batch 2: total loss    0.00265\n",
      "epoch 14, batch 3: total loss    0.00277\n",
      "epoch 14, batch 4: total loss    0.00222\n",
      "epoch 14, batch 5: total loss    0.00226\n",
      "epoch 14, batch 6: total loss    0.00208\n",
      "epoch 14, batch 7: total loss    0.00260\n",
      "epoch 14, batch 8: total loss    0.00277\n",
      "epoch 14, batch 9: total loss    0.00269\n",
      "epoch 14, batch 10: total loss    0.00270\n",
      "epoch 14, batch 11: total loss    0.00224\n",
      "epoch 14, batch 12: total loss    0.00266\n",
      "epoch 14, batch 13: total loss    0.00214\n",
      "epoch 14, batch 14: total loss    0.00247\n",
      "epoch 14, batch 15: total loss    0.00235\n",
      "epoch 14, batch 16: total loss    0.00265\n",
      "epoch 14, batch 17: total loss    0.00228\n",
      "epoch 14, batch 18: total loss    0.00243\n",
      "epoch 14, batch 19: total loss    0.00278\n",
      "epoch 14, batch 20: total loss    0.00283\n",
      "epoch 14, batch 21: total loss    0.00289\n",
      "epoch 14, batch 22: total loss    0.00277\n",
      "epoch 14, batch 23: total loss    0.00251\n",
      "epoch 14, batch 24: total loss    0.00204\n",
      "epoch 14, batch 25: total loss    0.00260\n",
      "epoch 14, batch 26: total loss    0.00231\n",
      "epoch 14, batch 27: total loss    0.00195\n",
      "epoch 14, batch 28: total loss    0.00216\n",
      "epoch 14, batch 29: total loss    0.00249\n",
      "epoch 14, batch 30: total loss    0.00285\n",
      "epoch 14, batch 31: total loss    0.00238\n",
      "epoch 14, batch 32: total loss    0.00236\n",
      "epoch 14, batch 33: total loss    0.00222\n",
      "epoch 14, batch 34: total loss    0.00222\n",
      "epoch 14, batch 35: total loss    0.00257\n",
      "epoch 14, batch 36: total loss    0.00291\n",
      "epoch 14, batch 37: total loss    0.00240\n",
      "epoch 14, batch 38: total loss    0.00236\n",
      "epoch 14, batch 39: total loss    0.00236\n",
      "epoch 14, batch 40: total loss    0.00213\n",
      "epoch 14, batch 41: total loss    0.00226\n",
      "epoch 14, batch 42: total loss    0.00202\n",
      "epoch 14, batch 43: total loss    0.00237\n",
      "epoch 14, batch 44: total loss    0.00249\n",
      "epoch 14, batch 45: total loss    0.00232\n",
      "epoch 14, batch 46: total loss    0.00226\n",
      "epoch 14, batch 47: total loss    0.00291\n",
      "epoch 14, batch 48: total loss    0.00240\n",
      "epoch 14, batch 49: total loss    0.00194\n",
      "epoch 14, batch 50: total loss    0.00260\n",
      "epoch 14, batch 51: total loss    0.00213\n",
      "epoch 14, batch 52: total loss    0.00192\n",
      "epoch 14, batch 53: total loss    0.00205\n",
      "epoch 14, batch 54: total loss    0.00239\n",
      "epoch 14, batch 55: total loss    0.00230\n",
      "epoch 14, batch 56: total loss    0.00243\n",
      "epoch 15, batch 0: total loss    0.00188\n",
      "epoch 15, batch 1: total loss    0.00178\n",
      "epoch 15, batch 2: total loss    0.00188\n",
      "epoch 15, batch 3: total loss    0.00238\n",
      "epoch 15, batch 4: total loss    0.00216\n",
      "epoch 15, batch 5: total loss    0.00260\n",
      "epoch 15, batch 6: total loss    0.00160\n",
      "epoch 15, batch 7: total loss    0.00212\n",
      "epoch 15, batch 8: total loss    0.00249\n",
      "epoch 15, batch 9: total loss    0.00218\n",
      "epoch 15, batch 10: total loss    0.00214\n",
      "epoch 15, batch 11: total loss    0.00200\n",
      "epoch 15, batch 12: total loss    0.00249\n",
      "epoch 15, batch 13: total loss    0.00237\n",
      "epoch 15, batch 14: total loss    0.00244\n",
      "epoch 15, batch 15: total loss    0.00222\n",
      "epoch 15, batch 16: total loss    0.00245\n",
      "epoch 15, batch 17: total loss    0.00219\n",
      "epoch 15, batch 18: total loss    0.00218\n",
      "epoch 15, batch 19: total loss    0.00276\n",
      "epoch 15, batch 20: total loss    0.00228\n",
      "epoch 15, batch 21: total loss    0.00278\n",
      "epoch 15, batch 22: total loss    0.00220\n",
      "epoch 15, batch 23: total loss    0.00213\n",
      "epoch 15, batch 24: total loss    0.00217\n",
      "epoch 15, batch 25: total loss    0.00227\n",
      "epoch 15, batch 26: total loss    0.00180\n",
      "epoch 15, batch 27: total loss    0.00202\n",
      "epoch 15, batch 28: total loss    0.00185\n",
      "epoch 15, batch 29: total loss    0.00193\n",
      "epoch 15, batch 30: total loss    0.00209\n",
      "epoch 15, batch 31: total loss    0.00204\n",
      "epoch 15, batch 32: total loss    0.00204\n",
      "epoch 15, batch 33: total loss    0.00231\n",
      "epoch 15, batch 34: total loss    0.00190\n",
      "epoch 15, batch 35: total loss    0.00243\n",
      "epoch 15, batch 36: total loss    0.00281\n",
      "epoch 15, batch 37: total loss    0.00198\n",
      "epoch 15, batch 38: total loss    0.00173\n",
      "epoch 15, batch 39: total loss    0.00242\n",
      "epoch 15, batch 40: total loss    0.00241\n",
      "epoch 15, batch 41: total loss    0.00212\n",
      "epoch 15, batch 42: total loss    0.00197\n",
      "epoch 15, batch 43: total loss    0.00146\n",
      "epoch 15, batch 44: total loss    0.00220\n",
      "epoch 15, batch 45: total loss    0.00223\n",
      "epoch 15, batch 46: total loss    0.00242\n",
      "epoch 15, batch 47: total loss    0.00210\n",
      "epoch 15, batch 48: total loss    0.00249\n",
      "epoch 15, batch 49: total loss    0.00260\n",
      "epoch 15, batch 50: total loss    0.00295\n",
      "epoch 15, batch 51: total loss    0.00244\n",
      "epoch 15, batch 52: total loss    0.00211\n",
      "epoch 15, batch 53: total loss    0.00232\n",
      "epoch 15, batch 54: total loss    0.00237\n",
      "epoch 15, batch 55: total loss    0.00226\n",
      "epoch 15, batch 56: total loss    0.00222\n",
      "epoch 16, batch 0: total loss    0.00207\n",
      "epoch 16, batch 1: total loss    0.00205\n",
      "epoch 16, batch 2: total loss    0.00212\n",
      "epoch 16, batch 3: total loss    0.00189\n",
      "epoch 16, batch 4: total loss    0.00242\n",
      "epoch 16, batch 5: total loss    0.00208\n",
      "epoch 16, batch 6: total loss    0.00213\n",
      "epoch 16, batch 7: total loss    0.00208\n",
      "epoch 16, batch 8: total loss    0.00178\n",
      "epoch 16, batch 9: total loss    0.00220\n",
      "epoch 16, batch 10: total loss    0.00209\n",
      "epoch 16, batch 11: total loss    0.00149\n",
      "epoch 16, batch 12: total loss    0.00257\n",
      "epoch 16, batch 13: total loss    0.00270\n",
      "epoch 16, batch 14: total loss    0.00189\n",
      "epoch 16, batch 15: total loss    0.00198\n",
      "epoch 16, batch 16: total loss    0.00202\n",
      "epoch 16, batch 17: total loss    0.00182\n",
      "epoch 16, batch 18: total loss    0.00172\n",
      "epoch 16, batch 19: total loss    0.00226\n",
      "epoch 16, batch 20: total loss    0.00183\n",
      "epoch 16, batch 21: total loss    0.00157\n",
      "epoch 16, batch 22: total loss    0.00181\n",
      "epoch 16, batch 23: total loss    0.00182\n",
      "epoch 16, batch 24: total loss    0.00162\n",
      "epoch 16, batch 25: total loss    0.00176\n",
      "epoch 16, batch 26: total loss    0.00206\n",
      "epoch 16, batch 27: total loss    0.00253\n",
      "epoch 16, batch 28: total loss    0.00193\n",
      "epoch 16, batch 29: total loss    0.00205\n",
      "epoch 16, batch 30: total loss    0.00195\n",
      "epoch 16, batch 31: total loss    0.00215\n",
      "epoch 16, batch 32: total loss    0.00245\n",
      "epoch 16, batch 33: total loss    0.00233\n",
      "epoch 16, batch 34: total loss    0.00209\n",
      "epoch 16, batch 35: total loss    0.00254\n",
      "epoch 16, batch 36: total loss    0.00210\n",
      "epoch 16, batch 37: total loss    0.00181\n",
      "epoch 16, batch 38: total loss    0.00192\n",
      "epoch 16, batch 39: total loss    0.00211\n",
      "epoch 16, batch 40: total loss    0.00227\n",
      "epoch 16, batch 41: total loss    0.00164\n",
      "epoch 16, batch 42: total loss    0.00201\n",
      "epoch 16, batch 43: total loss    0.00192\n",
      "epoch 16, batch 44: total loss    0.00186\n",
      "epoch 16, batch 45: total loss    0.00178\n",
      "epoch 16, batch 46: total loss    0.00189\n",
      "epoch 16, batch 47: total loss    0.00181\n",
      "epoch 16, batch 48: total loss    0.00210\n",
      "epoch 16, batch 49: total loss    0.00165\n",
      "epoch 16, batch 50: total loss    0.00216\n",
      "epoch 16, batch 51: total loss    0.00213\n",
      "epoch 16, batch 52: total loss    0.00194\n",
      "epoch 16, batch 53: total loss    0.00246\n",
      "epoch 16, batch 54: total loss    0.00205\n",
      "epoch 16, batch 55: total loss    0.00219\n",
      "epoch 16, batch 56: total loss    0.00243\n",
      "epoch 17, batch 0: total loss    0.00206\n",
      "epoch 17, batch 1: total loss    0.00198\n",
      "epoch 17, batch 2: total loss    0.00187\n",
      "epoch 17, batch 3: total loss    0.00164\n",
      "epoch 17, batch 4: total loss    0.00178\n",
      "epoch 17, batch 5: total loss    0.00225\n",
      "epoch 17, batch 6: total loss    0.00168\n",
      "epoch 17, batch 7: total loss    0.00146\n",
      "epoch 17, batch 8: total loss    0.00233\n",
      "epoch 17, batch 9: total loss    0.00170\n",
      "epoch 17, batch 10: total loss    0.00222\n",
      "epoch 17, batch 11: total loss    0.00183\n",
      "epoch 17, batch 12: total loss    0.00250\n",
      "epoch 17, batch 13: total loss    0.00208\n",
      "epoch 17, batch 14: total loss    0.00170\n",
      "epoch 17, batch 15: total loss    0.00148\n",
      "epoch 17, batch 16: total loss    0.00173\n",
      "epoch 17, batch 17: total loss    0.00160\n",
      "epoch 17, batch 18: total loss    0.00143\n",
      "epoch 17, batch 19: total loss    0.00186\n",
      "epoch 17, batch 20: total loss    0.00203\n",
      "epoch 17, batch 21: total loss    0.00176\n",
      "epoch 17, batch 22: total loss    0.00222\n",
      "epoch 17, batch 23: total loss    0.00232\n",
      "epoch 17, batch 24: total loss    0.00205\n",
      "epoch 17, batch 25: total loss    0.00158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, batch 26: total loss    0.00206\n",
      "epoch 17, batch 27: total loss    0.00216\n",
      "epoch 17, batch 28: total loss    0.00176\n",
      "epoch 17, batch 29: total loss    0.00195\n",
      "epoch 17, batch 30: total loss    0.00193\n",
      "epoch 17, batch 31: total loss    0.00235\n",
      "epoch 17, batch 32: total loss    0.00189\n",
      "epoch 17, batch 33: total loss    0.00207\n",
      "epoch 17, batch 34: total loss    0.00200\n",
      "epoch 17, batch 35: total loss    0.00191\n",
      "epoch 17, batch 36: total loss    0.00194\n",
      "epoch 17, batch 37: total loss    0.00188\n",
      "epoch 17, batch 38: total loss    0.00211\n",
      "epoch 17, batch 39: total loss    0.00184\n",
      "epoch 17, batch 40: total loss    0.00176\n",
      "epoch 17, batch 41: total loss    0.00194\n",
      "epoch 17, batch 42: total loss    0.00231\n",
      "epoch 17, batch 43: total loss    0.00222\n",
      "epoch 17, batch 44: total loss    0.00201\n",
      "epoch 17, batch 45: total loss    0.00238\n",
      "epoch 17, batch 46: total loss    0.00200\n",
      "epoch 17, batch 47: total loss    0.00163\n",
      "epoch 17, batch 48: total loss    0.00164\n",
      "epoch 17, batch 49: total loss    0.00227\n",
      "epoch 17, batch 50: total loss    0.00200\n",
      "epoch 17, batch 51: total loss    0.00234\n",
      "epoch 17, batch 52: total loss    0.00217\n",
      "epoch 17, batch 53: total loss    0.00213\n",
      "epoch 17, batch 54: total loss    0.00163\n",
      "epoch 17, batch 55: total loss    0.00168\n",
      "epoch 17, batch 56: total loss    0.00199\n",
      "epoch 18, batch 0: total loss    0.00187\n",
      "epoch 18, batch 1: total loss    0.00216\n",
      "epoch 18, batch 2: total loss    0.00230\n",
      "epoch 18, batch 3: total loss    0.00213\n",
      "epoch 18, batch 4: total loss    0.00240\n",
      "epoch 18, batch 5: total loss    0.00206\n",
      "epoch 18, batch 6: total loss    0.00206\n",
      "epoch 18, batch 7: total loss    0.00204\n",
      "epoch 18, batch 8: total loss    0.00185\n",
      "epoch 18, batch 9: total loss    0.00171\n",
      "epoch 18, batch 10: total loss    0.00187\n",
      "epoch 18, batch 11: total loss    0.00245\n",
      "epoch 18, batch 12: total loss    0.00217\n",
      "epoch 18, batch 13: total loss    0.00206\n",
      "epoch 18, batch 14: total loss    0.00185\n",
      "epoch 18, batch 15: total loss    0.00172\n",
      "epoch 18, batch 16: total loss    0.00244\n",
      "epoch 18, batch 17: total loss    0.00210\n",
      "epoch 18, batch 18: total loss    0.00202\n",
      "epoch 18, batch 19: total loss    0.00196\n",
      "epoch 18, batch 20: total loss    0.00195\n",
      "epoch 18, batch 21: total loss    0.00219\n",
      "epoch 18, batch 22: total loss    0.00213\n",
      "epoch 18, batch 23: total loss    0.00178\n",
      "epoch 18, batch 24: total loss    0.00197\n",
      "epoch 18, batch 25: total loss    0.00201\n",
      "epoch 18, batch 26: total loss    0.00157\n",
      "epoch 18, batch 27: total loss    0.00307\n",
      "epoch 18, batch 28: total loss    0.00257\n",
      "epoch 18, batch 29: total loss    0.00176\n",
      "epoch 18, batch 30: total loss    0.00181\n",
      "epoch 18, batch 31: total loss    0.00204\n",
      "epoch 18, batch 32: total loss    0.00160\n",
      "epoch 18, batch 33: total loss    0.00209\n",
      "epoch 18, batch 34: total loss    0.00207\n",
      "epoch 18, batch 35: total loss    0.00190\n",
      "epoch 18, batch 36: total loss    0.00178\n",
      "epoch 18, batch 37: total loss    0.00203\n",
      "epoch 18, batch 38: total loss    0.00175\n",
      "epoch 18, batch 39: total loss    0.00176\n",
      "epoch 18, batch 40: total loss    0.00173\n",
      "epoch 18, batch 41: total loss    0.00158\n",
      "epoch 18, batch 42: total loss    0.00176\n",
      "epoch 18, batch 43: total loss    0.00205\n",
      "epoch 18, batch 44: total loss    0.00187\n",
      "epoch 18, batch 45: total loss    0.00145\n",
      "epoch 18, batch 46: total loss    0.00147\n",
      "epoch 18, batch 47: total loss    0.00216\n",
      "epoch 18, batch 48: total loss    0.00230\n",
      "epoch 18, batch 49: total loss    0.00170\n",
      "epoch 18, batch 50: total loss    0.00172\n",
      "epoch 18, batch 51: total loss    0.00201\n",
      "epoch 18, batch 52: total loss    0.00228\n",
      "epoch 18, batch 53: total loss    0.00194\n",
      "epoch 18, batch 54: total loss    0.00241\n",
      "epoch 18, batch 55: total loss    0.00212\n",
      "epoch 18, batch 56: total loss    0.00202\n",
      "epoch 19, batch 0: total loss    0.00201\n",
      "epoch 19, batch 1: total loss    0.00163\n",
      "epoch 19, batch 2: total loss    0.00249\n",
      "epoch 19, batch 3: total loss    0.00189\n",
      "epoch 19, batch 4: total loss    0.00179\n",
      "epoch 19, batch 5: total loss    0.00177\n",
      "epoch 19, batch 6: total loss    0.00184\n",
      "epoch 19, batch 7: total loss    0.00139\n",
      "epoch 19, batch 8: total loss    0.00194\n",
      "epoch 19, batch 9: total loss    0.00207\n",
      "epoch 19, batch 10: total loss    0.00185\n",
      "epoch 19, batch 11: total loss    0.00171\n",
      "epoch 19, batch 12: total loss    0.00168\n",
      "epoch 19, batch 13: total loss    0.00174\n",
      "epoch 19, batch 14: total loss    0.00210\n",
      "epoch 19, batch 15: total loss    0.00183\n",
      "epoch 19, batch 16: total loss    0.00171\n",
      "epoch 19, batch 17: total loss    0.00161\n",
      "epoch 19, batch 18: total loss    0.00159\n",
      "epoch 19, batch 19: total loss    0.00204\n",
      "epoch 19, batch 20: total loss    0.00200\n",
      "epoch 19, batch 21: total loss    0.00159\n",
      "epoch 19, batch 22: total loss    0.00235\n",
      "epoch 19, batch 23: total loss    0.00187\n",
      "epoch 19, batch 24: total loss    0.00174\n",
      "epoch 19, batch 25: total loss    0.00162\n",
      "epoch 19, batch 26: total loss    0.00137\n",
      "epoch 19, batch 27: total loss    0.00181\n",
      "epoch 19, batch 28: total loss    0.00158\n",
      "epoch 19, batch 29: total loss    0.00201\n",
      "epoch 19, batch 30: total loss    0.00166\n",
      "epoch 19, batch 31: total loss    0.00177\n",
      "epoch 19, batch 32: total loss    0.00143\n",
      "epoch 19, batch 33: total loss    0.00202\n",
      "epoch 19, batch 34: total loss    0.00218\n",
      "epoch 19, batch 35: total loss    0.00169\n",
      "epoch 19, batch 36: total loss    0.00215\n",
      "epoch 19, batch 37: total loss    0.00179\n",
      "epoch 19, batch 38: total loss    0.00139\n",
      "epoch 19, batch 39: total loss    0.00186\n",
      "epoch 19, batch 40: total loss    0.00201\n",
      "epoch 19, batch 41: total loss    0.00173\n",
      "epoch 19, batch 42: total loss    0.00234\n",
      "epoch 19, batch 43: total loss    0.00196\n",
      "epoch 19, batch 44: total loss    0.00142\n",
      "epoch 19, batch 45: total loss    0.00144\n",
      "epoch 19, batch 46: total loss    0.00141\n",
      "epoch 19, batch 47: total loss    0.00188\n",
      "epoch 19, batch 48: total loss    0.00176\n",
      "epoch 19, batch 49: total loss    0.00185\n",
      "epoch 19, batch 50: total loss    0.00203\n",
      "epoch 19, batch 51: total loss    0.00142\n",
      "epoch 19, batch 52: total loss    0.00181\n",
      "epoch 19, batch 53: total loss    0.00185\n",
      "epoch 19, batch 54: total loss    0.00172\n",
      "epoch 19, batch 55: total loss    0.00158\n",
      "epoch 19, batch 56: total loss    0.00196\n",
      "epoch 20, batch 0: total loss    0.00177\n",
      "epoch 20, batch 1: total loss    0.00128\n",
      "epoch 20, batch 2: total loss    0.00151\n",
      "epoch 20, batch 3: total loss    0.00170\n",
      "epoch 20, batch 4: total loss    0.00199\n",
      "epoch 20, batch 5: total loss    0.00161\n",
      "epoch 20, batch 6: total loss    0.00145\n",
      "epoch 20, batch 7: total loss    0.00154\n",
      "epoch 20, batch 8: total loss    0.00122\n",
      "epoch 20, batch 9: total loss    0.00181\n",
      "epoch 20, batch 10: total loss    0.00152\n",
      "epoch 20, batch 11: total loss    0.00148\n",
      "epoch 20, batch 12: total loss    0.00226\n",
      "epoch 20, batch 13: total loss    0.00175\n",
      "epoch 20, batch 14: total loss    0.00188\n",
      "epoch 20, batch 15: total loss    0.00172\n",
      "epoch 20, batch 16: total loss    0.00138\n",
      "epoch 20, batch 17: total loss    0.00150\n",
      "epoch 20, batch 18: total loss    0.00166\n",
      "epoch 20, batch 19: total loss    0.00166\n",
      "epoch 20, batch 20: total loss    0.00126\n",
      "epoch 20, batch 21: total loss    0.00184\n",
      "epoch 20, batch 22: total loss    0.00130\n",
      "epoch 20, batch 23: total loss    0.00186\n",
      "epoch 20, batch 24: total loss    0.00212\n",
      "epoch 20, batch 25: total loss    0.00210\n",
      "epoch 20, batch 26: total loss    0.00168\n",
      "epoch 20, batch 27: total loss    0.00158\n",
      "epoch 20, batch 28: total loss    0.00193\n",
      "epoch 20, batch 29: total loss    0.00129\n",
      "epoch 20, batch 30: total loss    0.00142\n",
      "epoch 20, batch 31: total loss    0.00187\n",
      "epoch 20, batch 32: total loss    0.00149\n",
      "epoch 20, batch 33: total loss    0.00143\n",
      "epoch 20, batch 34: total loss    0.00177\n",
      "epoch 20, batch 35: total loss    0.00171\n",
      "epoch 20, batch 36: total loss    0.00136\n",
      "epoch 20, batch 37: total loss    0.00144\n",
      "epoch 20, batch 38: total loss    0.00187\n",
      "epoch 20, batch 39: total loss    0.00142\n",
      "epoch 20, batch 40: total loss    0.00141\n",
      "epoch 20, batch 41: total loss    0.00134\n",
      "epoch 20, batch 42: total loss    0.00107\n",
      "epoch 20, batch 43: total loss    0.00189\n",
      "epoch 20, batch 44: total loss    0.00129\n",
      "epoch 20, batch 45: total loss    0.00140\n",
      "epoch 20, batch 46: total loss    0.00166\n",
      "epoch 20, batch 47: total loss    0.00111\n",
      "epoch 20, batch 48: total loss    0.00165\n",
      "epoch 20, batch 49: total loss    0.00124\n",
      "epoch 20, batch 50: total loss    0.00145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, batch 51: total loss    0.00113\n",
      "epoch 20, batch 52: total loss    0.00207\n",
      "epoch 20, batch 53: total loss    0.00124\n",
      "epoch 20, batch 54: total loss    0.00179\n",
      "epoch 20, batch 55: total loss    0.00151\n",
      "epoch 20, batch 56: total loss    0.00175\n",
      "epoch 21, batch 0: total loss    0.00129\n",
      "epoch 21, batch 1: total loss    0.00145\n",
      "epoch 21, batch 2: total loss    0.00123\n",
      "epoch 21, batch 3: total loss    0.00132\n",
      "epoch 21, batch 4: total loss    0.00148\n",
      "epoch 21, batch 5: total loss    0.00126\n",
      "epoch 21, batch 6: total loss    0.00145\n",
      "epoch 21, batch 7: total loss    0.00165\n",
      "epoch 21, batch 8: total loss    0.00190\n",
      "epoch 21, batch 9: total loss    0.00139\n",
      "epoch 21, batch 10: total loss    0.00146\n",
      "epoch 21, batch 11: total loss    0.00119\n",
      "epoch 21, batch 12: total loss    0.00149\n",
      "epoch 21, batch 13: total loss    0.00180\n",
      "epoch 21, batch 14: total loss    0.00182\n",
      "epoch 21, batch 15: total loss    0.00167\n",
      "epoch 21, batch 16: total loss    0.00156\n",
      "epoch 21, batch 17: total loss    0.00154\n",
      "epoch 21, batch 18: total loss    0.00150\n",
      "epoch 21, batch 19: total loss    0.00190\n",
      "epoch 21, batch 20: total loss    0.00165\n",
      "epoch 21, batch 21: total loss    0.00170\n",
      "epoch 21, batch 22: total loss    0.00168\n",
      "epoch 21, batch 23: total loss    0.00149\n",
      "epoch 21, batch 24: total loss    0.00145\n",
      "epoch 21, batch 25: total loss    0.00160\n",
      "epoch 21, batch 26: total loss    0.00229\n",
      "epoch 21, batch 27: total loss    0.00181\n",
      "epoch 21, batch 28: total loss    0.00181\n",
      "epoch 21, batch 29: total loss    0.00164\n",
      "epoch 21, batch 30: total loss    0.00149\n",
      "epoch 21, batch 31: total loss    0.00150\n",
      "epoch 21, batch 32: total loss    0.00130\n",
      "epoch 21, batch 33: total loss    0.00177\n",
      "epoch 21, batch 34: total loss    0.00176\n",
      "epoch 21, batch 35: total loss    0.00156\n",
      "epoch 21, batch 36: total loss    0.00155\n",
      "epoch 21, batch 37: total loss    0.00168\n",
      "epoch 21, batch 38: total loss    0.00202\n",
      "epoch 21, batch 39: total loss    0.00153\n",
      "epoch 21, batch 40: total loss    0.00146\n",
      "epoch 21, batch 41: total loss    0.00158\n",
      "epoch 21, batch 42: total loss    0.00151\n",
      "epoch 21, batch 43: total loss    0.00149\n",
      "epoch 21, batch 44: total loss    0.00194\n",
      "epoch 21, batch 45: total loss    0.00132\n",
      "epoch 21, batch 46: total loss    0.00179\n",
      "epoch 21, batch 47: total loss    0.00149\n",
      "epoch 21, batch 48: total loss    0.00174\n",
      "epoch 21, batch 49: total loss    0.00170\n",
      "epoch 21, batch 50: total loss    0.00144\n",
      "epoch 21, batch 51: total loss    0.00158\n",
      "epoch 21, batch 52: total loss    0.00150\n",
      "epoch 21, batch 53: total loss    0.00170\n",
      "epoch 21, batch 54: total loss    0.00176\n",
      "epoch 21, batch 55: total loss    0.00129\n",
      "epoch 21, batch 56: total loss    0.00135\n",
      "epoch 22, batch 0: total loss    0.00146\n",
      "epoch 22, batch 1: total loss    0.00126\n",
      "epoch 22, batch 2: total loss    0.00142\n",
      "epoch 22, batch 3: total loss    0.00195\n",
      "epoch 22, batch 4: total loss    0.00225\n",
      "epoch 22, batch 5: total loss    0.00175\n",
      "epoch 22, batch 6: total loss    0.00171\n",
      "epoch 22, batch 7: total loss    0.00173\n",
      "epoch 22, batch 8: total loss    0.00144\n",
      "epoch 22, batch 9: total loss    0.00194\n",
      "epoch 22, batch 10: total loss    0.00186\n",
      "epoch 22, batch 11: total loss    0.00196\n",
      "epoch 22, batch 12: total loss    0.00134\n",
      "epoch 22, batch 13: total loss    0.00151\n",
      "epoch 22, batch 14: total loss    0.00154\n",
      "epoch 22, batch 15: total loss    0.00145\n",
      "epoch 22, batch 16: total loss    0.00169\n",
      "epoch 22, batch 17: total loss    0.00156\n",
      "epoch 22, batch 18: total loss    0.00135\n",
      "epoch 22, batch 19: total loss    0.00150\n",
      "epoch 22, batch 20: total loss    0.00135\n",
      "epoch 22, batch 21: total loss    0.00162\n",
      "epoch 22, batch 22: total loss    0.00146\n",
      "epoch 22, batch 23: total loss    0.00120\n",
      "epoch 22, batch 24: total loss    0.00168\n",
      "epoch 22, batch 25: total loss    0.00177\n",
      "epoch 22, batch 26: total loss    0.00178\n",
      "epoch 22, batch 27: total loss    0.00161\n",
      "epoch 22, batch 28: total loss    0.00199\n",
      "epoch 22, batch 29: total loss    0.00153\n",
      "epoch 22, batch 30: total loss    0.00113\n",
      "epoch 22, batch 31: total loss    0.00166\n",
      "epoch 22, batch 32: total loss    0.00165\n",
      "epoch 22, batch 33: total loss    0.00150\n",
      "epoch 22, batch 34: total loss    0.00134\n",
      "epoch 22, batch 35: total loss    0.00144\n",
      "epoch 22, batch 36: total loss    0.00121\n",
      "epoch 22, batch 37: total loss    0.00123\n",
      "epoch 22, batch 38: total loss    0.00165\n",
      "epoch 22, batch 39: total loss    0.00105\n",
      "epoch 22, batch 40: total loss    0.00096\n",
      "epoch 22, batch 41: total loss    0.00179\n",
      "epoch 22, batch 42: total loss    0.00120\n",
      "epoch 22, batch 43: total loss    0.00133\n",
      "epoch 22, batch 44: total loss    0.00167\n",
      "epoch 22, batch 45: total loss    0.00136\n",
      "epoch 22, batch 46: total loss    0.00153\n",
      "epoch 22, batch 47: total loss    0.00144\n",
      "epoch 22, batch 48: total loss    0.00135\n",
      "epoch 22, batch 49: total loss    0.00135\n",
      "epoch 22, batch 50: total loss    0.00152\n",
      "epoch 22, batch 51: total loss    0.00150\n",
      "epoch 22, batch 52: total loss    0.00163\n",
      "epoch 22, batch 53: total loss    0.00153\n",
      "epoch 22, batch 54: total loss    0.00133\n",
      "epoch 22, batch 55: total loss    0.00157\n",
      "epoch 22, batch 56: total loss    0.00127\n",
      "epoch 23, batch 0: total loss    0.00119\n",
      "epoch 23, batch 1: total loss    0.00100\n",
      "epoch 23, batch 2: total loss    0.00123\n",
      "epoch 23, batch 3: total loss    0.00135\n",
      "epoch 23, batch 4: total loss    0.00196\n",
      "epoch 23, batch 5: total loss    0.00146\n",
      "epoch 23, batch 6: total loss    0.00132\n",
      "epoch 23, batch 7: total loss    0.00136\n",
      "epoch 23, batch 8: total loss    0.00152\n",
      "epoch 23, batch 9: total loss    0.00165\n",
      "epoch 23, batch 10: total loss    0.00134\n",
      "epoch 23, batch 11: total loss    0.00133\n",
      "epoch 23, batch 12: total loss    0.00101\n",
      "epoch 23, batch 13: total loss    0.00173\n",
      "epoch 23, batch 14: total loss    0.00146\n",
      "epoch 23, batch 15: total loss    0.00101\n",
      "epoch 23, batch 16: total loss    0.00126\n",
      "epoch 23, batch 17: total loss    0.00129\n",
      "epoch 23, batch 18: total loss    0.00128\n",
      "epoch 23, batch 19: total loss    0.00137\n",
      "epoch 23, batch 20: total loss    0.00138\n",
      "epoch 23, batch 21: total loss    0.00157\n",
      "epoch 23, batch 22: total loss    0.00155\n",
      "epoch 23, batch 23: total loss    0.00154\n",
      "epoch 23, batch 24: total loss    0.00145\n",
      "epoch 23, batch 25: total loss    0.00182\n",
      "epoch 23, batch 26: total loss    0.00152\n",
      "epoch 23, batch 27: total loss    0.00141\n",
      "epoch 23, batch 28: total loss    0.00127\n",
      "epoch 23, batch 29: total loss    0.00149\n",
      "epoch 23, batch 30: total loss    0.00112\n",
      "epoch 23, batch 31: total loss    0.00165\n",
      "epoch 23, batch 32: total loss    0.00169\n",
      "epoch 23, batch 33: total loss    0.00122\n",
      "epoch 23, batch 34: total loss    0.00214\n",
      "epoch 23, batch 35: total loss    0.00160\n",
      "epoch 23, batch 36: total loss    0.00148\n",
      "epoch 23, batch 37: total loss    0.00102\n",
      "epoch 23, batch 38: total loss    0.00189\n",
      "epoch 23, batch 39: total loss    0.00144\n",
      "epoch 23, batch 40: total loss    0.00162\n",
      "epoch 23, batch 41: total loss    0.00155\n",
      "epoch 23, batch 42: total loss    0.00167\n",
      "epoch 23, batch 43: total loss    0.00133\n",
      "epoch 23, batch 44: total loss    0.00159\n",
      "epoch 23, batch 45: total loss    0.00137\n",
      "epoch 23, batch 46: total loss    0.00153\n",
      "epoch 23, batch 47: total loss    0.00129\n",
      "epoch 23, batch 48: total loss    0.00169\n",
      "epoch 23, batch 49: total loss    0.00141\n",
      "epoch 23, batch 50: total loss    0.00161\n",
      "epoch 23, batch 51: total loss    0.00126\n",
      "epoch 23, batch 52: total loss    0.00138\n",
      "epoch 23, batch 53: total loss    0.00140\n",
      "epoch 23, batch 54: total loss    0.00131\n",
      "epoch 23, batch 55: total loss    0.00132\n",
      "epoch 23, batch 56: total loss    0.00129\n",
      "epoch 24, batch 0: total loss    0.00168\n",
      "epoch 24, batch 1: total loss    0.00166\n",
      "epoch 24, batch 2: total loss    0.00152\n",
      "epoch 24, batch 3: total loss    0.00146\n",
      "epoch 24, batch 4: total loss    0.00127\n",
      "epoch 24, batch 5: total loss    0.00134\n",
      "epoch 24, batch 6: total loss    0.00155\n",
      "epoch 24, batch 7: total loss    0.00137\n",
      "epoch 24, batch 8: total loss    0.00137\n",
      "epoch 24, batch 9: total loss    0.00137\n",
      "epoch 24, batch 10: total loss    0.00152\n",
      "epoch 24, batch 11: total loss    0.00094\n",
      "epoch 24, batch 12: total loss    0.00166\n",
      "epoch 24, batch 13: total loss    0.00165\n",
      "epoch 24, batch 14: total loss    0.00100\n",
      "epoch 24, batch 15: total loss    0.00091\n",
      "epoch 24, batch 16: total loss    0.00167\n",
      "epoch 24, batch 17: total loss    0.00131\n",
      "epoch 24, batch 18: total loss    0.00188\n",
      "epoch 24, batch 19: total loss    0.00112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, batch 20: total loss    0.00138\n",
      "epoch 24, batch 21: total loss    0.00131\n",
      "epoch 24, batch 22: total loss    0.00182\n",
      "epoch 24, batch 23: total loss    0.00204\n",
      "epoch 24, batch 24: total loss    0.00177\n",
      "epoch 24, batch 25: total loss    0.00129\n",
      "epoch 24, batch 26: total loss    0.00159\n",
      "epoch 24, batch 27: total loss    0.00169\n",
      "epoch 24, batch 28: total loss    0.00148\n",
      "epoch 24, batch 29: total loss    0.00133\n",
      "epoch 24, batch 30: total loss    0.00203\n",
      "epoch 24, batch 31: total loss    0.00171\n",
      "epoch 24, batch 32: total loss    0.00137\n",
      "epoch 24, batch 33: total loss    0.00134\n",
      "epoch 24, batch 34: total loss    0.00172\n",
      "epoch 24, batch 35: total loss    0.00185\n",
      "epoch 24, batch 36: total loss    0.00176\n",
      "epoch 24, batch 37: total loss    0.00186\n",
      "epoch 24, batch 38: total loss    0.00153\n",
      "epoch 24, batch 39: total loss    0.00153\n",
      "epoch 24, batch 40: total loss    0.00161\n",
      "epoch 24, batch 41: total loss    0.00133\n",
      "epoch 24, batch 42: total loss    0.00106\n",
      "epoch 24, batch 43: total loss    0.00090\n",
      "epoch 24, batch 44: total loss    0.00100\n",
      "epoch 24, batch 45: total loss    0.00103\n",
      "epoch 24, batch 46: total loss    0.00109\n",
      "epoch 24, batch 47: total loss    0.00126\n",
      "epoch 24, batch 48: total loss    0.00158\n",
      "epoch 24, batch 49: total loss    0.00112\n",
      "epoch 24, batch 50: total loss    0.00116\n",
      "epoch 24, batch 51: total loss    0.00157\n",
      "epoch 24, batch 52: total loss    0.00146\n",
      "epoch 24, batch 53: total loss    0.00131\n",
      "epoch 24, batch 54: total loss    0.00120\n",
      "epoch 24, batch 55: total loss    0.00100\n",
      "epoch 24, batch 56: total loss    0.00159\n",
      "epoch 25, batch 0: total loss    0.00111\n",
      "epoch 25, batch 1: total loss    0.00146\n",
      "epoch 25, batch 2: total loss    0.00114\n",
      "epoch 25, batch 3: total loss    0.00101\n",
      "epoch 25, batch 4: total loss    0.00110\n",
      "epoch 25, batch 5: total loss    0.00156\n",
      "epoch 25, batch 6: total loss    0.00136\n",
      "epoch 25, batch 7: total loss    0.00176\n",
      "epoch 25, batch 8: total loss    0.00097\n",
      "epoch 25, batch 9: total loss    0.00111\n",
      "epoch 25, batch 10: total loss    0.00121\n",
      "epoch 25, batch 11: total loss    0.00105\n",
      "epoch 25, batch 12: total loss    0.00143\n",
      "epoch 25, batch 13: total loss    0.00124\n",
      "epoch 25, batch 14: total loss    0.00133\n",
      "epoch 25, batch 15: total loss    0.00154\n",
      "epoch 25, batch 16: total loss    0.00125\n",
      "epoch 25, batch 17: total loss    0.00149\n",
      "epoch 25, batch 18: total loss    0.00132\n",
      "epoch 25, batch 19: total loss    0.00133\n",
      "epoch 25, batch 20: total loss    0.00148\n",
      "epoch 25, batch 21: total loss    0.00124\n",
      "epoch 25, batch 22: total loss    0.00139\n",
      "epoch 25, batch 23: total loss    0.00119\n",
      "epoch 25, batch 24: total loss    0.00134\n",
      "epoch 25, batch 25: total loss    0.00151\n",
      "epoch 25, batch 26: total loss    0.00168\n",
      "epoch 25, batch 27: total loss    0.00137\n",
      "epoch 25, batch 28: total loss    0.00157\n",
      "epoch 25, batch 29: total loss    0.00126\n",
      "epoch 25, batch 30: total loss    0.00140\n",
      "epoch 25, batch 31: total loss    0.00141\n",
      "epoch 25, batch 32: total loss    0.00147\n",
      "epoch 25, batch 33: total loss    0.00108\n",
      "epoch 25, batch 34: total loss    0.00094\n",
      "epoch 25, batch 35: total loss    0.00099\n",
      "epoch 25, batch 36: total loss    0.00136\n",
      "epoch 25, batch 37: total loss    0.00123\n",
      "epoch 25, batch 38: total loss    0.00105\n",
      "epoch 25, batch 39: total loss    0.00137\n",
      "epoch 25, batch 40: total loss    0.00154\n",
      "epoch 25, batch 41: total loss    0.00117\n",
      "epoch 25, batch 42: total loss    0.00147\n",
      "epoch 25, batch 43: total loss    0.00089\n",
      "epoch 25, batch 44: total loss    0.00114\n",
      "epoch 25, batch 45: total loss    0.00129\n",
      "epoch 25, batch 46: total loss    0.00122\n",
      "epoch 25, batch 47: total loss    0.00120\n",
      "epoch 25, batch 48: total loss    0.00135\n",
      "epoch 25, batch 49: total loss    0.00125\n",
      "epoch 25, batch 50: total loss    0.00151\n",
      "epoch 25, batch 51: total loss    0.00092\n",
      "epoch 25, batch 52: total loss    0.00149\n",
      "epoch 25, batch 53: total loss    0.00177\n",
      "epoch 25, batch 54: total loss    0.00130\n",
      "epoch 25, batch 55: total loss    0.00100\n",
      "epoch 25, batch 56: total loss    0.00150\n",
      "epoch 26, batch 0: total loss    0.00150\n",
      "epoch 26, batch 1: total loss    0.00138\n",
      "epoch 26, batch 2: total loss    0.00118\n",
      "epoch 26, batch 3: total loss    0.00156\n",
      "epoch 26, batch 4: total loss    0.00097\n",
      "epoch 26, batch 5: total loss    0.00128\n",
      "epoch 26, batch 6: total loss    0.00131\n",
      "epoch 26, batch 7: total loss    0.00124\n",
      "epoch 26, batch 8: total loss    0.00121\n",
      "epoch 26, batch 9: total loss    0.00085\n",
      "epoch 26, batch 10: total loss    0.00167\n",
      "epoch 26, batch 11: total loss    0.00103\n",
      "epoch 26, batch 12: total loss    0.00108\n",
      "epoch 26, batch 13: total loss    0.00111\n",
      "epoch 26, batch 14: total loss    0.00150\n",
      "epoch 26, batch 15: total loss    0.00114\n",
      "epoch 26, batch 16: total loss    0.00106\n",
      "epoch 26, batch 17: total loss    0.00113\n",
      "epoch 26, batch 18: total loss    0.00124\n",
      "epoch 26, batch 19: total loss    0.00094\n",
      "epoch 26, batch 20: total loss    0.00112\n",
      "epoch 26, batch 21: total loss    0.00129\n",
      "epoch 26, batch 22: total loss    0.00098\n",
      "epoch 26, batch 23: total loss    0.00116\n",
      "epoch 26, batch 24: total loss    0.00118\n",
      "epoch 26, batch 25: total loss    0.00172\n",
      "epoch 26, batch 26: total loss    0.00144\n",
      "epoch 26, batch 27: total loss    0.00096\n",
      "epoch 26, batch 28: total loss    0.00127\n",
      "epoch 26, batch 29: total loss    0.00100\n",
      "epoch 26, batch 30: total loss    0.00171\n",
      "epoch 26, batch 31: total loss    0.00120\n",
      "epoch 26, batch 32: total loss    0.00158\n",
      "epoch 26, batch 33: total loss    0.00123\n",
      "epoch 26, batch 34: total loss    0.00118\n",
      "epoch 26, batch 35: total loss    0.00113\n",
      "epoch 26, batch 36: total loss    0.00137\n",
      "epoch 26, batch 37: total loss    0.00129\n",
      "epoch 26, batch 38: total loss    0.00101\n",
      "epoch 26, batch 39: total loss    0.00124\n",
      "epoch 26, batch 40: total loss    0.00113\n",
      "epoch 26, batch 41: total loss    0.00115\n",
      "epoch 26, batch 42: total loss    0.00126\n",
      "epoch 26, batch 43: total loss    0.00125\n",
      "epoch 26, batch 44: total loss    0.00125\n",
      "epoch 26, batch 45: total loss    0.00116\n",
      "epoch 26, batch 46: total loss    0.00133\n",
      "epoch 26, batch 47: total loss    0.00109\n",
      "epoch 26, batch 48: total loss    0.00115\n",
      "epoch 26, batch 49: total loss    0.00124\n",
      "epoch 26, batch 50: total loss    0.00095\n",
      "epoch 26, batch 51: total loss    0.00111\n",
      "epoch 26, batch 52: total loss    0.00105\n",
      "epoch 26, batch 53: total loss    0.00088\n",
      "epoch 26, batch 54: total loss    0.00120\n",
      "epoch 26, batch 55: total loss    0.00107\n",
      "epoch 26, batch 56: total loss    0.00106\n",
      "epoch 27, batch 0: total loss    0.00104\n",
      "epoch 27, batch 1: total loss    0.00117\n",
      "epoch 27, batch 2: total loss    0.00126\n",
      "epoch 27, batch 3: total loss    0.00132\n",
      "epoch 27, batch 4: total loss    0.00149\n",
      "epoch 27, batch 5: total loss    0.00124\n",
      "epoch 27, batch 6: total loss    0.00108\n",
      "epoch 27, batch 7: total loss    0.00135\n",
      "epoch 27, batch 8: total loss    0.00093\n",
      "epoch 27, batch 9: total loss    0.00119\n",
      "epoch 27, batch 10: total loss    0.00110\n",
      "epoch 27, batch 11: total loss    0.00105\n",
      "epoch 27, batch 12: total loss    0.00130\n",
      "epoch 27, batch 13: total loss    0.00149\n",
      "epoch 27, batch 14: total loss    0.00102\n",
      "epoch 27, batch 15: total loss    0.00105\n",
      "epoch 27, batch 16: total loss    0.00121\n",
      "epoch 27, batch 17: total loss    0.00153\n",
      "epoch 27, batch 18: total loss    0.00081\n",
      "epoch 27, batch 19: total loss    0.00113\n",
      "epoch 27, batch 20: total loss    0.00104\n",
      "epoch 27, batch 21: total loss    0.00085\n",
      "epoch 27, batch 22: total loss    0.00112\n",
      "epoch 27, batch 23: total loss    0.00083\n",
      "epoch 27, batch 24: total loss    0.00092\n",
      "epoch 27, batch 25: total loss    0.00121\n",
      "epoch 27, batch 26: total loss    0.00145\n",
      "epoch 27, batch 27: total loss    0.00094\n",
      "epoch 27, batch 28: total loss    0.00120\n",
      "epoch 27, batch 29: total loss    0.00130\n",
      "epoch 27, batch 30: total loss    0.00078\n",
      "epoch 27, batch 31: total loss    0.00132\n",
      "epoch 27, batch 32: total loss    0.00103\n",
      "epoch 27, batch 33: total loss    0.00097\n",
      "epoch 27, batch 34: total loss    0.00129\n",
      "epoch 27, batch 35: total loss    0.00114\n",
      "epoch 27, batch 36: total loss    0.00094\n",
      "epoch 27, batch 37: total loss    0.00112\n",
      "epoch 27, batch 38: total loss    0.00099\n",
      "epoch 27, batch 39: total loss    0.00137\n",
      "epoch 27, batch 40: total loss    0.00116\n",
      "epoch 27, batch 41: total loss    0.00106\n",
      "epoch 27, batch 42: total loss    0.00111\n",
      "epoch 27, batch 43: total loss    0.00157\n",
      "epoch 27, batch 44: total loss    0.00115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, batch 45: total loss    0.00142\n",
      "epoch 27, batch 46: total loss    0.00111\n",
      "epoch 27, batch 47: total loss    0.00102\n",
      "epoch 27, batch 48: total loss    0.00083\n",
      "epoch 27, batch 49: total loss    0.00114\n",
      "epoch 27, batch 50: total loss    0.00124\n",
      "epoch 27, batch 51: total loss    0.00109\n",
      "epoch 27, batch 52: total loss    0.00118\n",
      "epoch 27, batch 53: total loss    0.00115\n",
      "epoch 27, batch 54: total loss    0.00087\n",
      "epoch 27, batch 55: total loss    0.00108\n",
      "epoch 27, batch 56: total loss    0.00104\n",
      "epoch 28, batch 0: total loss    0.00089\n",
      "epoch 28, batch 1: total loss    0.00084\n",
      "epoch 28, batch 2: total loss    0.00097\n",
      "epoch 28, batch 3: total loss    0.00086\n",
      "epoch 28, batch 4: total loss    0.00110\n",
      "epoch 28, batch 5: total loss    0.00128\n",
      "epoch 28, batch 6: total loss    0.00142\n",
      "epoch 28, batch 7: total loss    0.00114\n",
      "epoch 28, batch 8: total loss    0.00104\n",
      "epoch 28, batch 9: total loss    0.00105\n",
      "epoch 28, batch 10: total loss    0.00106\n",
      "epoch 28, batch 11: total loss    0.00072\n",
      "epoch 28, batch 12: total loss    0.00103\n",
      "epoch 28, batch 13: total loss    0.00120\n",
      "epoch 28, batch 14: total loss    0.00124\n",
      "epoch 28, batch 15: total loss    0.00133\n",
      "epoch 28, batch 16: total loss    0.00108\n",
      "epoch 28, batch 17: total loss    0.00121\n",
      "epoch 28, batch 18: total loss    0.00090\n",
      "epoch 28, batch 19: total loss    0.00111\n",
      "epoch 28, batch 20: total loss    0.00101\n",
      "epoch 28, batch 21: total loss    0.00083\n",
      "epoch 28, batch 22: total loss    0.00103\n",
      "epoch 28, batch 23: total loss    0.00140\n",
      "epoch 28, batch 24: total loss    0.00144\n",
      "epoch 28, batch 25: total loss    0.00081\n",
      "epoch 28, batch 26: total loss    0.00127\n",
      "epoch 28, batch 27: total loss    0.00128\n",
      "epoch 28, batch 28: total loss    0.00124\n",
      "epoch 28, batch 29: total loss    0.00143\n",
      "epoch 28, batch 30: total loss    0.00132\n",
      "epoch 28, batch 31: total loss    0.00116\n",
      "epoch 28, batch 32: total loss    0.00107\n",
      "epoch 28, batch 33: total loss    0.00123\n",
      "epoch 28, batch 34: total loss    0.00067\n",
      "epoch 28, batch 35: total loss    0.00108\n",
      "epoch 28, batch 36: total loss    0.00131\n",
      "epoch 28, batch 37: total loss    0.00102\n",
      "epoch 28, batch 38: total loss    0.00113\n",
      "epoch 28, batch 39: total loss    0.00128\n",
      "epoch 28, batch 40: total loss    0.00090\n",
      "epoch 28, batch 41: total loss    0.00117\n",
      "epoch 28, batch 42: total loss    0.00149\n",
      "epoch 28, batch 43: total loss    0.00130\n",
      "epoch 28, batch 44: total loss    0.00109\n",
      "epoch 28, batch 45: total loss    0.00113\n",
      "epoch 28, batch 46: total loss    0.00111\n",
      "epoch 28, batch 47: total loss    0.00086\n",
      "epoch 28, batch 48: total loss    0.00098\n",
      "epoch 28, batch 49: total loss    0.00119\n",
      "epoch 28, batch 50: total loss    0.00108\n",
      "epoch 28, batch 51: total loss    0.00104\n",
      "epoch 28, batch 52: total loss    0.00098\n",
      "epoch 28, batch 53: total loss    0.00110\n",
      "epoch 28, batch 54: total loss    0.00145\n",
      "epoch 28, batch 55: total loss    0.00177\n",
      "epoch 28, batch 56: total loss    0.00151\n",
      "epoch 29, batch 0: total loss    0.00189\n",
      "epoch 29, batch 1: total loss    0.00281\n",
      "epoch 29, batch 2: total loss    0.00222\n",
      "epoch 29, batch 3: total loss    0.00171\n",
      "epoch 29, batch 4: total loss    0.00184\n",
      "epoch 29, batch 5: total loss    0.00135\n",
      "epoch 29, batch 6: total loss    0.00116\n",
      "epoch 29, batch 7: total loss    0.00127\n",
      "epoch 29, batch 8: total loss    0.00119\n",
      "epoch 29, batch 9: total loss    0.00118\n",
      "epoch 29, batch 10: total loss    0.00135\n",
      "epoch 29, batch 11: total loss    0.00121\n",
      "epoch 29, batch 12: total loss    0.00135\n",
      "epoch 29, batch 13: total loss    0.00095\n",
      "epoch 29, batch 14: total loss    0.00163\n",
      "epoch 29, batch 15: total loss    0.00133\n",
      "epoch 29, batch 16: total loss    0.00107\n",
      "epoch 29, batch 17: total loss    0.00095\n",
      "epoch 29, batch 18: total loss    0.00141\n",
      "epoch 29, batch 19: total loss    0.00127\n",
      "epoch 29, batch 20: total loss    0.00122\n",
      "epoch 29, batch 21: total loss    0.00107\n",
      "epoch 29, batch 22: total loss    0.00107\n",
      "epoch 29, batch 23: total loss    0.00142\n",
      "epoch 29, batch 24: total loss    0.00109\n",
      "epoch 29, batch 25: total loss    0.00104\n",
      "epoch 29, batch 26: total loss    0.00137\n",
      "epoch 29, batch 27: total loss    0.00073\n",
      "epoch 29, batch 28: total loss    0.00125\n",
      "epoch 29, batch 29: total loss    0.00101\n",
      "epoch 29, batch 30: total loss    0.00109\n",
      "epoch 29, batch 31: total loss    0.00100\n",
      "epoch 29, batch 32: total loss    0.00079\n",
      "epoch 29, batch 33: total loss    0.00092\n",
      "epoch 29, batch 34: total loss    0.00101\n",
      "epoch 29, batch 35: total loss    0.00088\n",
      "epoch 29, batch 36: total loss    0.00083\n",
      "epoch 29, batch 37: total loss    0.00081\n",
      "epoch 29, batch 38: total loss    0.00092\n",
      "epoch 29, batch 39: total loss    0.00090\n",
      "epoch 29, batch 40: total loss    0.00101\n",
      "epoch 29, batch 41: total loss    0.00122\n",
      "epoch 29, batch 42: total loss    0.00092\n",
      "epoch 29, batch 43: total loss    0.00104\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-30017eac1b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolumes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0minput_voxels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvolumes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mpix_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_pixel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_vector\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_voxels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    volumes = d.getAll(obj=obj, train=True, is_local=False, obj_ratio=obj_ratio, cube_len=32)\n",
    "    print ('Using ' + obj + ' Data')\n",
    "    volumes = volumes[...,np.newaxis].astype(np.float)\n",
    "\n",
    "    num_samples = len(volumes)\n",
    "\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    #sess.run(tf.global_variables_initializer())   \n",
    "    loss_stat = np.array([])\n",
    "    for epoch in range(num_epoch):\n",
    "        for i in range(num_batches):\n",
    "            np.random.shuffle(volumes)\n",
    "            input_voxels = volumes[i*batch_size: (i+1)*batch_size]\n",
    "            pix_loss, _ = sess.run([loss_pixel, train_op], feed_dict={x_vector: input_voxels})\n",
    "\n",
    "            loss_stat = np.concatenate([loss_stat,[pix_loss]])\n",
    "\n",
    "            print(\"epoch {}, batch {}: total loss {:10.5f}\".format(epoch, i, pix_loss))\n",
    "            if i==num_batches - 1 and epoch % save_interval == 0:\n",
    "                # generate and visualize generated images\n",
    "                recon_voxel = sess.run(dec, feed_dict={x_vector: input_voxels})\n",
    "                save_sample = np.concatenate((input_voxels, recon_voxel), axis=0)\n",
    "\n",
    "                save_sample.dump(\"{}{}\".format(train_sample_directory, epoch))\n",
    "\n",
    "                saver.save(sess, save_path = '{}compression_gen_{}.ckpt'.format(model_directory, epoch))\n",
    "\n",
    "                for n in range(3):\n",
    "                    plot_voxel(save_sample[n], save_sample[n + batch_size], saveas='{}{}_{}.png'.format(img_directory, epoch, n))\n",
    "\n",
    "                loss_stat.dump(\"{}{}.pickle\".format(pickle_directory, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/vamsi/Downloads/tf-3dgan-master/src/models/vase-ae_3/compression_gen_25.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /home/vamsi/Downloads/tf-3dgan-master/src/models/vase-ae_3/compression_gen_25.ckpt\n",
      "Using vase Data\n",
      "epoch 0, batch 0: total loss    0.00876\n",
      "epoch 0, batch 1: total loss    0.00803\n",
      "epoch 0, batch 2: total loss    0.00843\n",
      "epoch 0, batch 3: total loss    0.00902\n",
      "epoch 0, batch 4: total loss    0.00879\n",
      "epoch 0, batch 5: total loss    0.00967\n",
      "epoch 0, batch 6: total loss    0.00848\n",
      "epoch 0, batch 7: total loss    0.00944\n",
      "epoch 0, batch 8: total loss    0.00850\n",
      "epoch 0, batch 9: total loss    0.00721\n",
      "epoch 0, batch 10: total loss    0.00938\n",
      "epoch 0, batch 11: total loss    0.00792\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c2aa6c2d3ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     \u001b[0mplot_voxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{}{}_{}_test.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mloss_stat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}{}_test.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_sample' is not defined"
     ]
    }
   ],
   "source": [
    "code_directory = '/home/vamsi/Downloads/tf-3dgan-master/src/models/vase-ae_3/compression_gen_25.ckpt'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    gen_loader = tf.train.Saver(generator_vars)\n",
    "    gen_loader.restore(sess, code_directory)\n",
    "    \n",
    "    ec_loader = tf.train.Saver(encoder_vars)\n",
    "    ec_loader.restore(sess, code_directory)\n",
    "    \n",
    "    volumes = d.getAll(obj=obj, train=False, is_local=False, obj_ratio=obj_ratio, cube_len=32)\n",
    "    print ('Using ' + obj + ' Data')\n",
    "    volumes = volumes[...,np.newaxis].astype(np.float)\n",
    "\n",
    "    num_samples = len(volumes)\n",
    "\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    #sess.run(tf.global_variables_initializer())   \n",
    "    loss_stat = np.array([])\n",
    "    for epoch in range(num_epoch):\n",
    "        for i in range(num_batches):\n",
    "            #idx = np.random.randint(len(volumes), size=batch_size)\n",
    "            input_voxels = volumes[i*batch_size: (i+1)*batch_size]\n",
    "            pix_loss, recon_voxel = sess.run([loss_pixel, dec], feed_dict={x_vector: input_voxels})\n",
    "\n",
    "            loss_stat = np.concatenate([loss_stat,[pix_loss]])\n",
    "\n",
    "            print(\"epoch {}, batch {}: total loss {:10.5f}\".format(epoch, i, pix_loss))\n",
    "            if i==num_batches - 1 and epoch % save_interval == 0:\n",
    "                # generate and visualize generated images\n",
    "                recon_voxel = sess.run(dec, feed_dict={x_vector: input_voxels})\n",
    "                save_sample = np.concatenate((input_voxels, recon_voxel), axis=0)\n",
    "\n",
    "                #save_sample.dump(\"{}{}_test\".format(train_sample_directory, epoch))\n",
    "\n",
    "\n",
    "                for n in range(3):\n",
    "                    plot_voxel(save_sample[n], save_sample[n + batch_size], saveas='{}{}_{}_test.png'.format(img_directory, epoch*i, n))\n",
    "\n",
    "                loss_stat.dump(\"{}{}_test.pickle\".format(pickle_directory, epoch))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
