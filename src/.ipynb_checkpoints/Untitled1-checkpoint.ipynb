{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies not loaded, some functionality may not work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gen/Relu:0\", shape=(32, 4, 4, 4, 512), dtype=float32, device=/device:GPU:0) g1\n",
      "Tensor(\"gen/Relu_1:0\", shape=(32, 8, 8, 8, 256), dtype=float32, device=/device:GPU:0) g2\n",
      "Tensor(\"gen/Relu_2:0\", shape=(32, 16, 16, 16, 128), dtype=float32, device=/device:GPU:0) g3\n",
      "Tensor(\"gen/Relu_3:0\", shape=(32, 32, 32, 32, 64), dtype=float32, device=/device:GPU:0) g4\n",
      "Tensor(\"gen/Tanh:0\", shape=(32, 64, 64, 64, 1), dtype=float32, device=/device:GPU:0) g5\n",
      "Tensor(\"dis/Maximum:0\", shape=(32, 32, 32, 32, 64), dtype=float32, device=/device:GPU:0) d1\n",
      "Tensor(\"dis/Maximum_1:0\", shape=(32, 16, 16, 16, 128), dtype=float32, device=/device:GPU:0) d2\n",
      "Tensor(\"dis/Maximum_2:0\", shape=(32, 8, 8, 8, 256), dtype=float32, device=/device:GPU:0) d3\n",
      "Tensor(\"dis/Maximum_3:0\", shape=(32, 4, 4, 4, 512), dtype=float32, device=/device:GPU:0) d4\n",
      "Tensor(\"dis/Sigmoid:0\", shape=(32, 1, 1, 1, 1), dtype=float32, device=/device:GPU:0) d5\n",
      "Tensor(\"dis_1/Maximum:0\", shape=(32, 32, 32, 32, 64), dtype=float32, device=/device:GPU:0) d1\n",
      "Tensor(\"dis_1/Maximum_1:0\", shape=(32, 16, 16, 16, 128), dtype=float32, device=/device:GPU:0) d2\n",
      "Tensor(\"dis_1/Maximum_2:0\", shape=(32, 8, 8, 8, 256), dtype=float32, device=/device:GPU:0) d3\n",
      "Tensor(\"dis_1/Maximum_3:0\", shape=(32, 4, 4, 4, 512), dtype=float32, device=/device:GPU:0) d4\n",
      "Tensor(\"dis_1/Sigmoid:0\", shape=(32, 1, 1, 1, 1), dtype=float32, device=/device:GPU:0) d5\n",
      "Tensor(\"gen_1/Relu:0\", shape=(32, 4, 4, 4, 512), dtype=float32, device=/device:GPU:0) g1\n",
      "Tensor(\"gen_1/Relu_1:0\", shape=(32, 8, 8, 8, 256), dtype=float32, device=/device:GPU:0) g2\n",
      "Tensor(\"gen_1/Relu_2:0\", shape=(32, 16, 16, 16, 128), dtype=float32, device=/device:GPU:0) g3\n",
      "Tensor(\"gen_1/Relu_3:0\", shape=(32, 32, 32, 32, 64), dtype=float32, device=/device:GPU:0) g4\n",
      "Tensor(\"gen_1/Tanh:0\", shape=(32, 64, 64, 64, 1), dtype=float32, device=/device:GPU:0) g5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'n_p_x': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: n_p_x = ScalarSummary[T=DT_INT32, _device=\"/device:GPU:0\"](n_p_x/tags, Sum)]]\n\nCaused by op 'n_p_x', defined at:\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-f227e9981202>\", line 271, in <module>\n    trainGAN(is_dummy=False, checkpoint=None)\n  File \"<ipython-input-1-f227e9981202>\", line 159, in trainGAN\n    summary_n_p_x = tf.summary.scalar(\"n_p_x\", n_p_x)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 129, in scalar\n    tags=scope.rstrip('/'), values=tensor, name=scope)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 265, in _scalar_summary\n    name=name)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'n_p_x': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: n_p_x = ScalarSummary[T=DT_INT32, _device=\"/device:GPU:0\"](n_p_x/tags, Sum)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1116\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1166\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'n_p_x': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: n_p_x = ScalarSummary[T=DT_INT32, _device=\"/device:GPU:0\"](n_p_x/tags, Sum)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f227e9981202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m#    ckpt = sys.argv[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mtrainGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_dummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mtrainGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_dummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f227e9981202>\u001b[0m in \u001b[0;36mtrainGAN\u001b[0;34m(is_dummy, checkpoint)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'n_p_x': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: n_p_x = ScalarSummary[T=DT_INT32, _device=\"/device:GPU:0\"](n_p_x/tags, Sum)]]\n\nCaused by op 'n_p_x', defined at:\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-f227e9981202>\", line 271, in <module>\n    trainGAN(is_dummy=False, checkpoint=None)\n  File \"<ipython-input-1-f227e9981202>\", line 159, in trainGAN\n    summary_n_p_x = tf.summary.scalar(\"n_p_x\", n_p_x)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 129, in scalar\n    tags=scope.rstrip('/'), values=tensor, name=scope)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 265, in _scalar_summary\n    name=name)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'n_p_x': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: n_p_x = ScalarSummary[T=DT_INT32, _device=\"/device:GPU:0\"](n_p_x/tags, Sum)]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import visdom\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dataIO as d\n",
    "\n",
    "from tqdm import *\n",
    "from utils import *\n",
    "\n",
    "'''\n",
    "Global Parameters\n",
    "'''\n",
    "n_epochs   = 10000\n",
    "batch_size = 32\n",
    "g_lr       = 0.0025\n",
    "d_lr       = 0.00001\n",
    "beta       = 0.5\n",
    "d_thresh   = 0.8\n",
    "z_size     = 200\n",
    "leak_value = 0.2\n",
    "cube_len   = 64\n",
    "obj_ratio  = 0.7\n",
    "obj        = 'chair' \n",
    "\n",
    "train_sample_directory = './train_sample/'\n",
    "model_directory = './models/'\n",
    "is_local = False\n",
    "\n",
    "weights = {}\n",
    "\n",
    "def generator(z, batch_size=batch_size, phase_train=True, reuse=False):\n",
    "    \n",
    "    #with tf.device('/device:GPU:0'):\n",
    "\n",
    "        strides    = [1,2,2,2,1]\n",
    "\n",
    "        with tf.variable_scope(\"gen\", reuse=reuse):\n",
    "            z = tf.reshape(z, (batch_size, 1, 1, 1, z_size))\n",
    "            g_1 = tf.nn.conv3d_transpose(z, weights['wg1'], (batch_size,4,4,4,512), strides=[1,1,1,1,1], padding=\"VALID\")\n",
    "            g_1 = tf.contrib.layers.batch_norm(g_1, is_training=phase_train)\n",
    "            g_1 = tf.nn.relu(g_1)\n",
    "\n",
    "            g_2 = tf.nn.conv3d_transpose(g_1, weights['wg2'], (batch_size,8,8,8,256), strides=strides, padding=\"SAME\")\n",
    "            g_2 = tf.contrib.layers.batch_norm(g_2, is_training=phase_train)\n",
    "            g_2 = tf.nn.relu(g_2)\n",
    "\n",
    "            g_3 = tf.nn.conv3d_transpose(g_2, weights['wg3'], (batch_size,16,16,16,128), strides=strides, padding=\"SAME\")\n",
    "            g_3 = tf.contrib.layers.batch_norm(g_3, is_training=phase_train)\n",
    "            g_3 = tf.nn.relu(g_3)\n",
    "\n",
    "            g_4 = tf.nn.conv3d_transpose(g_3, weights['wg4'], (batch_size,32,32,32,64), strides=strides, padding=\"SAME\")\n",
    "            g_4 = tf.contrib.layers.batch_norm(g_4, is_training=phase_train)\n",
    "            g_4 = tf.nn.relu(g_4)\n",
    "\n",
    "            g_5 = tf.nn.conv3d_transpose(g_4, weights['wg5'], (batch_size,64,64,64,1), strides=strides, padding=\"SAME\")\n",
    "            # g_5 = tf.nn.sigmoid(g_5)\n",
    "            g_5 = tf.nn.tanh(g_5)\n",
    "\n",
    "        print(g_1, 'g1')\n",
    "        print(g_2, 'g2')\n",
    "        print(g_3, 'g3')\n",
    "        print(g_4, 'g4')\n",
    "        print(g_5, 'g5')\n",
    "\n",
    "        return g_5\n",
    "\n",
    "\n",
    "def discriminator(inputs, phase_train=True, reuse=False):\n",
    "    #with tf.device('/device:GPU:0'):\n",
    "        strides    = [1,2,2,2,1]\n",
    "        with tf.variable_scope(\"dis\", reuse=reuse):\n",
    "            d_1 = tf.nn.conv3d(inputs, weights['wd1'], strides=strides, padding=\"SAME\")\n",
    "            d_1 = tf.contrib.layers.batch_norm(d_1, is_training=phase_train)                               \n",
    "            d_1 = lrelu(d_1, leak_value)\n",
    "\n",
    "            d_2 = tf.nn.conv3d(d_1, weights['wd2'], strides=strides, padding=\"SAME\") \n",
    "            d_2 = tf.contrib.layers.batch_norm(d_2, is_training=phase_train)\n",
    "            d_2 = lrelu(d_2, leak_value)\n",
    "\n",
    "            d_3 = tf.nn.conv3d(d_2, weights['wd3'], strides=strides, padding=\"SAME\")  \n",
    "            d_3 = tf.contrib.layers.batch_norm(d_3, is_training=phase_train)\n",
    "            d_3 = lrelu(d_3, leak_value) \n",
    "\n",
    "            d_4 = tf.nn.conv3d(d_3, weights['wd4'], strides=strides, padding=\"SAME\")     \n",
    "            d_4 = tf.contrib.layers.batch_norm(d_4, is_training=phase_train)\n",
    "            d_4 = lrelu(d_4)\n",
    "\n",
    "            d_5 = tf.nn.conv3d(d_4, weights['wd5'], strides=[1,1,1,1,1], padding=\"VALID\")     \n",
    "            d_5_no_sigmoid = d_5\n",
    "            d_5 = tf.nn.sigmoid(d_5)\n",
    "\n",
    "        print(d_1, 'd1')\n",
    "        print(d_2, 'd2')\n",
    "        print(d_3, 'd3')\n",
    "        print(d_4, 'd4')\n",
    "        print(d_5, 'd5')\n",
    "\n",
    "        return d_5, d_5_no_sigmoid\n",
    "\n",
    "def initialiseWeights():\n",
    "    #with tf.device('/device:GPU:0'):\n",
    "        global weights\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "        weights['wg1'] = tf.get_variable(\"wg1\", shape=[4, 4, 4, 512, 200], initializer=xavier_init)\n",
    "        weights['wg2'] = tf.get_variable(\"wg2\", shape=[4, 4, 4, 256, 512], initializer=xavier_init)\n",
    "        weights['wg3'] = tf.get_variable(\"wg3\", shape=[4, 4, 4, 128, 256], initializer=xavier_init)\n",
    "        weights['wg4'] = tf.get_variable(\"wg4\", shape=[4, 4, 4, 64, 128], initializer=xavier_init)\n",
    "        weights['wg5'] = tf.get_variable(\"wg5\", shape=[4, 4, 4, 1, 64], initializer=xavier_init)    \n",
    "\n",
    "        weights['wd1'] = tf.get_variable(\"wd1\", shape=[4, 4, 4, 1, 64], initializer=xavier_init)\n",
    "        weights['wd2'] = tf.get_variable(\"wd2\", shape=[4, 4, 4, 64, 128], initializer=xavier_init)\n",
    "        weights['wd3'] = tf.get_variable(\"wd3\", shape=[4, 4, 4, 128, 256], initializer=xavier_init)\n",
    "        weights['wd4'] = tf.get_variable(\"wd4\", shape=[4, 4, 4, 256, 512], initializer=xavier_init)    \n",
    "        weights['wd5'] = tf.get_variable(\"wd5\", shape=[4, 4, 4, 512, 1], initializer=xavier_init)    \n",
    "\n",
    "        return weights\n",
    "\n",
    "\n",
    "def trainGAN(is_dummy=False, checkpoint=None):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "\n",
    "        weights =  initialiseWeights()\n",
    "\n",
    "        z_vector = tf.placeholder(shape=[batch_size,z_size],dtype=tf.float32) \n",
    "        x_vector = tf.placeholder(shape=[batch_size,cube_len,cube_len,cube_len,1],dtype=tf.float32) \n",
    "\n",
    "        net_g_train = generator(z_vector, phase_train=True, reuse=False) \n",
    "\n",
    "        d_output_x, d_no_sigmoid_output_x = discriminator(x_vector, phase_train=True, reuse=False)\n",
    "        d_output_x = tf.maximum(tf.minimum(d_output_x, 0.99), 0.01)\n",
    "        summary_d_x_hist = tf.summary.histogram(\"d_prob_x\", d_output_x)\n",
    "\n",
    "        d_output_z, d_no_sigmoid_output_z = discriminator(net_g_train, phase_train=True, reuse=True)\n",
    "        d_output_z = tf.maximum(tf.minimum(d_output_z, 0.99), 0.01)\n",
    "        summary_d_z_hist = tf.summary.histogram(\"d_prob_z\", d_output_z)\n",
    "\n",
    "        # Compute the discriminator accuracy\n",
    "        n_p_x = tf.reduce_sum(tf.to_int32(d_output_x > 0.5))\n",
    "        n_p_z = tf.reduce_sum(tf.to_int32(d_output_z < 0.5))\n",
    "        d_acc = tf.divide(n_p_x + n_p_z, 2 * batch_size)\n",
    "\n",
    "        # Compute the discriminator and generator loss\n",
    "        # d_loss = -tf.reduce_mean(tf.log(d_output_x) + tf.log(1-d_output_z))\n",
    "        # g_loss = -tf.reduce_mean(tf.log(d_output_z))\n",
    "\n",
    "        d_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_no_sigmoid_output_x, labels=tf.ones_like(d_output_x)) + tf.nn.sigmoid_cross_entropy_with_logits(logits=d_no_sigmoid_output_z, labels=tf.zeros_like(d_output_z))\n",
    "        g_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_no_sigmoid_output_z, labels=tf.ones_like(d_output_z))\n",
    "\n",
    "        d_loss = tf.reduce_mean(d_loss)\n",
    "        g_loss = tf.reduce_mean(g_loss)\n",
    "\n",
    "        summary_d_loss = tf.summary.scalar(\"d_loss\", d_loss)\n",
    "        summary_g_loss = tf.summary.scalar(\"g_loss\", g_loss)\n",
    "        summary_n_p_z = tf.summary.scalar(\"n_p_z\", n_p_z)\n",
    "        summary_n_p_x = tf.summary.scalar(\"n_p_x\", n_p_x)\n",
    "        summary_d_acc = tf.summary.scalar(\"d_acc\", d_acc)\n",
    "\n",
    "        net_g_test = generator(z_vector, phase_train=False, reuse=True)\n",
    "\n",
    "        para_g = [var for var in tf.trainable_variables() if any(x in var.name for x in ['wg', 'bg', 'gen'])]\n",
    "        para_d = [var for var in tf.trainable_variables() if any(x in var.name for x in ['wd', 'bd', 'dis'])]\n",
    "\n",
    "        # only update the weights for the discriminator network\n",
    "        optimizer_op_d = tf.train.AdamOptimizer(learning_rate=d_lr,beta1=beta).minimize(d_loss,var_list=para_d)\n",
    "        # only update the weights for the generator network\n",
    "        optimizer_op_g = tf.train.AdamOptimizer(learning_rate=g_lr,beta1=beta).minimize(g_loss,var_list=para_g)\n",
    "\n",
    "        saver = tf.train.Saver() \n",
    "        vis = visdom.Visdom()\n",
    "\n",
    "\n",
    "        with tf.Session() as sess:  \n",
    "\n",
    "            sess.run(tf.global_variables_initializer())        \n",
    "            if checkpoint is not None:\n",
    "                saver.restore(sess, checkpoint)        \n",
    "\n",
    "            if is_dummy:\n",
    "                volumes = np.random.randint(0,2,(batch_size,cube_len,cube_len,cube_len))\n",
    "                print('Using Dummy Data')\n",
    "            else:\n",
    "                volumes = d.getAll(obj=obj, train=True, is_local=is_local, obj_ratio=obj_ratio)\n",
    "                print('Using ' + obj + ' Data')\n",
    "            volumes = volumes[...,np.newaxis].astype(np.float)\n",
    "            # volumes *= 2.0\n",
    "            # volumes -= 1.0\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "\n",
    "                idx = np.random.randint(len(volumes), size=batch_size)\n",
    "                x = volumes[idx]\n",
    "                z_sample = np.random.normal(0, 0.33, size=[batch_size, z_size]).astype(np.float32)\n",
    "                z = np.random.normal(0, 0.33, size=[batch_size, z_size]).astype(np.float32)\n",
    "                # z = np.random.uniform(0, 1, size=[batch_size, z_size]).astype(np.float32)\n",
    "\n",
    "                # Update the discriminator and generator\n",
    "                d_summary_merge = tf.summary.merge([summary_d_loss,\n",
    "                                                    summary_d_x_hist, \n",
    "                                                    summary_d_z_hist,\n",
    "                                                    summary_n_p_x,\n",
    "                                                    summary_n_p_z,\n",
    "                                                    summary_d_acc])\n",
    "\n",
    "                summary_d, discriminator_loss = sess.run([d_summary_merge,d_loss],feed_dict={z_vector:z, x_vector:x})\n",
    "                summary_g, generator_loss = sess.run([summary_g_loss,g_loss],feed_dict={z_vector:z})  \n",
    "                d_accuracy, n_x, n_z = sess.run([d_acc, n_p_x, n_p_z],feed_dict={z_vector:z, x_vector:x})\n",
    "                print(n_x, n_z)\n",
    "\n",
    "                if d_accuracy < d_thresh:\n",
    "                    sess.run([optimizer_op_d],feed_dict={z_vector:z, x_vector:x})\n",
    "                    print('Discriminator Training ', \"epoch: \",epoch,', d_loss:',discriminator_loss,'g_loss:',generator_loss, \"d_acc: \", d_accuracy)\n",
    "\n",
    "                sess.run([optimizer_op_g],feed_dict={z_vector:z})\n",
    "                print('Generator Training ', \"epoch: \",epoch,', d_loss:',discriminator_loss,'g_loss:',generator_loss, \"d_acc: \", d_accuracy)\n",
    "\n",
    "                # output generated chairs\n",
    "                if epoch % 200 == 0:\n",
    "                    g_objects = sess.run(net_g_test,feed_dict={z_vector:z_sample})\n",
    "                    if not os.path.exists(train_sample_directory):\n",
    "                        os.makedirs(train_sample_directory)\n",
    "                    g_objects.dump(train_sample_directory+'/biasfree_'+str(epoch))\n",
    "                    id_ch = np.random.randint(0, batch_size, 4)\n",
    "                    for i in range(4):\n",
    "                        if g_objects[id_ch[i]].max() > 0.5:\n",
    "                            d.plotVoxelVisdom(np.squeeze(g_objects[id_ch[i]]>0.5), vis, '_'.join(map(str,[epoch,i])))          \n",
    "                if epoch % 50 == 10:\n",
    "                    if not os.path.exists(model_directory):\n",
    "                        os.makedirs(model_directory)      \n",
    "                    saver.save(sess, save_path = model_directory + '/biasfree_' + str(epoch) + '.cptk')\n",
    "\n",
    "\n",
    "def testGAN(trained_model_path=None, n_batches=40):\n",
    "\n",
    "    weights = initialiseWeights()\n",
    "\n",
    "    z_vector = tf.placeholder(shape=[batch_size,z_size],dtype=tf.float32) \n",
    "    net_g_test = generator(z_vector, phase_train=True, reuse=True)\n",
    "\n",
    "    vis = visdom.Visdom()\n",
    "\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, trained_model_path) \n",
    "\n",
    "        # output generated chairs\n",
    "        for i in range(n_batches):\n",
    "            next_sigma = float(raw_input())\n",
    "            z_sample = np.random.normal(0, next_sigma, size=[batch_size, z_size]).astype(np.float32)\n",
    "            g_objects = sess.run(net_g_test,feed_dict={z_vector:z_sample})\n",
    "            id_ch = np.random.randint(0, batch_size, 4)\n",
    "            for i in range(4):\n",
    "                print(g_objects[id_ch[i]].max(), g_objects[id_ch[i]].min(), g_objects[id_ch[i]].shape)\n",
    "                if g_objects[id_ch[i]].max() > 0.5:\n",
    "                    d.plotVoxelVisdom(np.squeeze(g_objects[id_ch[i]]>0.5), vis, '_'.join(map(str,[i])))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #test = bool(int(sys.argv[1]))\n",
    "    #if test:\n",
    "    #    path = sys.argv[2]\n",
    "    #    testGAN(trained_model_path=path)\n",
    "    #else:\n",
    "    #    ckpt = sys.argv[2]\n",
    "    if True:\n",
    "            trainGAN(is_dummy=False, checkpoint=None)\n",
    "    else:\n",
    "            trainGAN(is_dummy=False, checkpoint=ckpt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
