{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies not loaded, some functionality may not work\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# import visdom\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dataIO as d\n",
    "\n",
    "from tqdm import *\n",
    "from utils import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Global Parameters\n",
    "'''\n",
    "n_epochs   = 20000\n",
    "batch_size = 100\n",
    "g_lr       = 0.0025\n",
    "d_lr       = 0.0001\n",
    "beta       = 0.5\n",
    "d_thresh   = 0.8\n",
    "z_size     = 200\n",
    "leak_value = 0.2\n",
    "cube_len   = 32\n",
    "obj_ratio  = 0.5\n",
    "obj        = 'chair' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'gan-small-airplane-vae'\n",
    "\n",
    "train_sample_directory = './train_sample/' + experiment_name + '/'\n",
    "model_directory = './models/' + experiment_name + '/'\n",
    "img_base_directory = './img/'\n",
    "img_directory = img_base_directory + experiment_name + '/'\n",
    "pickle_base_directory = './pickle/'\n",
    "pickle_directory = pickle_base_directory + experiment_name + '/'\n",
    "is_local = False\n",
    "\n",
    "    \n",
    "weights = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size=batch_size, phase_train=True, reuse=False):\n",
    "\n",
    "    strides    = [2,2,2]\n",
    "\n",
    "    with tf.variable_scope(\"gen\", reuse=reuse):\n",
    "#         z = tf.reshape(z, (batch_size, 1, 1, 1, z_size))\n",
    "        g_1 = tf.layers.dense(z, 256*2*2*2, kernel_initializer=tf.random_normal_initializer(stddev=0.02), name='g1')\n",
    "        g_1 = tf.reshape(g_1, (-1, 2,2,2,256))\n",
    "#         g_1 = tf.nn.conv3d_transpose(z, weights['wg1'], (batch_size,4,4,4,512), strides=[1,1,1,1,1], padding=\"VALID\")\n",
    "        g_1 = tf.layers.batch_normalization(g_1, training=phase_train, name='g_bn1')\n",
    "        g_1 = tf.nn.relu(g_1)\n",
    "\n",
    "        g_2 = tf.layers.conv3d_transpose(g_1, 256, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g2')\n",
    "        g_2 = tf.layers.batch_normalization(g_2, training=phase_train, name='g_bn2')\n",
    "        g_2 = tf.nn.relu(g_2)\n",
    "\n",
    "        g_3 = tf.layers.conv3d_transpose(g_2, 128, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g3')\n",
    "        g_3 = tf.layers.batch_normalization(g_3, training=phase_train, name='g_bn3')\n",
    "        g_3 = tf.nn.relu(g_3)\n",
    "\n",
    "        g_4 = tf.layers.conv3d_transpose(g_3, 64, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g4')\n",
    "        g_4 = tf.layers.batch_normalization(g_4, training=phase_train, name='g_bn4')\n",
    "        g_4 = tf.nn.relu(g_4)\n",
    "        \n",
    "        g_5 = tf.layers.conv3d_transpose(g_4, 1, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g5')\n",
    "        g_5 = tf.nn.sigmoid(g_5)\n",
    "#         g_5 = tf.nn.tanh(g_5)\n",
    "\n",
    "    print (g_1, 'g1')\n",
    "    print (g_2, 'g2')\n",
    "    print (g_3, 'g3')\n",
    "    print (g_4, 'g4')\n",
    "    print (g_5, 'g5')\n",
    "    \n",
    "    return g_5\n",
    "\n",
    "\n",
    "def discriminator(inputs, phase_train=True, reuse=False):\n",
    "\n",
    "    strides    = [2,2,2]\n",
    "    with tf.variable_scope(\"dis\", reuse=reuse):\n",
    "        d_1 = tf.layers.conv3d(inputs, 32, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='d1')\n",
    "        d_1 = tf.layers.batch_normalization(d_1, training=phase_train, name='d_bn1')                               \n",
    "        d_1 = lrelu(d_1, leak_value)\n",
    "\n",
    "        d_2 = tf.layers.conv3d(d_1, 64, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='d2') \n",
    "        d_2 = tf.layers.batch_normalization(d_2, training=phase_train, name='d_bn2')\n",
    "        d_2 = lrelu(d_2, leak_value)\n",
    "        \n",
    "        d_3 = tf.layers.conv3d(d_2, 128, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='d3')  \n",
    "        d_3 = tf.layers.batch_normalization(d_3, training=phase_train, name='d_bn3')\n",
    "        d_3 = lrelu(d_3, leak_value) \n",
    "\n",
    "        d_4 = tf.layers.conv3d(d_3, 256, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='d4')     \n",
    "        d_4 = tf.layers.batch_normalization(d_4, training=phase_train, name='d_bn4')\n",
    "        d_4 = lrelu(d_4)\n",
    "\n",
    "        d_5 = tf.contrib.layers.flatten(d_4)\n",
    "        d_5 = tf.layers.dense(d_5, 1, kernel_initializer=tf.random_normal_initializer(stddev=0.02), name='d5')\n",
    "#         d_5 = tf.nn.conv3d(d_4, weights['wd5'], strides=[1,1,1,1,1], padding=\"VALID\")     \n",
    "        d_5_no_sigmoid = d_5\n",
    "        d_5 = tf.nn.sigmoid(d_5)\n",
    "\n",
    "    print (d_1, 'd1')\n",
    "    print (d_2, 'd2')\n",
    "    print (d_3, 'd3')\n",
    "    print (d_4, 'd4')\n",
    "    print (d_5, 'd5')\n",
    "\n",
    "    return d_5, d_5_no_sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae(input_image, phase_train=True, reuse=False):\n",
    "        with tf.variable_scope(\"vae\", reuse=reuse):\n",
    "            strides=[4, 4]\n",
    "            v_1 = tf.layers.conv2d(input_image, 64, (11,11), strides=strides, padding=\"same\")\n",
    "            v_1 = tf.layers.batch_normalization(v_1, training=phase_train)                               \n",
    "            v_1 = lrelu(v_1, leak_value)\n",
    "            strides=[2, 2]\n",
    "            v_2 = tf.layers.conv2d(v_1, 128, (5,5),strides=strides, padding=\"same\") \n",
    "            v_2 = tf.layers.batch_normalization(v_2, training=phase_train)\n",
    "            v_2 = lrelu(d_2, leak_value)\n",
    "\n",
    "            v_3 = tf.layers.conv2d(v_2, 256,(5,5), strides=strides, padding=\"same\")  \n",
    "            v_3 = tf.layers.batch_normalization(v_3, training=phase_train)\n",
    "            v_3 = lrelu(v_3, leak_value) \n",
    "\n",
    "            v_4 = tf.layers.conv2d(v_3, 512, (5,5), strides=strides, padding=\"same\")     \n",
    "            v_4 = tf.layers.batch_normalization(v_4, training=phase_train)\n",
    "            v_4 = lrelu(v_4, leak_value)\n",
    "            \n",
    "            strides=[1, 1]\n",
    "            v_5 = tf.layers.conv2d(v_4, 400, (8,8), strides=strides, padding=\"valid\")     \n",
    "            v_5 = tf.layers.batch_normalization(v_5, training=phase_train)\n",
    "            v_5 = tf.reshape(v_5, (400))\n",
    "            mean = tf.slice(v_5,[0], [200])\n",
    "            variance = tf.slice(v_5, [200], [400])\n",
    "\n",
    "    return mean, variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseWeights():\n",
    "\n",
    "    global weights\n",
    "    xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "#     weights['wg1'] = tf.get_variable(\"wg1\", shape=[4, 4, 4, 512, 200], initializer=xavier_init)\n",
    "    weights['wg2'] = tf.get_variable(\"wg2\", shape=[4, 4, 4, 256, 256], initializer=xavier_init)\n",
    "    weights['wg3'] = tf.get_variable(\"wg3\", shape=[4, 4, 4, 128, 256], initializer=xavier_init)\n",
    "    weights['wg4'] = tf.get_variable(\"wg4\", shape=[4, 4, 4, 64, 128], initializer=xavier_init)\n",
    "    weights['wg5'] = tf.get_variable(\"wg5\", shape=[4, 4, 4, 1, 64], initializer=xavier_init)    \n",
    "\n",
    "    weights['wd1'] = tf.get_variable(\"wd1\", shape=[4, 4, 4, 1, 32], initializer=xavier_init)\n",
    "    weights['wd2'] = tf.get_variable(\"wd2\", shape=[4, 4, 4, 32, 64], initializer=xavier_init)\n",
    "    weights['wd3'] = tf.get_variable(\"wd3\", shape=[4, 4, 4, 64, 128], initializer=xavier_init)\n",
    "    weights['wd4'] = tf.get_variable(\"wd4\", shape=[4, 4, 4, 128, 256], initializer=xavier_init)    \n",
    "#     weights['wd5'] = tf.get_variable(\"wd5\", shape=[4, 4, 4, 256, 1], initializer=xavier_init)    \n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGAN(is_dummy=False, checkpoint=None):\n",
    "\n",
    "    weights =  initialiseWeights()\n",
    "\n",
    "    z_vector = tf.placeholder(shape=[batch_size,z_size],dtype=tf.float32) \n",
    "    x_vector = tf.placeholder(shape=[batch_size,cube_len,cube_len,cube_len,1],dtype=tf.float32) \n",
    "\n",
    "    net_g_train = generator(z_vector, phase_train=True, reuse=False) \n",
    "\n",
    "    d_output_x, d_no_sigmoid_output_x = discriminator(x_vector, phase_train=True, reuse=False)\n",
    "    d_output_x = tf.maximum(tf.minimum(d_output_x, 0.99), 0.01)\n",
    "    summary_d_x_hist = tf.summary.histogram(\"d_prob_x\", d_output_x)\n",
    "\n",
    "    d_output_z, d_no_sigmoid_output_z = discriminator(net_g_train, phase_train=True, reuse=True)\n",
    "    d_output_z = tf.maximum(tf.minimum(d_output_z, 0.99), 0.01)\n",
    "    summary_d_z_hist = tf.summary.histogram(\"d_prob_z\", d_output_z)\n",
    "\n",
    "    # Compute the discriminator accuracy\n",
    "    n_p_x = tf.reduce_sum(tf.cast(d_output_x > 0.5, tf.int32))\n",
    "    n_p_z = tf.reduce_sum(tf.cast(d_output_z < 0.5, tf.int32))\n",
    "    d_acc = tf.divide(n_p_x + n_p_z, 2 * batch_size)\n",
    "\n",
    "    # Compute the discriminator and generator loss\n",
    "   # d_loss = -tf.reduce_mean(tf.log(d_output_x) + tf.log(1-d_output_z))\n",
    "  #  g_loss = -tf.reduce_mean(tf.log(d_output_z))\n",
    "\n",
    "    d_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_no_sigmoid_output_x, labels=tf.ones_like(d_output_x)) + tf.nn.sigmoid_cross_entropy_with_logits(logits=d_no_sigmoid_output_z, labels=tf.zeros_like(d_output_z)))\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_no_sigmoid_output_z, labels=tf.ones_like(d_output_z)))\n",
    "    \n",
    "#     d_loss = tf.reduce_mean(d_loss)\n",
    "#     g_loss = tf.reduce_mean(g_loss)\n",
    "\n",
    "    summary_d_loss = tf.summary.scalar(\"d_loss\", d_loss)\n",
    "    summary_g_loss = tf.summary.scalar(\"g_loss\", g_loss)\n",
    "    summary_n_p_z = tf.summary.scalar(\"n_p_z\", n_p_z)\n",
    "    summary_n_p_x = tf.summary.scalar(\"n_p_x\", n_p_x)\n",
    "    summary_d_acc = tf.summary.scalar(\"d_acc\", d_acc)\n",
    "\n",
    "    net_g_test = generator(z_vector, phase_train=False, reuse=True)\n",
    "\n",
    "    para_g = [var for var in tf.trainable_variables() if any(x in var.name for x in ['wg', 'bg', 'g_bn', 'gen'])]\n",
    "    para_d = [var for var in tf.trainable_variables() if any(x in var.name for x in ['wd', 'bd', 'd_bn', 'dis'])]\n",
    "    #update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    #with tf.control_dependencies(update_ops):\n",
    "        # only update the weights for the discriminator network\n",
    "    optimizer_op_d = tf.train.AdamOptimizer(learning_rate=d_lr,beta1=beta).minimize(d_loss,var_list=para_d)\n",
    "        # only update the weights for the generator network\n",
    "    optimizer_op_g = tf.train.AdamOptimizer(learning_rate=g_lr,beta1=beta).minimize(g_loss,var_list=para_g)\n",
    "\n",
    "    saver = tf.train.Saver() \n",
    "#     vis = visdom.Visdom()\n",
    "\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    with tf.Session() as sess:  \n",
    "      \n",
    "        sess.run(tf.global_variables_initializer())   \n",
    "\n",
    "        if checkpoint is not None:\n",
    "            saver.restore(sess, checkpoint)        \n",
    "\n",
    "        if is_dummy:\n",
    "            volumes = np.random.randint(0,2,(batch_size,cube_len,cube_len,cube_len))\n",
    "            print ('Using Dummy Data')\n",
    "        else:\n",
    "            volumes = d.getAll(obj=obj, train=True, is_local=is_local, obj_ratio=obj_ratio, cube_len=32)\n",
    "            print ('Using ' + obj + ' Data')\n",
    "        volumes = volumes[...,np.newaxis].astype(np.float)\n",
    "    \n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            idx = np.random.randint(len(volumes), size=batch_size)\n",
    "            x = volumes[idx]\n",
    "            z_sample = np.random.normal(0, 0.33, size=[batch_size, z_size]).astype(np.float32)\n",
    "            z = np.random.normal(0, 0.33, size=[batch_size, z_size]).astype(np.float32)\n",
    "            # Update the discriminator and generator\n",
    "            d_summary_merge = tf.summary.merge([summary_d_loss,\n",
    "                                                summary_d_x_hist, \n",
    "                                                summary_d_z_hist,\n",
    "                                                summary_n_p_x,\n",
    "                                                summary_n_p_z,\n",
    "                                                summary_d_acc])\n",
    "\n",
    "            summary_d, discriminator_loss = sess.run([d_summary_merge,d_loss],feed_dict={z_vector:z, x_vector:x})\n",
    "            summary_g, generator_loss = sess.run([summary_g_loss,g_loss],feed_dict={z_vector:z})  \n",
    "            d_accuracy, n_x, n_z = sess.run([d_acc, n_p_x, n_p_z],feed_dict={z_vector:z, x_vector:x})\n",
    "            print (n_x, n_z)\n",
    "            \n",
    "            d_losses.append(discriminator_loss)\n",
    "            g_losses.append(generator_loss)\n",
    "\n",
    "            if d_accuracy < d_thresh:\n",
    "                sess.run([optimizer_op_d],feed_dict={z_vector:z, x_vector:x})\n",
    "                print ('Discriminator Training ', \"epoch: \",epoch,', d_loss:',discriminator_loss,'g_loss:',generator_loss, \"d_acc: \", d_accuracy)\n",
    "\n",
    "            sess.run([optimizer_op_g],feed_dict={z_vector:z})\n",
    "            print ('Generator Training ', \"epoch: \",epoch,', d_loss:',discriminator_loss,'g_loss:',generator_loss, \"d_acc: \", d_accuracy)\n",
    "\n",
    "            # output generated chairs\n",
    "            if epoch % 200 == 0:\n",
    "                g_objects = sess.run(net_g_test,feed_dict={z_vector:z_sample})\n",
    "                if not os.path.exists(train_sample_directory):\n",
    "                    os.makedirs(train_sample_directory)\n",
    "                    \n",
    "                if not os.path.exists(img_directory):\n",
    "                    os.makedirs(img_directory)\n",
    "                    \n",
    "                if not os.path.exists(pickle_directory):\n",
    "                    os.makedirs(pickle_directory)\n",
    "                    \n",
    "                g_objects.dump(train_sample_directory+'/biasfree_'+str(epoch))\n",
    "                id_ch = np.random.randint(0, batch_size, 4)\n",
    "                \n",
    "                with open(pickle_directory + 'd_loss.pickle', 'wb') as file:\n",
    "                    pickle.dump(d_losses, file)\n",
    "                with open(pickle_directory + 'g_loss.pickle', 'wb') as file:\n",
    "                    pickle.dump(g_losses, file)\n",
    "                \n",
    "                for i in range(4):\n",
    "                    if g_objects[id_ch[i]].max() > 0.5:\n",
    "                        objects = np.squeeze(g_objects[id_ch[i]]>0.5)\n",
    "                        d.plotFromVoxels(objects, img_directory+'{}_{}.png'.format(str(epoch), str(i)))\n",
    "            if epoch % 50 == 10:\n",
    "                if not os.path.exists(model_directory):\n",
    "                    os.makedirs(model_directory)      \n",
    "                saver.save(sess, save_path = model_directory + '/biasfree_' + str(epoch) + '.cptk')\n",
    "\n",
    "\n",
    "def testGAN(trained_model_path=None, n_batches=40):\n",
    "\n",
    "    weights = initialiseWeights()\n",
    "\n",
    "    z_vector = tf.placeholder(shape=[batch_size,z_size],dtype=tf.float32) \n",
    "    net_g_test = generator(z_vector, phase_train=True, reuse=True)\n",
    "\n",
    "#     vis = visdom.Visdom()\n",
    "\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, trained_model_path) \n",
    "\n",
    "        # output generated chairs\n",
    "        for i in range(n_batches):\n",
    "            next_sigma = float(raw_input())\n",
    "            z_sample = np.random.normal(0, next_sigma, size=[batch_size, z_size]).astype(np.float32)\n",
    "            g_objects = sess.run(net_g_test,feed_dict={z_vector:z_sample})\n",
    "            id_ch = np.random.randint(0, batch_size, 4)\n",
    "            for i in range(4):\n",
    "                print( g_objects[id_ch[i]].max(), g_objects[id_ch[i]].min(), g_objects[id_ch[i]].shape)\n",
    "                if g_objects[id_ch[i]].max() > 0.5:\n",
    "                    pass\n",
    "#                     d.plotVoxelVisdom(np.squeeze(g_objects[id_ch[i]]>0.5), vis, '_'.join(map(str,[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gen/Relu:0\", shape=(100, 2, 2, 2, 256), dtype=float32) g1\n",
      "Tensor(\"gen/Relu_1:0\", shape=(100, 4, 4, 4, 256), dtype=float32) g2\n",
      "Tensor(\"gen/Relu_2:0\", shape=(100, 8, 8, 8, 128), dtype=float32) g3\n",
      "Tensor(\"gen/Relu_3:0\", shape=(100, 16, 16, 16, 64), dtype=float32) g4\n",
      "Tensor(\"gen/Sigmoid:0\", shape=(100, 32, 32, 32, 1), dtype=float32) g5\n",
      "Tensor(\"dis/Maximum:0\", shape=(100, 16, 16, 16, 32), dtype=float32) d1\n",
      "Tensor(\"dis/Maximum_1:0\", shape=(100, 8, 8, 8, 64), dtype=float32) d2\n",
      "Tensor(\"dis/Maximum_2:0\", shape=(100, 4, 4, 4, 128), dtype=float32) d3\n",
      "Tensor(\"dis/Maximum_3:0\", shape=(100, 2, 2, 2, 256), dtype=float32) d4\n",
      "Tensor(\"dis/Sigmoid:0\", shape=(100, 1), dtype=float32) d5\n",
      "Tensor(\"dis_1/Maximum:0\", shape=(100, 16, 16, 16, 32), dtype=float32) d1\n",
      "Tensor(\"dis_1/Maximum_1:0\", shape=(100, 8, 8, 8, 64), dtype=float32) d2\n",
      "Tensor(\"dis_1/Maximum_2:0\", shape=(100, 4, 4, 4, 128), dtype=float32) d3\n",
      "Tensor(\"dis_1/Maximum_3:0\", shape=(100, 2, 2, 2, 256), dtype=float32) d4\n",
      "Tensor(\"dis_1/Sigmoid:0\", shape=(100, 1), dtype=float32) d5\n",
      "Tensor(\"gen_1/Relu:0\", shape=(100, 2, 2, 2, 256), dtype=float32) g1\n",
      "Tensor(\"gen_1/Relu_1:0\", shape=(100, 4, 4, 4, 256), dtype=float32) g2\n",
      "Tensor(\"gen_1/Relu_2:0\", shape=(100, 8, 8, 8, 128), dtype=float32) g3\n",
      "Tensor(\"gen_1/Relu_3:0\", shape=(100, 16, 16, 16, 64), dtype=float32) g4\n",
      "Tensor(\"gen_1/Sigmoid:0\", shape=(100, 32, 32, 32, 1), dtype=float32) g5\n",
      "INFO:tensorflow:Restoring parameters from /home/vamsi/Downloads/tf-3dgan-master/src/models/gan-small-airplane/biasfree_7810.cptk\n",
      "Using chair Data\n",
      "93 63\n",
      "Discriminator Training  epoch:  0 , d_loss: 1.0487145 g_loss: 0.7303781 d_acc:  0.78\n",
      "Generator Training  epoch:  0 , d_loss: 1.0487145 g_loss: 0.7303781 d_acc:  0.78\n",
      "0 100\n",
      "Discriminator Training  epoch:  1 , d_loss: 4.735359 g_loss: 7.4528804 d_acc:  0.5\n",
      "Generator Training  epoch:  1 , d_loss: 4.735359 g_loss: 7.4528804 d_acc:  0.5\n",
      "100 0\n",
      "Discriminator Training  epoch:  2 , d_loss: 2.7542143 g_loss: 0.10746331 d_acc:  0.5\n",
      "Generator Training  epoch:  2 , d_loss: 2.7542143 g_loss: 0.10746331 d_acc:  0.5\n",
      "10 100\n",
      "Discriminator Training  epoch:  3 , d_loss: 3.1696992 g_loss: 4.2799425 d_acc:  0.55\n",
      "Generator Training  epoch:  3 , d_loss: 3.1696992 g_loss: 4.2799425 d_acc:  0.55\n",
      "74 97\n",
      "Generator Training  epoch:  4 , d_loss: 0.81508064 g_loss: 1.6024983 d_acc:  0.855\n",
      "76 44\n",
      "Discriminator Training  epoch:  5 , d_loss: 1.3130045 g_loss: 0.75898826 d_acc:  0.6\n",
      "Generator Training  epoch:  5 , d_loss: 1.3130045 g_loss: 0.75898826 d_acc:  0.6\n",
      "95 94\n",
      "Generator Training  epoch:  6 , d_loss: 0.46131995 g_loss: 1.6079285 d_acc:  0.945\n",
      "99 61\n",
      "Generator Training  epoch:  7 , d_loss: 0.8332287 g_loss: 0.82073885 d_acc:  0.8\n",
      "100 14\n",
      "Discriminator Training  epoch:  8 , d_loss: 1.2413188 g_loss: 0.45228732 d_acc:  0.57\n",
      "Generator Training  epoch:  8 , d_loss: 1.2413188 g_loss: 0.45228732 d_acc:  0.57\n",
      "52 100\n",
      "Discriminator Training  epoch:  9 , d_loss: 0.9951639 g_loss: 3.6114702 d_acc:  0.76\n",
      "Generator Training  epoch:  9 , d_loss: 0.9951639 g_loss: 3.6114702 d_acc:  0.76\n",
      "86 89\n",
      "Generator Training  epoch:  10 , d_loss: 0.7112714 g_loss: 1.6316295 d_acc:  0.875\n",
      "88 32\n",
      "Discriminator Training  epoch:  11 , d_loss: 1.2520857 g_loss: 0.70699894 d_acc:  0.6\n",
      "Generator Training  epoch:  11 , d_loss: 1.2520857 g_loss: 0.70699894 d_acc:  0.6\n",
      "59 86\n",
      "Discriminator Training  epoch:  12 , d_loss: 1.1865914 g_loss: 1.8422434 d_acc:  0.725\n",
      "Generator Training  epoch:  12 , d_loss: 1.1865914 g_loss: 1.8422434 d_acc:  0.725\n",
      "91 82\n",
      "Generator Training  epoch:  13 , d_loss: 0.71206474 g_loss: 1.2197326 d_acc:  0.865\n",
      "91 47\n",
      "Discriminator Training  epoch:  14 , d_loss: 1.1227183 g_loss: 0.6970829 d_acc:  0.69\n",
      "Generator Training  epoch:  14 , d_loss: 1.1227183 g_loss: 0.6970829 d_acc:  0.69\n",
      "42 100\n",
      "Discriminator Training  epoch:  15 , d_loss: 0.9712419 g_loss: 3.076275 d_acc:  0.71\n",
      "Generator Training  epoch:  15 , d_loss: 0.9712419 g_loss: 3.076275 d_acc:  0.71\n",
      "94 98\n",
      "Generator Training  epoch:  16 , d_loss: 0.5372207 g_loss: 1.6046011 d_acc:  0.96\n",
      "98 71\n",
      "Generator Training  epoch:  17 , d_loss: 0.69392914 g_loss: 1.0857322 d_acc:  0.845\n",
      "96 49\n",
      "Discriminator Training  epoch:  18 , d_loss: 1.061096 g_loss: 0.6813559 d_acc:  0.725\n",
      "Generator Training  epoch:  18 , d_loss: 1.061096 g_loss: 0.6813559 d_acc:  0.725\n",
      "80 100\n",
      "Generator Training  epoch:  19 , d_loss: 0.61561894 g_loss: 2.5374522 d_acc:  0.9\n",
      "69 89\n",
      "Discriminator Training  epoch:  20 , d_loss: 0.92347324 g_loss: 2.0217981 d_acc:  0.79\n",
      "Generator Training  epoch:  20 , d_loss: 0.92347324 g_loss: 2.0217981 d_acc:  0.79\n",
      "85 100\n",
      "Generator Training  epoch:  21 , d_loss: 0.5653353 g_loss: 1.9175586 d_acc:  0.925\n",
      "94 95\n",
      "Generator Training  epoch:  22 , d_loss: 0.6352555 g_loss: 1.3825512 d_acc:  0.945\n",
      "90 67\n",
      "Discriminator Training  epoch:  23 , d_loss: 0.903311 g_loss: 0.9166966 d_acc:  0.785\n",
      "Generator Training  epoch:  23 , d_loss: 0.903311 g_loss: 0.9166966 d_acc:  0.785\n",
      "58 100\n",
      "Discriminator Training  epoch:  24 , d_loss: 0.78801876 g_loss: 2.3979626 d_acc:  0.79\n",
      "Generator Training  epoch:  24 , d_loss: 0.78801876 g_loss: 2.3979626 d_acc:  0.79\n",
      "97 90\n",
      "Generator Training  epoch:  25 , d_loss: 0.5617839 g_loss: 1.2638884 d_acc:  0.935\n",
      "99 50\n",
      "Discriminator Training  epoch:  26 , d_loss: 0.8382781 g_loss: 0.7039835 d_acc:  0.745\n",
      "Generator Training  epoch:  26 , d_loss: 0.8382781 g_loss: 0.7039835 d_acc:  0.745\n",
      "83 100\n",
      "Generator Training  epoch:  27 , d_loss: 0.5294924 g_loss: 2.6657517 d_acc:  0.915\n",
      "77 100\n",
      "Generator Training  epoch:  28 , d_loss: 0.7121705 g_loss: 1.7843747 d_acc:  0.885\n",
      "76 79\n",
      "Discriminator Training  epoch:  29 , d_loss: 0.9845036 g_loss: 1.0937468 d_acc:  0.775\n",
      "Generator Training  epoch:  29 , d_loss: 0.9845036 g_loss: 1.0937468 d_acc:  0.775\n",
      "41 100\n",
      "Discriminator Training  epoch:  30 , d_loss: 1.1384803 g_loss: 2.1611903 d_acc:  0.705\n",
      "Generator Training  epoch:  30 , d_loss: 1.1384803 g_loss: 2.1611903 d_acc:  0.705\n",
      "98 43\n",
      "Discriminator Training  epoch:  31 , d_loss: 1.0062696 g_loss: 0.7309209 d_acc:  0.705\n",
      "Generator Training  epoch:  31 , d_loss: 1.0062696 g_loss: 0.7309209 d_acc:  0.705\n",
      "90 100\n",
      "Generator Training  epoch:  32 , d_loss: 0.4506195 g_loss: 3.015199 d_acc:  0.95\n",
      "66 100\n",
      "Generator Training  epoch:  33 , d_loss: 0.79142964 g_loss: 2.1405249 d_acc:  0.83\n",
      "66 86\n",
      "Discriminator Training  epoch:  34 , d_loss: 0.9618591 g_loss: 1.3788353 d_acc:  0.76\n",
      "Generator Training  epoch:  34 , d_loss: 0.9618591 g_loss: 1.3788353 d_acc:  0.76\n",
      "66 99\n",
      "Generator Training  epoch:  35 , d_loss: 0.84692687 g_loss: 2.034681 d_acc:  0.825\n",
      "63 91\n",
      "Discriminator Training  epoch:  36 , d_loss: 0.9951628 g_loss: 1.4666811 d_acc:  0.77\n",
      "Generator Training  epoch:  36 , d_loss: 0.9951628 g_loss: 1.4666811 d_acc:  0.77\n",
      "95 100\n",
      "Generator Training  epoch:  37 , d_loss: 0.5708629 g_loss: 1.3892211 d_acc:  0.975\n",
      "93 44\n",
      "Discriminator Training  epoch:  38 , d_loss: 1.0302523 g_loss: 0.7349009 d_acc:  0.685\n",
      "Generator Training  epoch:  38 , d_loss: 1.0302523 g_loss: 0.7349009 d_acc:  0.685\n",
      "25 100\n",
      "Discriminator Training  epoch:  39 , d_loss: 1.1605198 g_loss: 3.410296 d_acc:  0.625\n",
      "Generator Training  epoch:  39 , d_loss: 1.1605198 g_loss: 3.410296 d_acc:  0.625\n",
      "100 62\n",
      "Generator Training  epoch:  40 , d_loss: 0.77191234 g_loss: 0.8586515 d_acc:  0.81\n",
      "100 23\n",
      "Discriminator Training  epoch:  41 , d_loss: 1.1759136 g_loss: 0.49959406 d_acc:  0.615\n",
      "Generator Training  epoch:  41 , d_loss: 1.1759136 g_loss: 0.49959406 d_acc:  0.615\n",
      "58 100\n",
      "Discriminator Training  epoch:  42 , d_loss: 0.8414953 g_loss: 3.6180918 d_acc:  0.79\n",
      "Generator Training  epoch:  42 , d_loss: 0.8414953 g_loss: 3.6180918 d_acc:  0.79\n",
      "99 100\n",
      "Generator Training  epoch:  43 , d_loss: 0.32608995 g_loss: 2.2936263 d_acc:  0.995\n",
      "96 98\n",
      "Generator Training  epoch:  44 , d_loss: 0.5353815 g_loss: 1.5357525 d_acc:  0.97\n",
      "96 80\n",
      "Generator Training  epoch:  45 , d_loss: 0.8519473 g_loss: 0.9097892 d_acc:  0.88\n",
      "94 15\n",
      "Discriminator Training  epoch:  46 , d_loss: 1.304585 g_loss: 0.48950183 d_acc:  0.545\n",
      "Generator Training  epoch:  46 , d_loss: 1.304585 g_loss: 0.48950183 d_acc:  0.545\n",
      "53 100\n",
      "Discriminator Training  epoch:  47 , d_loss: 0.8240849 g_loss: 2.488381 d_acc:  0.765\n",
      "Generator Training  epoch:  47 , d_loss: 0.8240849 g_loss: 2.488381 d_acc:  0.765\n",
      "99 94\n",
      "Generator Training  epoch:  48 , d_loss: 0.53955144 g_loss: 1.4762248 d_acc:  0.965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 70\n",
      "Generator Training  epoch:  49 , d_loss: 0.82240313 g_loss: 0.86754894 d_acc:  0.84\n",
      "98 19\n",
      "Discriminator Training  epoch:  50 , d_loss: 1.2666507 g_loss: 0.5060374 d_acc:  0.585\n",
      "Generator Training  epoch:  50 , d_loss: 1.2666507 g_loss: 0.5060374 d_acc:  0.585\n",
      "40 100\n",
      "Discriminator Training  epoch:  51 , d_loss: 1.0099533 g_loss: 2.980989 d_acc:  0.7\n",
      "Generator Training  epoch:  51 , d_loss: 1.0099533 g_loss: 2.980989 d_acc:  0.7\n",
      "98 99\n",
      "Generator Training  epoch:  52 , d_loss: 0.49566245 g_loss: 1.463772 d_acc:  0.985\n",
      "97 93\n",
      "Generator Training  epoch:  53 , d_loss: 0.6594924 g_loss: 1.1132352 d_acc:  0.95\n",
      "100 51\n",
      "Discriminator Training  epoch:  54 , d_loss: 0.8970816 g_loss: 0.722749 d_acc:  0.755\n",
      "Generator Training  epoch:  54 , d_loss: 0.8970816 g_loss: 0.722749 d_acc:  0.755\n",
      "83 100\n",
      "Generator Training  epoch:  55 , d_loss: 0.54119736 g_loss: 2.214251 d_acc:  0.915\n",
      "73 100\n",
      "Generator Training  epoch:  56 , d_loss: 0.7298344 g_loss: 1.7672698 d_acc:  0.865\n",
      "88 100\n",
      "Generator Training  epoch:  57 , d_loss: 0.6597265 g_loss: 1.522211 d_acc:  0.94\n",
      "78 91\n",
      "Generator Training  epoch:  58 , d_loss: 0.93758017 g_loss: 1.1519215 d_acc:  0.845\n",
      "84 65\n",
      "Discriminator Training  epoch:  59 , d_loss: 1.0437047 g_loss: 0.8244027 d_acc:  0.745\n",
      "Generator Training  epoch:  59 , d_loss: 1.0437047 g_loss: 0.8244027 d_acc:  0.745\n",
      "13 100\n",
      "Discriminator Training  epoch:  60 , d_loss: 1.4412136 g_loss: 2.913493 d_acc:  0.565\n",
      "Generator Training  epoch:  60 , d_loss: 1.4412136 g_loss: 2.913493 d_acc:  0.565\n",
      "100 28\n",
      "Discriminator Training  epoch:  61 , d_loss: 1.0894282 g_loss: 0.5209236 d_acc:  0.64\n",
      "Generator Training  epoch:  61 , d_loss: 1.0894282 g_loss: 0.5209236 d_acc:  0.64\n",
      "42 100\n",
      "Discriminator Training  epoch:  62 , d_loss: 0.9676927 g_loss: 2.9039733 d_acc:  0.71\n",
      "Generator Training  epoch:  62 , d_loss: 0.9676927 g_loss: 2.9039733 d_acc:  0.71\n",
      "98 99\n",
      "Generator Training  epoch:  63 , d_loss: 0.5821749 g_loss: 1.3444055 d_acc:  0.985\n",
      "93 65\n",
      "Discriminator Training  epoch:  64 , d_loss: 0.89538586 g_loss: 0.86368376 d_acc:  0.79\n",
      "Generator Training  epoch:  64 , d_loss: 0.89538586 g_loss: 0.86368376 d_acc:  0.79\n",
      "93 92\n",
      "Generator Training  epoch:  65 , d_loss: 0.672248 g_loss: 1.2482913 d_acc:  0.925\n",
      "88 66\n",
      "Discriminator Training  epoch:  66 , d_loss: 1.0377853 g_loss: 0.8031125 d_acc:  0.77\n",
      "Generator Training  epoch:  66 , d_loss: 1.0377853 g_loss: 0.8031125 d_acc:  0.77\n",
      "57 100\n",
      "Discriminator Training  epoch:  67 , d_loss: 0.82265306 g_loss: 2.214333 d_acc:  0.785\n",
      "Generator Training  epoch:  67 , d_loss: 0.82265306 g_loss: 2.214333 d_acc:  0.785\n",
      "96 100\n",
      "Generator Training  epoch:  68 , d_loss: 0.5337442 g_loss: 1.6442076 d_acc:  0.98\n",
      "93 72\n",
      "Generator Training  epoch:  69 , d_loss: 0.8470208 g_loss: 1.0349665 d_acc:  0.825\n",
      "97 45\n",
      "Discriminator Training  epoch:  70 , d_loss: 0.94529986 g_loss: 0.806164 d_acc:  0.71\n",
      "Generator Training  epoch:  70 , d_loss: 0.94529986 g_loss: 0.806164 d_acc:  0.71\n",
      "73 96\n",
      "Generator Training  epoch:  71 , d_loss: 0.7880903 g_loss: 1.9231278 d_acc:  0.845\n",
      "66 93\n",
      "Discriminator Training  epoch:  72 , d_loss: 0.89956516 g_loss: 1.5096855 d_acc:  0.795\n",
      "Generator Training  epoch:  72 , d_loss: 0.89956516 g_loss: 1.5096855 d_acc:  0.795\n",
      "79 100\n",
      "Generator Training  epoch:  73 , d_loss: 0.72409916 g_loss: 1.7675061 d_acc:  0.895\n",
      "81 83\n",
      "Generator Training  epoch:  74 , d_loss: 0.9865804 g_loss: 0.9785822 d_acc:  0.82\n",
      "84 45\n",
      "Discriminator Training  epoch:  75 , d_loss: 1.220153 g_loss: 0.7183835 d_acc:  0.645\n",
      "Generator Training  epoch:  75 , d_loss: 1.220153 g_loss: 0.7183835 d_acc:  0.645\n",
      "45 100\n",
      "Discriminator Training  epoch:  76 , d_loss: 1.1149724 g_loss: 1.811005 d_acc:  0.725\n",
      "Generator Training  epoch:  76 , d_loss: 1.1149724 g_loss: 1.811005 d_acc:  0.725\n",
      "98 82\n",
      "Generator Training  epoch:  77 , d_loss: 0.73687255 g_loss: 0.9054873 d_acc:  0.9\n",
      "99 39\n",
      "Discriminator Training  epoch:  78 , d_loss: 0.97555995 g_loss: 0.62115514 d_acc:  0.69\n",
      "Generator Training  epoch:  78 , d_loss: 0.97555995 g_loss: 0.62115514 d_acc:  0.69\n",
      "49 100\n",
      "Discriminator Training  epoch:  79 , d_loss: 0.81705964 g_loss: 3.3031104 d_acc:  0.745\n",
      "Generator Training  epoch:  79 , d_loss: 0.81705964 g_loss: 3.3031104 d_acc:  0.745\n",
      "99 96\n",
      "Generator Training  epoch:  80 , d_loss: 0.3818251 g_loss: 1.694275 d_acc:  0.975\n",
      "99 95\n",
      "Generator Training  epoch:  81 , d_loss: 0.5889163 g_loss: 1.24674 d_acc:  0.97\n",
      "98 60\n",
      "Discriminator Training  epoch:  82 , d_loss: 0.840456 g_loss: 0.7836656 d_acc:  0.79\n",
      "Generator Training  epoch:  82 , d_loss: 0.840456 g_loss: 0.7836656 d_acc:  0.79\n",
      "79 100\n",
      "Generator Training  epoch:  83 , d_loss: 0.71630377 g_loss: 2.111354 d_acc:  0.895\n",
      "80 100\n",
      "Generator Training  epoch:  84 , d_loss: 0.7118773 g_loss: 1.6523556 d_acc:  0.9\n",
      "85 98\n",
      "Generator Training  epoch:  85 , d_loss: 0.8054161 g_loss: 1.3100476 d_acc:  0.915\n",
      "87 80\n",
      "Generator Training  epoch:  86 , d_loss: 0.9436042 g_loss: 1.0117779 d_acc:  0.835\n",
      "87 42\n",
      "Discriminator Training  epoch:  87 , d_loss: 1.208946 g_loss: 0.6839931 d_acc:  0.645\n",
      "Generator Training  epoch:  87 , d_loss: 1.208946 g_loss: 0.6839931 d_acc:  0.645\n",
      "7 100\n",
      "Discriminator Training  epoch:  88 , d_loss: 1.5859197 g_loss: 2.944958 d_acc:  0.535\n",
      "Generator Training  epoch:  88 , d_loss: 1.5859197 g_loss: 2.944958 d_acc:  0.535\n",
      "96 40\n",
      "Discriminator Training  epoch:  89 , d_loss: 0.92806274 g_loss: 0.83571744 d_acc:  0.68\n",
      "Generator Training  epoch:  89 , d_loss: 0.92806274 g_loss: 0.83571744 d_acc:  0.68\n",
      "97 90\n",
      "Generator Training  epoch:  90 , d_loss: 0.5889356 g_loss: 1.3670154 d_acc:  0.935\n",
      "94 73\n",
      "Generator Training  epoch:  91 , d_loss: 0.84102166 g_loss: 0.95362866 d_acc:  0.835\n",
      "90 21\n",
      "Discriminator Training  epoch:  92 , d_loss: 1.2780535 g_loss: 0.5361094 d_acc:  0.555\n",
      "Generator Training  epoch:  92 , d_loss: 1.2780535 g_loss: 0.5361094 d_acc:  0.555\n",
      "10 100\n",
      "Discriminator Training  epoch:  93 , d_loss: 1.527363 g_loss: 2.888762 d_acc:  0.55\n",
      "Generator Training  epoch:  93 , d_loss: 1.527363 g_loss: 2.888762 d_acc:  0.55\n",
      "96 87\n",
      "Generator Training  epoch:  94 , d_loss: 0.6781728 g_loss: 1.0713968 d_acc:  0.915\n",
      "94 42\n",
      "Discriminator Training  epoch:  95 , d_loss: 1.0112412 g_loss: 0.73576474 d_acc:  0.68\n",
      "Generator Training  epoch:  95 , d_loss: 1.0112412 g_loss: 0.73576474 d_acc:  0.68\n",
      "89 98\n",
      "Generator Training  epoch:  96 , d_loss: 0.6416657 g_loss: 1.5124007 d_acc:  0.935\n",
      "95 93\n",
      "Generator Training  epoch:  97 , d_loss: 0.72253716 g_loss: 1.2003025 d_acc:  0.94\n",
      "96 76\n",
      "Generator Training  epoch:  98 , d_loss: 0.8424245 g_loss: 0.8993657 d_acc:  0.86\n",
      "88 37\n",
      "Discriminator Training  epoch:  99 , d_loss: 1.1596593 g_loss: 0.63533115 d_acc:  0.625\n",
      "Generator Training  epoch:  99 , d_loss: 1.1596593 g_loss: 0.63533115 d_acc:  0.625\n",
      "30 100\n",
      "Discriminator Training  epoch:  100 , d_loss: 1.1621916 g_loss: 2.6010993 d_acc:  0.65\n",
      "Generator Training  epoch:  100 , d_loss: 1.1621916 g_loss: 2.6010993 d_acc:  0.65\n",
      "99 91\n",
      "Generator Training  epoch:  101 , d_loss: 0.6610656 g_loss: 1.1771504 d_acc:  0.95\n",
      "100 79\n",
      "Generator Training  epoch:  102 , d_loss: 0.728706 g_loss: 1.0153672 d_acc:  0.895\n",
      "100 44\n",
      "Discriminator Training  epoch:  103 , d_loss: 0.91506934 g_loss: 0.71678436 d_acc:  0.72\n",
      "Generator Training  epoch:  103 , d_loss: 0.91506934 g_loss: 0.71678436 d_acc:  0.72\n",
      "73 100\n",
      "Generator Training  epoch:  104 , d_loss: 0.71227837 g_loss: 1.9041537 d_acc:  0.865\n",
      "93 100\n",
      "Generator Training  epoch:  105 , d_loss: 0.65853155 g_loss: 1.5121782 d_acc:  0.965\n",
      "88 92\n",
      "Generator Training  epoch:  106 , d_loss: 0.85060334 g_loss: 1.1335037 d_acc:  0.9\n",
      "86 67\n",
      "Discriminator Training  epoch:  107 , d_loss: 1.0925038 g_loss: 0.8392014 d_acc:  0.765\n",
      "Generator Training  epoch:  107 , d_loss: 1.0925038 g_loss: 0.8392014 d_acc:  0.765\n",
      "41 100\n",
      "Discriminator Training  epoch:  108 , d_loss: 1.0887327 g_loss: 2.2749817 d_acc:  0.705\n",
      "Generator Training  epoch:  108 , d_loss: 1.0887327 g_loss: 2.2749817 d_acc:  0.705\n",
      "96 84\n",
      "Generator Training  epoch:  109 , d_loss: 0.7416321 g_loss: 0.96014667 d_acc:  0.9\n",
      "100 17\n",
      "Discriminator Training  epoch:  110 , d_loss: 1.0394309 g_loss: 0.56242114 d_acc:  0.585\n",
      "Generator Training  epoch:  110 , d_loss: 1.0394309 g_loss: 0.56242114 d_acc:  0.585\n",
      "56 100\n",
      "Discriminator Training  epoch:  111 , d_loss: 0.8181557 g_loss: 2.407949 d_acc:  0.78\n",
      "Generator Training  epoch:  111 , d_loss: 0.8181557 g_loss: 2.407949 d_acc:  0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 99\n",
      "Generator Training  epoch:  112 , d_loss: 0.5142878 g_loss: 1.4105865 d_acc:  0.98\n",
      "96 95\n",
      "Generator Training  epoch:  113 , d_loss: 0.67567253 g_loss: 1.0520567 d_acc:  0.955\n",
      "100 33\n",
      "Discriminator Training  epoch:  114 , d_loss: 1.0009995 g_loss: 0.631352 d_acc:  0.665\n",
      "Generator Training  epoch:  114 , d_loss: 1.0009995 g_loss: 0.631352 d_acc:  0.665\n",
      "37 100\n",
      "Discriminator Training  epoch:  115 , d_loss: 0.9920063 g_loss: 2.766726 d_acc:  0.685\n",
      "Generator Training  epoch:  115 , d_loss: 0.9920063 g_loss: 2.766726 d_acc:  0.685\n",
      "99 87\n",
      "Generator Training  epoch:  116 , d_loss: 0.5749711 g_loss: 1.1719834 d_acc:  0.93\n",
      "100 49\n",
      "Discriminator Training  epoch:  117 , d_loss: 0.8438914 g_loss: 0.7370348 d_acc:  0.745\n",
      "Generator Training  epoch:  117 , d_loss: 0.8438914 g_loss: 0.7370348 d_acc:  0.745\n",
      "85 100\n",
      "Generator Training  epoch:  118 , d_loss: 0.54620373 g_loss: 2.0096917 d_acc:  0.925\n",
      "94 100\n",
      "Generator Training  epoch:  119 , d_loss: 0.72932786 g_loss: 1.1674867 d_acc:  0.97\n",
      "90 33\n",
      "Discriminator Training  epoch:  120 , d_loss: 1.1282427 g_loss: 0.6805933 d_acc:  0.615\n",
      "Generator Training  epoch:  120 , d_loss: 1.1282427 g_loss: 0.6805933 d_acc:  0.615\n",
      "40 100\n",
      "Discriminator Training  epoch:  121 , d_loss: 1.134354 g_loss: 3.4887242 d_acc:  0.7\n",
      "Generator Training  epoch:  121 , d_loss: 1.134354 g_loss: 3.4887242 d_acc:  0.7\n",
      "97 94\n",
      "Generator Training  epoch:  122 , d_loss: 0.46326664 g_loss: 1.70084 d_acc:  0.955\n",
      "97 58\n",
      "Discriminator Training  epoch:  123 , d_loss: 0.8341475 g_loss: 0.8598106 d_acc:  0.775\n",
      "Generator Training  epoch:  123 , d_loss: 0.8341475 g_loss: 0.8598106 d_acc:  0.775\n",
      "74 100\n",
      "Generator Training  epoch:  124 , d_loss: 0.68043303 g_loss: 1.8442116 d_acc:  0.87\n",
      "87 80\n",
      "Generator Training  epoch:  125 , d_loss: 0.8427957 g_loss: 1.1835473 d_acc:  0.835\n",
      "93 50\n",
      "Discriminator Training  epoch:  126 , d_loss: 1.0556947 g_loss: 0.79930544 d_acc:  0.715\n",
      "Generator Training  epoch:  126 , d_loss: 1.0556947 g_loss: 0.79930544 d_acc:  0.715\n",
      "22 100\n",
      "Discriminator Training  epoch:  127 , d_loss: 1.3635433 g_loss: 3.1302633 d_acc:  0.61\n",
      "Generator Training  epoch:  127 , d_loss: 1.3635433 g_loss: 3.1302633 d_acc:  0.61\n",
      "94 61\n",
      "Discriminator Training  epoch:  128 , d_loss: 0.89925516 g_loss: 1.0603459 d_acc:  0.775\n",
      "Generator Training  epoch:  128 , d_loss: 0.89925516 g_loss: 1.0603459 d_acc:  0.775\n",
      "93 58\n",
      "Discriminator Training  epoch:  129 , d_loss: 0.81021273 g_loss: 1.9094979 d_acc:  0.755\n",
      "Generator Training  epoch:  129 , d_loss: 0.81021273 g_loss: 1.9094979 d_acc:  0.755\n",
      "87 100\n",
      "Generator Training  epoch:  130 , d_loss: 0.49016792 g_loss: 3.3247006 d_acc:  0.935\n",
      "83 100\n",
      "Generator Training  epoch:  131 , d_loss: 0.5878882 g_loss: 2.21285 d_acc:  0.915\n",
      "83 100\n",
      "Generator Training  epoch:  132 , d_loss: 0.74419665 g_loss: 1.4950533 d_acc:  0.915\n",
      "91 45\n",
      "Discriminator Training  epoch:  133 , d_loss: 1.034647 g_loss: 0.7467449 d_acc:  0.68\n",
      "Generator Training  epoch:  133 , d_loss: 1.034647 g_loss: 0.7467449 d_acc:  0.68\n",
      "20 100\n",
      "Discriminator Training  epoch:  134 , d_loss: 1.5304725 g_loss: 3.6370234 d_acc:  0.6\n",
      "Generator Training  epoch:  134 , d_loss: 1.5304725 g_loss: 3.6370234 d_acc:  0.6\n",
      "98 56\n",
      "Discriminator Training  epoch:  135 , d_loss: 0.722774 g_loss: 1.2479055 d_acc:  0.77\n",
      "Generator Training  epoch:  135 , d_loss: 0.722774 g_loss: 1.2479055 d_acc:  0.77\n",
      "96 77\n",
      "Generator Training  epoch:  136 , d_loss: 0.60761887 g_loss: 1.6208297 d_acc:  0.865\n",
      "92 55\n",
      "Discriminator Training  epoch:  137 , d_loss: 1.0518992 g_loss: 0.89887583 d_acc:  0.735\n",
      "Generator Training  epoch:  137 , d_loss: 1.0518992 g_loss: 0.89887583 d_acc:  0.735\n",
      "24 100\n",
      "Discriminator Training  epoch:  138 , d_loss: 1.2596681 g_loss: 3.4113157 d_acc:  0.62\n",
      "Generator Training  epoch:  138 , d_loss: 1.2596681 g_loss: 3.4113157 d_acc:  0.62\n",
      "96 54\n",
      "Discriminator Training  epoch:  139 , d_loss: 0.85554177 g_loss: 0.843338 d_acc:  0.75\n",
      "Generator Training  epoch:  139 , d_loss: 0.85554177 g_loss: 0.843338 d_acc:  0.75\n",
      "95 98\n",
      "Generator Training  epoch:  140 , d_loss: 0.5128654 g_loss: 1.6521884 d_acc:  0.965\n",
      "96 88\n",
      "Generator Training  epoch:  141 , d_loss: 0.7153688 g_loss: 1.1955386 d_acc:  0.92\n",
      "92 49\n",
      "Discriminator Training  epoch:  142 , d_loss: 1.0320044 g_loss: 0.8739427 d_acc:  0.705\n",
      "Generator Training  epoch:  142 , d_loss: 1.0320044 g_loss: 0.8739427 d_acc:  0.705\n",
      "60 100\n",
      "Generator Training  epoch:  143 , d_loss: 0.8043043 g_loss: 2.4006734 d_acc:  0.8\n",
      "66 97\n",
      "Generator Training  epoch:  144 , d_loss: 0.88855463 g_loss: 1.9146193 d_acc:  0.815\n",
      "70 89\n",
      "Discriminator Training  epoch:  145 , d_loss: 0.90518653 g_loss: 1.4793587 d_acc:  0.795\n",
      "Generator Training  epoch:  145 , d_loss: 0.90518653 g_loss: 1.4793587 d_acc:  0.795\n",
      "79 100\n",
      "Generator Training  epoch:  146 , d_loss: 0.71749574 g_loss: 2.1822145 d_acc:  0.895\n",
      "66 100\n",
      "Generator Training  epoch:  147 , d_loss: 0.9622743 g_loss: 1.5466344 d_acc:  0.83\n",
      "73 76\n",
      "Discriminator Training  epoch:  148 , d_loss: 1.0851748 g_loss: 1.1025264 d_acc:  0.745\n",
      "Generator Training  epoch:  148 , d_loss: 1.0851748 g_loss: 1.1025264 d_acc:  0.745\n",
      "87 99\n",
      "Generator Training  epoch:  149 , d_loss: 0.6438641 g_loss: 1.731266 d_acc:  0.93\n",
      "83 86\n",
      "Generator Training  epoch:  150 , d_loss: 0.8244405 g_loss: 1.3417947 d_acc:  0.845\n",
      "83 68\n",
      "Discriminator Training  epoch:  151 , d_loss: 1.1528364 g_loss: 0.89668024 d_acc:  0.755\n",
      "Generator Training  epoch:  151 , d_loss: 1.1528364 g_loss: 0.89668024 d_acc:  0.755\n",
      "47 100\n",
      "Discriminator Training  epoch:  152 , d_loss: 1.0329328 g_loss: 2.2515113 d_acc:  0.735\n",
      "Generator Training  epoch:  152 , d_loss: 1.0329328 g_loss: 2.2515113 d_acc:  0.735\n",
      "100 27\n",
      "Discriminator Training  epoch:  153 , d_loss: 0.9417348 g_loss: 0.61496264 d_acc:  0.635\n",
      "Generator Training  epoch:  153 , d_loss: 0.9417348 g_loss: 0.61496264 d_acc:  0.635\n",
      "62 100\n",
      "Generator Training  epoch:  154 , d_loss: 0.72227013 g_loss: 3.1433675 d_acc:  0.81\n",
      "40 100\n",
      "Discriminator Training  epoch:  155 , d_loss: 0.98157 g_loss: 2.2972975 d_acc:  0.7\n",
      "Generator Training  epoch:  155 , d_loss: 0.98157 g_loss: 2.2972975 d_acc:  0.7\n",
      "99 91\n",
      "Generator Training  epoch:  156 , d_loss: 0.7094002 g_loss: 0.94734144 d_acc:  0.95\n",
      "98 9\n",
      "Discriminator Training  epoch:  157 , d_loss: 1.1825749 g_loss: 0.4895147 d_acc:  0.535\n",
      "Generator Training  epoch:  157 , d_loss: 1.1825749 g_loss: 0.4895147 d_acc:  0.535\n",
      "51 100\n",
      "Discriminator Training  epoch:  158 , d_loss: 0.92983454 g_loss: 2.9344566 d_acc:  0.755\n",
      "Generator Training  epoch:  158 , d_loss: 0.92983454 g_loss: 2.9344566 d_acc:  0.755\n",
      "99 100\n",
      "Generator Training  epoch:  159 , d_loss: 0.48259658 g_loss: 1.6312228 d_acc:  0.995\n",
      "99 79\n",
      "Generator Training  epoch:  160 , d_loss: 0.68921906 g_loss: 1.0984681 d_acc:  0.89\n",
      "95 53\n",
      "Discriminator Training  epoch:  161 , d_loss: 1.0127323 g_loss: 0.70800084 d_acc:  0.74\n",
      "Generator Training  epoch:  161 , d_loss: 1.0127323 g_loss: 0.70800084 d_acc:  0.74\n",
      "85 100\n",
      "Generator Training  epoch:  162 , d_loss: 0.5130364 g_loss: 2.5114052 d_acc:  0.925\n",
      "82 100\n",
      "Generator Training  epoch:  163 , d_loss: 0.6433587 g_loss: 2.0702577 d_acc:  0.91\n",
      "84 96\n",
      "Generator Training  epoch:  164 , d_loss: 0.7065709 g_loss: 1.6068211 d_acc:  0.9\n",
      "79 91\n",
      "Generator Training  epoch:  165 , d_loss: 0.8331053 g_loss: 1.3568699 d_acc:  0.85\n",
      "89 65\n",
      "Discriminator Training  epoch:  166 , d_loss: 0.986661 g_loss: 0.9346422 d_acc:  0.77\n",
      "Generator Training  epoch:  166 , d_loss: 0.986661 g_loss: 0.9346422 d_acc:  0.77\n",
      "60 100\n",
      "Generator Training  epoch:  167 , d_loss: 0.7838415 g_loss: 2.6576564 d_acc:  0.8\n",
      "57 100\n",
      "Discriminator Training  epoch:  168 , d_loss: 0.833016 g_loss: 2.269865 d_acc:  0.785\n",
      "Generator Training  epoch:  168 , d_loss: 0.833016 g_loss: 2.269865 d_acc:  0.785\n",
      "99 77\n",
      "Generator Training  epoch:  169 , d_loss: 0.7198076 g_loss: 0.8536295 d_acc:  0.88\n",
      "100 2\n",
      "Discriminator Training  epoch:  170 , d_loss: 1.5840509 g_loss: 0.34393185 d_acc:  0.51\n",
      "Generator Training  epoch:  170 , d_loss: 1.5840509 g_loss: 0.34393185 d_acc:  0.51\n",
      "23 100\n",
      "Discriminator Training  epoch:  171 , d_loss: 1.328925 g_loss: 4.5877643 d_acc:  0.615\n",
      "Generator Training  epoch:  171 , d_loss: 1.328925 g_loss: 4.5877643 d_acc:  0.615\n",
      "89 100\n",
      "Generator Training  epoch:  172 , d_loss: 0.4030531 g_loss: 2.208173 d_acc:  0.945\n",
      "94 96\n",
      "Generator Training  epoch:  173 , d_loss: 0.5150971 g_loss: 1.5957557 d_acc:  0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 67\n",
      "Generator Training  epoch:  174 , d_loss: 0.8598267 g_loss: 0.9187405 d_acc:  0.82\n",
      "93 45\n",
      "Discriminator Training  epoch:  175 , d_loss: 1.0392587 g_loss: 0.77899414 d_acc:  0.69\n",
      "Generator Training  epoch:  175 , d_loss: 1.0392587 g_loss: 0.77899414 d_acc:  0.69\n",
      "86 91\n",
      "Generator Training  epoch:  176 , d_loss: 0.6297673 g_loss: 1.8558971 d_acc:  0.885\n",
      "80 86\n",
      "Generator Training  epoch:  177 , d_loss: 0.90982896 g_loss: 1.1686751 d_acc:  0.83\n",
      "90 49\n",
      "Discriminator Training  epoch:  178 , d_loss: 1.1210848 g_loss: 0.6862434 d_acc:  0.695\n",
      "Generator Training  epoch:  178 , d_loss: 1.1210848 g_loss: 0.6862434 d_acc:  0.695\n",
      "24 100\n",
      "Discriminator Training  epoch:  179 , d_loss: 1.3384948 g_loss: 3.2808995 d_acc:  0.62\n",
      "Generator Training  epoch:  179 , d_loss: 1.3384948 g_loss: 3.2808995 d_acc:  0.62\n",
      "90 86\n",
      "Generator Training  epoch:  180 , d_loss: 0.81485474 g_loss: 1.1595303 d_acc:  0.88\n",
      "94 54\n",
      "Discriminator Training  epoch:  181 , d_loss: 0.9897754 g_loss: 0.7991748 d_acc:  0.74\n",
      "Generator Training  epoch:  181 , d_loss: 0.9897754 g_loss: 0.7991748 d_acc:  0.74\n",
      "81 93\n",
      "Generator Training  epoch:  182 , d_loss: 0.8547669 g_loss: 1.2829795 d_acc:  0.87\n",
      "86 72\n",
      "Discriminator Training  epoch:  183 , d_loss: 0.94474375 g_loss: 0.98347294 d_acc:  0.79\n",
      "Generator Training  epoch:  183 , d_loss: 0.94474375 g_loss: 0.98347294 d_acc:  0.79\n",
      "56 100\n",
      "Discriminator Training  epoch:  184 , d_loss: 0.8983299 g_loss: 2.2261496 d_acc:  0.78\n",
      "Generator Training  epoch:  184 , d_loss: 0.8983299 g_loss: 2.2261496 d_acc:  0.78\n",
      "96 100\n",
      "Generator Training  epoch:  185 , d_loss: 0.5526551 g_loss: 1.2971257 d_acc:  0.98\n",
      "91 58\n",
      "Discriminator Training  epoch:  186 , d_loss: 0.90406495 g_loss: 0.7917657 d_acc:  0.745\n",
      "Generator Training  epoch:  186 , d_loss: 0.90406495 g_loss: 0.7917657 d_acc:  0.745\n",
      "82 100\n",
      "Generator Training  epoch:  187 , d_loss: 0.54485065 g_loss: 2.1391056 d_acc:  0.91\n",
      "86 100\n",
      "Generator Training  epoch:  188 , d_loss: 0.72353506 g_loss: 1.4099236 d_acc:  0.93\n",
      "83 79\n",
      "Generator Training  epoch:  189 , d_loss: 1.0225425 g_loss: 0.9012281 d_acc:  0.81\n",
      "77 32\n",
      "Discriminator Training  epoch:  190 , d_loss: 1.3393961 g_loss: 0.61450154 d_acc:  0.545\n",
      "Generator Training  epoch:  190 , d_loss: 1.3393961 g_loss: 0.61450154 d_acc:  0.545\n",
      "33 100\n",
      "Discriminator Training  epoch:  191 , d_loss: 1.2134595 g_loss: 3.054809 d_acc:  0.665\n",
      "Generator Training  epoch:  191 , d_loss: 1.2134595 g_loss: 3.054809 d_acc:  0.665\n",
      "92 86\n",
      "Generator Training  epoch:  192 , d_loss: 0.73081815 g_loss: 1.2524197 d_acc:  0.89\n",
      "90 63\n",
      "Discriminator Training  epoch:  193 , d_loss: 0.973454 g_loss: 0.79470813 d_acc:  0.765\n",
      "Generator Training  epoch:  193 , d_loss: 0.973454 g_loss: 0.79470813 d_acc:  0.765\n",
      "96 95\n",
      "Generator Training  epoch:  194 , d_loss: 0.64748895 g_loss: 1.2012959 d_acc:  0.955\n",
      "100 51\n",
      "Discriminator Training  epoch:  195 , d_loss: 0.884869 g_loss: 0.7318356 d_acc:  0.755\n",
      "Generator Training  epoch:  195 , d_loss: 0.884869 g_loss: 0.7318356 d_acc:  0.755\n",
      "15 100\n",
      "Discriminator Training  epoch:  196 , d_loss: 1.2458701 g_loss: 2.9814785 d_acc:  0.575\n",
      "Generator Training  epoch:  196 , d_loss: 1.2458701 g_loss: 2.9814785 d_acc:  0.575\n",
      "96 75\n",
      "Generator Training  epoch:  197 , d_loss: 0.63709116 g_loss: 1.1688708 d_acc:  0.855\n",
      "98 52\n",
      "Discriminator Training  epoch:  198 , d_loss: 0.9265021 g_loss: 0.7374071 d_acc:  0.75\n",
      "Generator Training  epoch:  198 , d_loss: 0.9265021 g_loss: 0.7374071 d_acc:  0.75\n",
      "86 100\n",
      "Generator Training  epoch:  199 , d_loss: 0.5713798 g_loss: 1.9516833 d_acc:  0.93\n",
      "83 100\n",
      "Generator Training  epoch:  200 , d_loss: 0.732298 g_loss: 1.4394608 d_acc:  0.915\n",
      "84 73\n",
      "Discriminator Training  epoch:  201 , d_loss: 0.8580865 g_loss: 1.0738317 d_acc:  0.785\n",
      "Generator Training  epoch:  201 , d_loss: 0.8580865 g_loss: 1.0738317 d_acc:  0.785\n",
      "64 100\n",
      "Generator Training  epoch:  202 , d_loss: 0.7999772 g_loss: 2.3560567 d_acc:  0.82\n",
      "62 100\n",
      "Generator Training  epoch:  203 , d_loss: 0.93307096 g_loss: 1.6384274 d_acc:  0.81\n",
      "58 87\n",
      "Discriminator Training  epoch:  204 , d_loss: 1.1783341 g_loss: 1.0430442 d_acc:  0.725\n",
      "Generator Training  epoch:  204 , d_loss: 1.1783341 g_loss: 1.0430442 d_acc:  0.725\n",
      "60 100\n",
      "Generator Training  epoch:  205 , d_loss: 0.9277032 g_loss: 1.5652647 d_acc:  0.8\n",
      "58 86\n",
      "Discriminator Training  epoch:  206 , d_loss: 1.1033719 g_loss: 1.1874944 d_acc:  0.72\n",
      "Generator Training  epoch:  206 , d_loss: 1.1033719 g_loss: 1.1874944 d_acc:  0.72\n",
      "82 94\n",
      "Generator Training  epoch:  207 , d_loss: 0.8286619 g_loss: 1.2872152 d_acc:  0.88\n",
      "90 83\n",
      "Generator Training  epoch:  208 , d_loss: 0.91356266 g_loss: 0.95303833 d_acc:  0.865\n",
      "80 28\n",
      "Discriminator Training  epoch:  209 , d_loss: 1.2898908 g_loss: 0.61388874 d_acc:  0.54\n",
      "Generator Training  epoch:  209 , d_loss: 1.2898908 g_loss: 0.61388874 d_acc:  0.54\n",
      "49 100\n",
      "Discriminator Training  epoch:  210 , d_loss: 0.9316757 g_loss: 2.511372 d_acc:  0.745\n",
      "Generator Training  epoch:  210 , d_loss: 0.9316757 g_loss: 2.511372 d_acc:  0.745\n",
      "100 86\n",
      "Generator Training  epoch:  211 , d_loss: 0.6429093 g_loss: 1.0678988 d_acc:  0.93\n",
      "100 78\n",
      "Generator Training  epoch:  212 , d_loss: 0.72075295 g_loss: 0.8696753 d_acc:  0.89\n",
      "100 24\n",
      "Discriminator Training  epoch:  213 , d_loss: 1.0819368 g_loss: 0.5653919 d_acc:  0.62\n",
      "Generator Training  epoch:  213 , d_loss: 1.0819368 g_loss: 0.5653919 d_acc:  0.62\n",
      "52 100\n",
      "Discriminator Training  epoch:  214 , d_loss: 0.82114124 g_loss: 3.0789824 d_acc:  0.76\n",
      "Generator Training  epoch:  214 , d_loss: 0.82114124 g_loss: 3.0789824 d_acc:  0.76\n",
      "97 100\n",
      "Generator Training  epoch:  215 , d_loss: 0.39731312 g_loss: 1.8765625 d_acc:  0.985\n",
      "99 95\n",
      "Generator Training  epoch:  216 , d_loss: 0.6142919 g_loss: 1.2051401 d_acc:  0.97\n",
      "100 51\n",
      "Discriminator Training  epoch:  217 , d_loss: 0.879725 g_loss: 0.7594117 d_acc:  0.755\n",
      "Generator Training  epoch:  217 , d_loss: 0.879725 g_loss: 0.7594117 d_acc:  0.755\n",
      "87 100\n",
      "Generator Training  epoch:  218 , d_loss: 0.6118593 g_loss: 1.9735947 d_acc:  0.935\n",
      "81 94\n",
      "Generator Training  epoch:  219 , d_loss: 0.79049 g_loss: 1.2588131 d_acc:  0.875\n",
      "86 68\n",
      "Discriminator Training  epoch:  220 , d_loss: 1.0479223 g_loss: 0.83623487 d_acc:  0.77\n",
      "Generator Training  epoch:  220 , d_loss: 1.0479223 g_loss: 0.83623487 d_acc:  0.77\n",
      "15 100\n",
      "Discriminator Training  epoch:  221 , d_loss: 1.2955766 g_loss: 2.8359475 d_acc:  0.575\n",
      "Generator Training  epoch:  221 , d_loss: 1.2955766 g_loss: 2.8359475 d_acc:  0.575\n",
      "98 33\n",
      "Discriminator Training  epoch:  222 , d_loss: 1.0104823 g_loss: 0.80016065 d_acc:  0.655\n",
      "Generator Training  epoch:  222 , d_loss: 1.0104823 g_loss: 0.80016065 d_acc:  0.655\n",
      "91 100\n",
      "Generator Training  epoch:  223 , d_loss: 0.5817789 g_loss: 1.6577374 d_acc:  0.955\n",
      "91 81\n",
      "Generator Training  epoch:  224 , d_loss: 0.8319414 g_loss: 1.0575565 d_acc:  0.86\n",
      "87 52\n",
      "Discriminator Training  epoch:  225 , d_loss: 1.0219798 g_loss: 0.75433904 d_acc:  0.695\n",
      "Generator Training  epoch:  225 , d_loss: 1.0219798 g_loss: 0.75433904 d_acc:  0.695\n",
      "27 100\n",
      "Discriminator Training  epoch:  226 , d_loss: 1.285243 g_loss: 2.622338 d_acc:  0.635\n",
      "Generator Training  epoch:  226 , d_loss: 1.285243 g_loss: 2.622338 d_acc:  0.635\n",
      "88 77\n",
      "Generator Training  epoch:  227 , d_loss: 0.8198194 g_loss: 1.109255 d_acc:  0.825\n",
      "94 41\n",
      "Discriminator Training  epoch:  228 , d_loss: 1.0977724 g_loss: 0.6753718 d_acc:  0.675\n",
      "Generator Training  epoch:  228 , d_loss: 1.0977724 g_loss: 0.6753718 d_acc:  0.675\n",
      "64 100\n",
      "Generator Training  epoch:  229 , d_loss: 0.81031084 g_loss: 1.9123142 d_acc:  0.82\n",
      "69 95\n",
      "Generator Training  epoch:  230 , d_loss: 0.92150027 g_loss: 1.3166411 d_acc:  0.82\n",
      "71 78\n",
      "Discriminator Training  epoch:  231 , d_loss: 1.0642833 g_loss: 1.0395538 d_acc:  0.745\n",
      "Generator Training  epoch:  231 , d_loss: 1.0642833 g_loss: 1.0395538 d_acc:  0.745\n",
      "49 100\n",
      "Discriminator Training  epoch:  232 , d_loss: 0.9234889 g_loss: 2.0871615 d_acc:  0.745\n",
      "Generator Training  epoch:  232 , d_loss: 0.9234889 g_loss: 2.0871615 d_acc:  0.745\n",
      "96 87\n",
      "Generator Training  epoch:  233 , d_loss: 0.6862764 g_loss: 1.1873122 d_acc:  0.915\n",
      "96 66\n",
      "Generator Training  epoch:  234 , d_loss: 0.8724425 g_loss: 0.87798554 d_acc:  0.81\n",
      "99 32\n",
      "Discriminator Training  epoch:  235 , d_loss: 1.0748768 g_loss: 0.64415705 d_acc:  0.655\n",
      "Generator Training  epoch:  235 , d_loss: 1.0748768 g_loss: 0.64415705 d_acc:  0.655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 100\n",
      "Generator Training  epoch:  236 , d_loss: 0.67824435 g_loss: 2.0745802 d_acc:  0.89\n",
      "83 100\n",
      "Generator Training  epoch:  237 , d_loss: 0.7068106 g_loss: 1.6428794 d_acc:  0.915\n",
      "78 99\n",
      "Generator Training  epoch:  238 , d_loss: 0.87597257 g_loss: 1.2673002 d_acc:  0.885\n",
      "73 72\n",
      "Discriminator Training  epoch:  239 , d_loss: 1.1047008 g_loss: 0.9244562 d_acc:  0.725\n",
      "Generator Training  epoch:  239 , d_loss: 1.1047008 g_loss: 0.9244562 d_acc:  0.725\n",
      "49 100\n",
      "Discriminator Training  epoch:  240 , d_loss: 0.9914174 g_loss: 2.2580395 d_acc:  0.745\n",
      "Generator Training  epoch:  240 , d_loss: 0.9914174 g_loss: 2.2580395 d_acc:  0.745\n",
      "94 94\n",
      "Generator Training  epoch:  241 , d_loss: 0.6055532 g_loss: 1.325077 d_acc:  0.94\n",
      "91 63\n",
      "Discriminator Training  epoch:  242 , d_loss: 0.9431411 g_loss: 0.8821572 d_acc:  0.77\n",
      "Generator Training  epoch:  242 , d_loss: 0.9431411 g_loss: 0.8821572 d_acc:  0.77\n",
      "94 100\n",
      "Generator Training  epoch:  243 , d_loss: 0.5661673 g_loss: 1.47166 d_acc:  0.97\n",
      "93 94\n",
      "Generator Training  epoch:  244 , d_loss: 0.72666866 g_loss: 1.1412044 d_acc:  0.935\n",
      "94 79\n",
      "Generator Training  epoch:  245 , d_loss: 0.8346365 g_loss: 0.9071268 d_acc:  0.865\n",
      "94 34\n",
      "Discriminator Training  epoch:  246 , d_loss: 1.0590138 g_loss: 0.6561459 d_acc:  0.64\n",
      "Generator Training  epoch:  246 , d_loss: 1.0590138 g_loss: 0.6561459 d_acc:  0.64\n",
      "40 100\n",
      "Discriminator Training  epoch:  247 , d_loss: 0.92098296 g_loss: 2.7534502 d_acc:  0.7\n",
      "Generator Training  epoch:  247 , d_loss: 0.92098296 g_loss: 2.7534502 d_acc:  0.7\n",
      "95 100\n",
      "Generator Training  epoch:  248 , d_loss: 0.49088147 g_loss: 1.7238141 d_acc:  0.975\n",
      "96 99\n",
      "Generator Training  epoch:  249 , d_loss: 0.54734766 g_loss: 1.4389155 d_acc:  0.975\n",
      "98 78\n",
      "Generator Training  epoch:  250 , d_loss: 0.7622125 g_loss: 0.99681765 d_acc:  0.88\n",
      "97 51\n",
      "Discriminator Training  epoch:  251 , d_loss: 0.95153475 g_loss: 0.7636256 d_acc:  0.74\n",
      "Generator Training  epoch:  251 , d_loss: 0.95153475 g_loss: 0.7636256 d_acc:  0.74\n",
      "84 100\n",
      "Generator Training  epoch:  252 , d_loss: 0.63337284 g_loss: 2.110475 d_acc:  0.92\n",
      "68 91\n",
      "Discriminator Training  epoch:  253 , d_loss: 0.91110486 g_loss: 1.4286208 d_acc:  0.795\n",
      "Generator Training  epoch:  253 , d_loss: 0.91110486 g_loss: 1.4286208 d_acc:  0.795\n",
      "85 100\n",
      "Generator Training  epoch:  254 , d_loss: 0.69653064 g_loss: 1.6725808 d_acc:  0.925\n",
      "88 89\n",
      "Generator Training  epoch:  255 , d_loss: 0.8548221 g_loss: 1.1867554 d_acc:  0.885\n",
      "82 72\n",
      "Discriminator Training  epoch:  256 , d_loss: 0.9872718 g_loss: 0.90190226 d_acc:  0.77\n",
      "Generator Training  epoch:  256 , d_loss: 0.9872718 g_loss: 0.90190226 d_acc:  0.77\n",
      "62 100\n",
      "Generator Training  epoch:  257 , d_loss: 0.8957394 g_loss: 1.6765039 d_acc:  0.81\n",
      "66 91\n",
      "Discriminator Training  epoch:  258 , d_loss: 1.0280433 g_loss: 1.1936984 d_acc:  0.785\n",
      "Generator Training  epoch:  258 , d_loss: 1.0280433 g_loss: 1.1936984 d_acc:  0.785\n",
      "87 98\n",
      "Generator Training  epoch:  259 , d_loss: 0.7048013 g_loss: 1.4581081 d_acc:  0.925\n",
      "99 80\n",
      "Generator Training  epoch:  260 , d_loss: 0.80568993 g_loss: 0.9700068 d_acc:  0.895\n",
      "85 72\n",
      "Discriminator Training  epoch:  261 , d_loss: 1.0358326 g_loss: 0.85870427 d_acc:  0.785\n",
      "Generator Training  epoch:  261 , d_loss: 1.0358326 g_loss: 0.85870427 d_acc:  0.785\n",
      "70 100\n",
      "Generator Training  epoch:  262 , d_loss: 0.8077467 g_loss: 1.7070415 d_acc:  0.85\n",
      "74 100\n",
      "Generator Training  epoch:  263 , d_loss: 0.86873186 g_loss: 1.399051 d_acc:  0.87\n",
      "86 100\n",
      "Generator Training  epoch:  264 , d_loss: 0.85010135 g_loss: 1.1319824 d_acc:  0.93\n",
      "77 68\n",
      "Discriminator Training  epoch:  265 , d_loss: 1.1664407 g_loss: 0.8097558 d_acc:  0.725\n",
      "Generator Training  epoch:  265 , d_loss: 1.1664407 g_loss: 0.8097558 d_acc:  0.725\n",
      "52 100\n",
      "Discriminator Training  epoch:  266 , d_loss: 0.87804437 g_loss: 2.3290322 d_acc:  0.76\n",
      "Generator Training  epoch:  266 , d_loss: 0.87804437 g_loss: 2.3290322 d_acc:  0.76\n",
      "98 79\n",
      "Generator Training  epoch:  267 , d_loss: 0.69617146 g_loss: 0.92519957 d_acc:  0.885\n",
      "100 36\n",
      "Discriminator Training  epoch:  268 , d_loss: 0.8698038 g_loss: 0.67299163 d_acc:  0.68\n",
      "Generator Training  epoch:  268 , d_loss: 0.8698038 g_loss: 0.67299163 d_acc:  0.68\n",
      "78 100\n",
      "Generator Training  epoch:  269 , d_loss: 0.5397496 g_loss: 2.6658888 d_acc:  0.89\n",
      "76 100\n",
      "Generator Training  epoch:  270 , d_loss: 0.69471836 g_loss: 2.0771902 d_acc:  0.88\n",
      "81 100\n",
      "Generator Training  epoch:  271 , d_loss: 0.7003448 g_loss: 1.6059537 d_acc:  0.905\n",
      "58 92\n",
      "Discriminator Training  epoch:  272 , d_loss: 1.0920553 g_loss: 1.2228976 d_acc:  0.75\n",
      "Generator Training  epoch:  272 , d_loss: 1.0920553 g_loss: 1.2228976 d_acc:  0.75\n",
      "85 100\n",
      "Generator Training  epoch:  273 , d_loss: 0.61840725 g_loss: 1.857543 d_acc:  0.925\n",
      "81 100\n",
      "Generator Training  epoch:  274 , d_loss: 0.7800616 g_loss: 1.3410547 d_acc:  0.905\n",
      "83 76\n",
      "Discriminator Training  epoch:  275 , d_loss: 1.0067685 g_loss: 0.9105425 d_acc:  0.795\n",
      "Generator Training  epoch:  275 , d_loss: 1.0067685 g_loss: 0.9105425 d_acc:  0.795\n",
      "31 100\n",
      "Discriminator Training  epoch:  276 , d_loss: 1.1427724 g_loss: 2.2179887 d_acc:  0.655\n",
      "Generator Training  epoch:  276 , d_loss: 1.1427724 g_loss: 2.2179887 d_acc:  0.655\n",
      "99 49\n",
      "Discriminator Training  epoch:  277 , d_loss: 0.9545092 g_loss: 0.7411881 d_acc:  0.74\n",
      "Generator Training  epoch:  277 , d_loss: 0.9545092 g_loss: 0.7411881 d_acc:  0.74\n",
      "96 100\n",
      "Generator Training  epoch:  278 , d_loss: 0.39724588 g_loss: 2.470807 d_acc:  0.98\n",
      "95 98\n",
      "Generator Training  epoch:  279 , d_loss: 0.51563615 g_loss: 1.8995978 d_acc:  0.965\n",
      "94 97\n",
      "Generator Training  epoch:  280 , d_loss: 0.6531342 g_loss: 1.3191112 d_acc:  0.955\n",
      "97 79\n",
      "Generator Training  epoch:  281 , d_loss: 0.8665792 g_loss: 0.8862422 d_acc:  0.88\n",
      "84 21\n",
      "Discriminator Training  epoch:  282 , d_loss: 1.2513194 g_loss: 0.5699856 d_acc:  0.525\n",
      "Generator Training  epoch:  282 , d_loss: 1.2513194 g_loss: 0.5699856 d_acc:  0.525\n",
      "5 100\n",
      "Discriminator Training  epoch:  283 , d_loss: 1.5802364 g_loss: 3.6417363 d_acc:  0.525\n",
      "Generator Training  epoch:  283 , d_loss: 1.5802364 g_loss: 3.6417363 d_acc:  0.525\n",
      "95 95\n",
      "Generator Training  epoch:  284 , d_loss: 0.5445149 g_loss: 1.4858407 d_acc:  0.95\n",
      "97 82\n",
      "Generator Training  epoch:  285 , d_loss: 0.78537744 g_loss: 1.0309777 d_acc:  0.895\n",
      "94 47\n",
      "Discriminator Training  epoch:  286 , d_loss: 1.051099 g_loss: 0.6799653 d_acc:  0.705\n",
      "Generator Training  epoch:  286 , d_loss: 1.051099 g_loss: 0.6799653 d_acc:  0.705\n",
      "96 87\n",
      "Generator Training  epoch:  287 , d_loss: 0.7908003 g_loss: 1.0602555 d_acc:  0.915\n",
      "97 60\n",
      "Discriminator Training  epoch:  288 , d_loss: 0.9324377 g_loss: 0.79910946 d_acc:  0.785\n",
      "Generator Training  epoch:  288 , d_loss: 0.9324377 g_loss: 0.79910946 d_acc:  0.785\n",
      "39 100\n",
      "Discriminator Training  epoch:  289 , d_loss: 1.0201266 g_loss: 2.1101708 d_acc:  0.695\n",
      "Generator Training  epoch:  289 , d_loss: 1.0201266 g_loss: 2.1101708 d_acc:  0.695\n",
      "87 94\n",
      "Generator Training  epoch:  290 , d_loss: 0.7388134 g_loss: 1.2407628 d_acc:  0.905\n",
      "95 69\n",
      "Generator Training  epoch:  291 , d_loss: 0.89199895 g_loss: 0.8674133 d_acc:  0.82\n",
      "93 34\n",
      "Discriminator Training  epoch:  292 , d_loss: 1.1808629 g_loss: 0.58935636 d_acc:  0.635\n",
      "Generator Training  epoch:  292 , d_loss: 1.1808629 g_loss: 0.58935636 d_acc:  0.635\n",
      "62 100\n",
      "Generator Training  epoch:  293 , d_loss: 0.8217355 g_loss: 2.0609584 d_acc:  0.81\n",
      "60 100\n",
      "Generator Training  epoch:  294 , d_loss: 0.92340815 g_loss: 1.6555662 d_acc:  0.8\n",
      "54 88\n",
      "Discriminator Training  epoch:  295 , d_loss: 1.2101765 g_loss: 1.0748978 d_acc:  0.71\n",
      "Generator Training  epoch:  295 , d_loss: 1.2101765 g_loss: 1.0748978 d_acc:  0.71\n",
      "84 100\n",
      "Generator Training  epoch:  296 , d_loss: 0.69149876 g_loss: 1.6013083 d_acc:  0.92\n",
      "84 99\n",
      "Generator Training  epoch:  297 , d_loss: 0.79451597 g_loss: 1.3295093 d_acc:  0.915\n",
      "81 87\n",
      "Generator Training  epoch:  298 , d_loss: 0.99660176 g_loss: 1.0495226 d_acc:  0.84\n",
      "86 67\n",
      "Discriminator Training  epoch:  299 , d_loss: 1.058656 g_loss: 0.8662233 d_acc:  0.765\n",
      "Generator Training  epoch:  299 , d_loss: 1.058656 g_loss: 0.8662233 d_acc:  0.765\n",
      "61 100\n",
      "Generator Training  epoch:  300 , d_loss: 0.82538915 g_loss: 2.0145383 d_acc:  0.805\n",
      "65 100\n",
      "Generator Training  epoch:  301 , d_loss: 0.8559675 g_loss: 1.7010405 d_acc:  0.825\n",
      "46 99\n",
      "Discriminator Training  epoch:  302 , d_loss: 1.1954921 g_loss: 1.3153425 d_acc:  0.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Training  epoch:  302 , d_loss: 1.1954921 g_loss: 1.3153425 d_acc:  0.725\n",
      "99 89\n",
      "Generator Training  epoch:  303 , d_loss: 0.62592345 g_loss: 1.3767556 d_acc:  0.94\n",
      "99 72\n",
      "Generator Training  epoch:  304 , d_loss: 0.6913101 g_loss: 1.1204382 d_acc:  0.855\n",
      "98 66\n",
      "Generator Training  epoch:  305 , d_loss: 0.83592236 g_loss: 0.88101816 d_acc:  0.82\n",
      "94 40\n",
      "Discriminator Training  epoch:  306 , d_loss: 1.0613204 g_loss: 0.67789817 d_acc:  0.67\n",
      "Generator Training  epoch:  306 , d_loss: 1.0613204 g_loss: 0.67789817 d_acc:  0.67\n",
      "53 100\n",
      "Discriminator Training  epoch:  307 , d_loss: 0.86644804 g_loss: 2.5354834 d_acc:  0.765\n",
      "Generator Training  epoch:  307 , d_loss: 0.86644804 g_loss: 2.5354834 d_acc:  0.765\n",
      "99 95\n",
      "Generator Training  epoch:  308 , d_loss: 0.4321027 g_loss: 1.4573411 d_acc:  0.97\n",
      "97 93\n",
      "Generator Training  epoch:  309 , d_loss: 0.6571561 g_loss: 1.0794905 d_acc:  0.95\n",
      "100 36\n",
      "Discriminator Training  epoch:  310 , d_loss: 0.87963665 g_loss: 0.7065145 d_acc:  0.68\n",
      "Generator Training  epoch:  310 , d_loss: 0.87963665 g_loss: 0.7065145 d_acc:  0.68\n",
      "89 100\n",
      "Generator Training  epoch:  311 , d_loss: 0.51577705 g_loss: 2.5443072 d_acc:  0.945\n",
      "89 100\n",
      "Generator Training  epoch:  312 , d_loss: 0.57066965 g_loss: 2.1763198 d_acc:  0.945\n",
      "74 97\n",
      "Generator Training  epoch:  313 , d_loss: 0.76806223 g_loss: 1.6839129 d_acc:  0.855\n",
      "85 86\n",
      "Generator Training  epoch:  314 , d_loss: 0.78207076 g_loss: 1.2711259 d_acc:  0.855\n",
      "76 68\n",
      "Discriminator Training  epoch:  315 , d_loss: 1.0624343 g_loss: 0.9024249 d_acc:  0.72\n",
      "Generator Training  epoch:  315 , d_loss: 1.0624343 g_loss: 0.9024249 d_acc:  0.72\n",
      "38 100\n",
      "Discriminator Training  epoch:  316 , d_loss: 1.0423832 g_loss: 2.6847959 d_acc:  0.69\n",
      "Generator Training  epoch:  316 , d_loss: 1.0423832 g_loss: 2.6847959 d_acc:  0.69\n",
      "100 80\n",
      "Generator Training  epoch:  317 , d_loss: 0.61963004 g_loss: 1.1057436 d_acc:  0.9\n",
      "100 45\n",
      "Discriminator Training  epoch:  318 , d_loss: 0.83992547 g_loss: 0.76486397 d_acc:  0.725\n",
      "Generator Training  epoch:  318 , d_loss: 0.83992547 g_loss: 0.76486397 d_acc:  0.725\n",
      "94 99\n",
      "Generator Training  epoch:  319 , d_loss: 0.51007295 g_loss: 1.9932129 d_acc:  0.965\n",
      "92 92\n",
      "Generator Training  epoch:  320 , d_loss: 0.61549747 g_loss: 1.591065 d_acc:  0.92\n",
      "80 78\n",
      "Discriminator Training  epoch:  321 , d_loss: 0.9492753 g_loss: 1.1226513 d_acc:  0.79\n",
      "Generator Training  epoch:  321 , d_loss: 0.9492753 g_loss: 1.1226513 d_acc:  0.79\n",
      "44 100\n",
      "Discriminator Training  epoch:  322 , d_loss: 0.96316254 g_loss: 2.506106 d_acc:  0.72\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "        trainGAN(is_dummy=False, checkpoint='/home/vamsi/Downloads/tf-3dgan-master/src/models/gan-small-airplane/biasfree_7810.cptk')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
