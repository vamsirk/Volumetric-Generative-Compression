{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dataIO as d\n",
    "\n",
    "from tqdm import *\n",
    "from utils import *\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "response = urllib.request.urlopen(\"https://raw.githubusercontent.com/yaroslavvb/memory_util/master/memory_util.py\")\n",
    "open(\"memory_util.py\", \"wb\").write(response.read())\n",
    "\n",
    "import memory_util\n",
    "memory_util.vlog(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "z_size = 200\n",
    "cube_len = 32\n",
    "leak_value = 0.2\n",
    "weights = {}\n",
    "l = 0.95\n",
    "lr = 0.001\n",
    "\n",
    "obj = 'vase'\n",
    "obj_ratio = 1.0\n",
    "num_epoch = 101\n",
    "save_interval = 5\n",
    "beta       = 0.5\n",
    "\n",
    "experiment_name = 'vase-compress_3_test'\n",
    "\n",
    "voxnet_save_path = '/home/vamsi/Downloads/tf-3dgan-master/src/models/cls_vox/biasfree_19999.cptk'\n",
    "gan_save_directory = '/home/vamsi/Downloads/tf-3dgan-master/src/models/vase/biasfree_5600.cptk'\n",
    "\n",
    "train_sample_directory = './train_sample/' + experiment_name + '/'\n",
    "model_directory = './models/' + experiment_name + '/'\n",
    "\n",
    "img_base_directory = './img/'\n",
    "img_directory = img_base_directory + experiment_name + '/'\n",
    "\n",
    "pickle_base_directory = './pickle/'\n",
    "pickle_directory = pickle_base_directory + experiment_name + '/'\n",
    "\n",
    "if not os.path.exists(pickle_directory):\n",
    "    os.makedirs(pickle_directory)\n",
    "    \n",
    "if not os.path.exists(train_sample_directory):\n",
    "    os.makedirs(train_sample_directory)\n",
    "    \n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "    \n",
    "if not os.path.exists(img_directory):\n",
    "    os.makedirs(img_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(z, batch_size=batch_size, phase_train=True, reuse=False):\n",
    "\n",
    "    strides    = [2,2,2]\n",
    "\n",
    "    with tf.variable_scope(\"gen\", reuse=reuse):\n",
    "#         z = tf.reshape(z, (batch_size, 1, 1, 1, z_size))\n",
    "        g_1 = tf.layers.dense(z, 256*2*2*2, kernel_initializer=tf.random_normal_initializer(stddev=0.02), name='g1',trainable=phase_train)\n",
    "        g_1 = tf.reshape(g_1, (-1, 2,2,2,256))\n",
    "#         g_1 = tf.nn.conv3d_transpose(z, weights['wg1'], (batch_size,4,4,4,512), strides=[1,1,1,1,1], padding=\"VALID\")\n",
    "        g_1 = tf.layers.batch_normalization(g_1, training=phase_train, name='g_bn1')\n",
    "        g_1 = tf.nn.relu(g_1)\n",
    "\n",
    "        g_2 = tf.layers.conv3d_transpose(g_1, 256, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g2',trainable=phase_train)\n",
    "        g_2 = tf.layers.batch_normalization(g_2, training=phase_train, name='g_bn2')\n",
    "        g_2 = tf.nn.relu(g_2)\n",
    "\n",
    "        g_3 = tf.layers.conv3d_transpose(g_2, 128, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g3',trainable=phase_train)\n",
    "        g_3 = tf.layers.batch_normalization(g_3, training=phase_train, name='g_bn3')\n",
    "        g_3 = tf.nn.relu(g_3)\n",
    "\n",
    "        g_4 = tf.layers.conv3d_transpose(g_3, 64, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g4',trainable=phase_train)\n",
    "        g_4 = tf.layers.batch_normalization(g_4, training=phase_train, name='g_bn4')\n",
    "        g_4 = tf.nn.relu(g_4)\n",
    "        \n",
    "        g_5 = tf.layers.conv3d_transpose(g_4, 1, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='g5',trainable=phase_train)\n",
    "        g_5 = tf.nn.sigmoid(g_5)\n",
    "#         g_5 = tf.nn.tanh(g_5)\n",
    "\n",
    "    print (g_1, 'g1')\n",
    "    print (g_2, 'g2')\n",
    "    print (g_3, 'g3')\n",
    "    print (g_4, 'g4')\n",
    "    print (g_5, 'g5')\n",
    "    \n",
    "    return g_5\n",
    "\n",
    "def encoder(inputs, encoding_size, phase_train=True, reuse=False):\n",
    "\n",
    "    strides    = [2,2,2]\n",
    "    with tf.variable_scope(\"enc\", reuse=reuse):\n",
    "             \n",
    "        d_1 = tf.layers.conv3d(inputs, 32, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='e1',trainable=phase_train)\n",
    "        d_1 = tf.layers.batch_normalization(d_1, training=phase_train, name='bn_e1')                               \n",
    "        d_1 = lrelu(d_1, leak_value)\n",
    "\n",
    "        d_2 = tf.layers.conv3d(d_1, 64, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='e2',trainable=phase_train) \n",
    "        d_2 = tf.layers.batch_normalization(d_2, training=phase_train, name='bn_e2')\n",
    "        d_2 = lrelu(d_2, leak_value)\n",
    "        \n",
    "        d_3 = tf.layers.conv3d(d_2, 128, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='e3',trainable=phase_train)\n",
    "        d_3 = tf.layers.batch_normalization(d_3, training=phase_train, name='bn_e3')\n",
    "        d_3 = lrelu(d_3, leak_value) \n",
    "\n",
    "        d_4 = tf.layers.conv3d(d_3, 256, [4, 4, 4], strides=strides, padding=\"same\", use_bias=False, name='e4',trainable=phase_train)    \n",
    "        d_4 = tf.layers.batch_normalization(d_4, training=phase_train, name='bn_e4')\n",
    "        d_4 = lrelu(d_4)\n",
    "\n",
    "        d_5 = tf.contrib.layers.flatten(d_4)\n",
    "        d_5 = tf.layers.dense(d_5, encoding_size, kernel_initializer=tf.random_normal_initializer(stddev=0.02), name='f1',trainable=phase_train)\n",
    "        d_5_no_sigmoid = d_5\n",
    "        d_5 = tf.nn.sigmoid(d_5)\n",
    "        \n",
    "        \n",
    "    print (d_1, 'd1')\n",
    "    print (d_2, 'd2')\n",
    "    print (d_3, 'd3')\n",
    "    print (d_4, 'd4')\n",
    "    print (d_5, 'd5')\n",
    "\n",
    "    return d_5, d_5_no_sigmoid\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2):\n",
    "    return tf.maximum(x, leak*x)\n",
    "\n",
    "def voxnet(input_models, phase_train=False, reuse=False):\n",
    "    strides    = [2,2,2]\n",
    "    with tf.variable_scope(\"vox\", reuse=reuse):\n",
    "        vox_1 = tf.layers.conv3d(input_models, 32, [5, 5, 5], strides=strides, padding=\"valid\", trainable = phase_train, use_bias=False, name='vox1')\n",
    "        vox_1 = tf.layers.batch_normalization(vox_1, training=phase_train, name='vox_bn1', trainable = phase_train)                               \n",
    "        vox_1 = lrelu(vox_1, leak_value)\n",
    "        \n",
    "        vox_2 = tf.layers.conv3d(vox_1, 32, [3, 3, 3], strides=[1,1,1], padding=\"valid\", use_bias=False, name='vox2', trainable = phase_train)\n",
    "        vox_2 = tf.layers.batch_normalization(vox_2, training=phase_train, name='vox_bn2', trainable = phase_train)                               \n",
    "        vox_2 = lrelu(vox_2, leak_value)\n",
    "        vox_2 = tf.layers.max_pooling3d(vox_2, [2,2,2], strides=[1,1,1], padding='valid', name='max_pool1')\n",
    "        \n",
    "        vox_flat = tf.contrib.layers.flatten(vox_2)\n",
    "        vox_3 = tf.layers.dense(vox_flat, 5, kernel_initializer=tf.random_normal_initializer(stddev=0.02), name='vox3', trainable = phase_train)\n",
    "        vox_3_no_softmax = vox_3\n",
    "        vox_3 = tf.nn.softmax(vox_3_no_softmax)\n",
    "\n",
    "    #return 2nd layer of voxnet\n",
    "    return vox_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voxel(voxel, voxel2=None, saveas=None):\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax.voxels(voxel.squeeze()>.5, facecolors='red', edgecolors='k')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    if voxel2 is not None:\n",
    "        ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "        ax.voxels(voxel2.squeeze()>.5, facecolors='red', edgecolors='k')\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "    if saveas is not None:\n",
    "        plt.savefig(saveas)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "x_vector = tf.placeholder(shape=[batch_size,cube_len,cube_len,cube_len,1],dtype=tf.float32) \n",
    "\n",
    "#encoding from 32*32*32 down to 200 ::: 163x\n",
    "enc,_ = encoder(x_vector, z_size, phase_train=True, reuse=False)\n",
    "dec = decoder(enc, phase_train=True, reuse=False) \n",
    "\n",
    "input_vox = voxnet(x_vector, phase_train=False, reuse=False)\n",
    "decoded_vox = voxnet(dec, phase_train=False, reuse=True)\n",
    "\n",
    "num_voxnet_intermediate_units = np.product(input_vox.get_shape().as_list())\n",
    "\n",
    "loss_pixel = tf.nn.l2_loss(x_vector - dec) / (batch_size*cube_len*cube_len*cube_len)\n",
    "loss_perceptual = tf.nn.l2_loss(input_vox - decoded_vox) / num_voxnet_intermediate_units\n",
    "# weighted sum of the two losses\n",
    "loss = l*loss_pixel + (1-l)*loss_perceptual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='enc')\n",
    "#build a list of variable to load\n",
    "generator_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='gen')\n",
    "#generator_vars.extend(list(weights.values()))\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=lr, beta1 = beta ).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "code_directory = '/home/vamsi/Downloads/tf-3dgan-master/src/models/vase-compress_3/compression_gen_100.ckpt'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    #all_saver = tf.train.Saver()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    gen_loader = tf.train.Saver(generator_vars)\n",
    "    gen_loader.restore(sess, code_directory)\n",
    "\n",
    "    vox_loader = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='vox'))\n",
    "    vox_loader.restore(sess, voxnet_save_path)\n",
    "    \n",
    "    ec_loader = tf.train.Saver(encoder_vars)\n",
    "    ec_loader.restore(sess, code_directory)\n",
    "\n",
    "    # load from checkpoint\n",
    "    # all_saver.restore(sess, tf.train.latest_checkpoint(model_directory))\n",
    "    volumes = d.getAll(obj=obj, train=True, is_local=False, obj_ratio=obj_ratio, cube_len=32)\n",
    "    print ('Using ' + obj + ' Data')\n",
    "    volumes = volumes[...,np.newaxis].astype(np.float)\n",
    "\n",
    "    num_samples = len(volumes)\n",
    "\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    #sess.run(tf.global_variables_initializer())   \n",
    "    loss_stat = np.array([])\n",
    "    for epoch in range(100, 200):\n",
    "        for i in range(num_batches):\n",
    "            idx = np.random.randint(len(volumes), size=batch_size)\n",
    "            input_voxels = volumes[idx]\n",
    "            pix_loss, perc_loss, tot_loss, _ = sess.run([loss_pixel, loss_perceptual, loss, train_op], feed_dict={x_vector: input_voxels})\n",
    "\n",
    "            loss_stat = np.concatenate([loss_stat,[tot_loss]])\n",
    "\n",
    "            print(\"epoch {}, batch {}: pix loss {:10.5f}, perc loss {:10.5f}, total loss {:10.5f}\".format(epoch, i, pix_loss, perc_loss, tot_loss))\n",
    "            if i==num_batches - 1 and epoch % save_interval == 0:\n",
    "                # generate and visualize generated images\n",
    "                recon_voxel = sess.run(dec, feed_dict={x_vector: input_voxels})\n",
    "                save_sample = np.concatenate((input_voxels, recon_voxel), axis=0)\n",
    "\n",
    "                save_sample.dump(\"{}{}\".format(train_sample_directory, epoch))\n",
    "\n",
    "                saver.save(sess, save_path = '{}compression_gen_{}.ckpt'.format(model_directory, epoch))\n",
    "\n",
    "                for n in range(3):\n",
    "                    plot_voxel(save_sample[n], save_sample[n + batch_size], saveas='{}{}_{}.png'.format(img_directory, epoch, n))\n",
    "\n",
    "                loss_stat.dump(\"{}{}.pickle\".format(pickle_directory, epoch))\n",
    "                \n",
    "                volumes_test = d.getAll(obj=obj, train=False, is_local=False, obj_ratio=obj_ratio, cube_len=32)\n",
    "    \n",
    "                volumes_test = volumes_test[...,np.newaxis].astype(np.float)\n",
    "\n",
    "                num_samples = len(volumes_test)\n",
    "\n",
    "                print(num_samples)\n",
    "\n",
    "                num_batches = num_samples // batch_size\n",
    "\n",
    "                sess.run(tf.global_variables_initializer())  \n",
    "\n",
    "                loss_stat = np.array([])\n",
    "\n",
    "                for epoch in range(20):\n",
    "                    for i in range(num_batches):\n",
    "                        input_voxels = volumes[i*batch_size: (i+1)*batch_size]\n",
    "                        # generate and visualize generated images\n",
    "                        pix_loss, recon_voxel = sess.run([loss_pixel, dec], feed_dict={x_vector: input_voxels})\n",
    "                        #print(\"epoch {}, batch {}: pix loss {:10.5f}, perc loss {:10.5f}, total loss {:10.5f}\".format(epoch, i, pix_loss, perc_loss, tot_loss))\n",
    "                    save_sample = np.concatenate((input_voxels, recon_voxel), axis=0)\n",
    "                    recon_voxel.dump(train_sample_directory+'/biasfree_'+str(epoch))\n",
    "                    for n in range(3):\n",
    "                        plot_voxel(save_sample[n], save_sample[n + batch_size], saveas='{}{}_{}_test.png'.format(img_directory, epoch, n))\n",
    "\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vamsi/miniconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"enc/Maximum:0\", shape=(100, 16, 16, 16, 32), dtype=float32) d1\n",
      "Tensor(\"enc/Maximum_1:0\", shape=(100, 8, 8, 8, 64), dtype=float32) d2\n",
      "Tensor(\"enc/Maximum_2:0\", shape=(100, 4, 4, 4, 128), dtype=float32) d3\n",
      "Tensor(\"enc/Maximum_3:0\", shape=(100, 2, 2, 2, 256), dtype=float32) d4\n",
      "Tensor(\"enc/Sigmoid:0\", shape=(100, 200), dtype=float32) d5\n",
      "Tensor(\"gen/Relu:0\", shape=(100, 2, 2, 2, 256), dtype=float32) g1\n",
      "Tensor(\"gen/Relu_1:0\", shape=(100, 4, 4, 4, 256), dtype=float32) g2\n",
      "Tensor(\"gen/Relu_2:0\", shape=(100, 8, 8, 8, 128), dtype=float32) g3\n",
      "Tensor(\"gen/Relu_3:0\", shape=(100, 16, 16, 16, 64), dtype=float32) g4\n",
      "Tensor(\"gen/Sigmoid:0\", shape=(100, 32, 32, 32, 1), dtype=float32) g5\n"
     ]
    }
   ],
   "source": [
    "x_vector = tf.placeholder(shape=[batch_size,cube_len,cube_len,cube_len,1],dtype=tf.float32) \n",
    "\n",
    "#encoding from 32*32*32 down to 200 ::: 163x\n",
    "enc,_ = encoder(x_vector, z_size, phase_train=False, reuse=False)\n",
    "dec = decoder(enc, phase_train=False, reuse=False) \n",
    "\n",
    "input_vox = voxnet(x_vector, phase_train=False, reuse=False)\n",
    "decoded_vox = voxnet(dec, phase_train=False, reuse=True)\n",
    "\n",
    "num_voxnet_intermediate_units = np.product(input_vox.get_shape().as_list())\n",
    "\n",
    "loss_pixel = tf.nn.l2_loss(x_vector - dec) / (batch_size*cube_len*cube_len*cube_len)\n",
    "loss_perceptual = tf.nn.l2_loss(input_vox - decoded_vox) / num_voxnet_intermediate_units\n",
    "# weighted sum of the two losses\n",
    "loss = l*loss_pixel + (1-l)*loss_perceptual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='enc')\n",
    "#build a list of variable to load\n",
    "generator_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='gen')\n",
    "#generator_vars.extend(list(weights.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/vamsi/Downloads/tf-3dgan-master/src/models/vase-compress_3/compression_gen_90.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /home/vamsi/Downloads/tf-3dgan-master/src/models/vase-compress_3/compression_gen_90.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /home/vamsi/Downloads/tf-3dgan-master/src/models/cls_vox/biasfree_19999.cptk\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "code_directory = '/home/vamsi/Downloads/tf-3dgan-master/src/models/vase-compress_3/compression_gen_90.ckpt'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    gen_loader = tf.train.Saver(generator_vars)\n",
    "    gen_loader.restore(sess, code_directory)\n",
    "\n",
    "    ec_loader = tf.train.Saver(encoder_vars)\n",
    "    ec_loader.restore(sess, code_directory)\n",
    "\n",
    "    vox_loader = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='vox'))\n",
    "    vox_loader.restore(sess, voxnet_save_path)\n",
    "\n",
    "    # change the path \n",
    "    volumes = d.getAll(obj=obj, train=False, is_local=False, obj_ratio=obj_ratio, cube_len=32)\n",
    "    \n",
    "    volumes = volumes[...,np.newaxis].astype(np.float)\n",
    "\n",
    "    num_samples = len(volumes)\n",
    "    \n",
    "    print(num_samples)\n",
    "\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "\n",
    "    loss_stat = np.array([])\n",
    "\n",
    "    for epoch in range(20):\n",
    "        for i in range(num_batches):\n",
    "            input_voxels = volumes[i*batch_size: (i+1)*batch_size]\n",
    "            # generate and visualize generated images\n",
    "            pix_loss, perc_loss, tot_loss, recon_voxel = sess.run([loss_pixel, loss_perceptual, loss, dec], feed_dict={x_vector: input_voxels})\n",
    "            print(\"epoch {}, batch {}: pix loss {:10.5f}, perc loss {:10.5f}, total loss {:10.5f}\".format(epoch, i, pix_loss, perc_loss, tot_loss))\n",
    "            for n in range(3):\n",
    "                plot_voxel(save_sample[n], save_sample[n + batch_size], saveas='{}{}_{}_test.png'.format(img_directory, epoch*i, n))\n",
    "\n",
    "        #save_sample = np.concatenate((input_voxels, recon_voxel), axis=0)\n",
    "        #recon_voxel.dump(train_sample_directory+'/biasfree_'+str(epoch))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
